---
ONEVIEW:
    GLOBAL:
        ENVIRONMENT: prd
        ACCOUNT: '285887636563'

        EDW_HOST: rdbp1190.ama-assn.org
        EDW_PORT: '54000'
        EDW_NAME: prddw
        EDW_USERNAME: 'dlabs'
        EDW_PASSWORD: '{{datalabs_password}}'

        DATAMART_HOST: rdbp1715.ama-assn.org
        DATAMART_PORT: '54000'
        DATAMART_NAME: prddm
        DATAMART_USERNAME: 'dlabs'
        DATAMART_PASSWORD: '{{datalabs_password}}'

        ODS_HOST: rdbp1715.ama-assn.org
        ODS_PORT: '54000'
        ODS_NAME: eprdods
        ODS_USERNAME: dlabs
        ODS_PASSWORD: '{{datalabs_password}}'

        UDRIVE_HOST: eft.ama-assn.org
        UDRIVE_USERNAME: datalabs
        UDRIVE_PASSWORD: '{{udrive_password}}'

        EFT_HOST: eft.ama-assn.org
        EFT_USERNAME: oneviewprd
        EFT_PASSWORD: '{{eft_password}}'

        S3_INGESTED_DATA_BUCKET: ama-${ENVIRONMENT}-datalake-ingest-us-east-1
        S3_PROCESSED_DATA_BUCKET: ama-${ENVIRONMENT}-datalake-process-us-east-1
        S3_STAGED_DATA_BUCKET: ama-${ENVIRONMENT}-datalake-staged-us-east-1

        DATABASE_HOST: oneview-prd-content-aurora-cluster.cluster-cxgp9osuwqi3.us-east-1.rds.amazonaws.com
        DATABASE_PORT: '5432'
        DATABASE_BACKEND: 'postgresql+psycopg2'
        DATABASE_NAME: 'oneview_content'
        DATABASE_USERNAME:  oneviewadmin
        DATABASE_PASSWORD:  '{{database_password}}'

        S3_CACHE_PYTHON_CLASS: 'datalabs.etl.dag.cache.s3.S3TaskDataCache'
        S3_CACHE_JAVA_CLASS: 'datalabs.task.cache.S3TaskDataCache'
        S3_BASE_PATH: 'AMA/OneView'
        DB2_DRIVER: 'com.ibm.db2.jcc.DB2Jcc'
        DB2_DRIVER_TYPE: 'db2'
        DB2_JAR_PATH: './db2jcc4.jar,./'

    DAG:
        LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-ETL'
        DAG_CLASS: 'datalabs.etl.dag.masterfile.oneview.OneViewDAG'
        DAG_STATE_PARAMETERS:
            DAG_STATE_CLASS: 'datalabs.etl.dag.state.dynamodb.DAGState'
            DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
            STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'
        DAG_TOPIC_ARN: 'arn:aws:sns:us-east-1:${ACCOUNT}:DataLake-${ENVIRONMENT}-DAGProcessor'
        TASK_TOPIC_ARN: 'arn:aws:sns:us-east-1:${ACCOUNT}:DataLake-${ENVIRONMENT}-TaskProcessor'
        DAG_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.awslambda.LambdaDAGExecutorTask'
        TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.awslambda.LambdaTaskExecutorTask'
        ENVIRONMENT: ${ENVIRONMENT}
        STATUS_NOTIFICATION_EMAILS: 'datalabs@ama-assn.org,rudainah.najeeb@ama-assn.org,peter.lane@ama-assn.org'
        STATUS_NOTIFICATION_FROM: 'datalabs@ama-assn.org'
        JOB_QUEUE: 'OneView-${ENVIRONMENT}-ETL'
        JOB_DEFINITION: 'OneView-${ENVIRONMENT}-ETL'

    EXTRACT_PPD:
        BASE_PATH: ''
        FILES: 'physician_professional_data.psv'
        HOST: ${EFT_HOST}
        USERNAME: ${EFT_USERNAME}
        PASSWORD: ${EFT_PASSWORD}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'physician_professional_data.psv'

    CREATE_PHYSICIAN_NPI_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'party_key.csv'

        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'physician_npi.csv'

    SUPPLEMENT_PPD_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'physician_professional_data.psv,race_ethnicity.psv,medical_student.psv'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'physician_professional_data.csv'

    SPLIT_PPD_TABLE:
        COUNT: '10'
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'physician_professional_data.csv'
        CACHE_OUTPUT_FILES: 'physician_professional_data_0.csv,physician_professional_data_1.csv,physician_professional_data_2.csv,physician_professional_data_3.csv,physician_professional_data_4.csv,physician_professional_data_5.csv,physician_professional_data_6.csv,physician_professional_data_7.csv,physician_professional_data_8.csv,physician_professional_data_9.csv'

    EXTRACT_PARTY_KEYS:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        __MACRO_COUNT__: 3
        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: "SELECT PARTY_ID, KEY_TYPE_ID, KEY_VAL FROM AMAEDW.PARTY_KEY WHERE KEY_TYPE_ID=9 OR (KEY_TYPE_ID=18 AND ACTIVE_IND='Y') OR (KEY_TYPE_ID=38 AND ACTIVE_IND='Y') ORDER BY PARTY_ID LIMIT {index}, {count};"
        CHUNK_SIZE: '1000000'
        COUNT: '3000000'
        START_INDEX: '__MACRO_INDEX__'
        MAX_PARTS: '__MACRO_COUNT__'
        PART_INDEX: '__MACRO_INDEX__'
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'party_key___MACRO_INDEX__.csv'

    CONCATENATE_PARTY_KEYS:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'party_key_0.csv,party_key_1.csv,party_key_2.csv'
        CACHE_OUTPUT_FILES: 'party_key.csv'

    EXTRACT_MEMBERSHIP_DATA:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: "SELECT P.PARTY_ID_FROM as PARTY_ID, P.STS_TYPE_ID, S.DESC as MEMBERSHIP_STATUS FROM AMAEDW.PARTY_RLSHIP P, AMAEDW.STS_TYPE S WHERE P.MBRSHP_YR=2022 AND P.THRU_DT is null AND P.STS_TYPE_ID=S.STS_TYPE_ID LIMIT {index}, {count};"
        CHUNK_SIZE: '1000000'
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'membership_year.csv'

    EXTRACT_PHYSICIAN_EMAIL_STATUS:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: "SELECT party.PARTY_ID as PARTY_ID, addr.EMAIL_STATUS as EMAIL_STATUS FROM AMAEDW.EMAIL_ADDR addr INNER JOIN AMAEDW.PARTY_EMAIL party ON party.EMAIL_ID=addr.EMAIL_ID AND party.THRU_DT IS NULL AND party.PURPOSE_TYPE_ID in(266, 279, 315, 327, 337, 344) AND party.SRC_SYS='MASTERFILE' ORDER BY PARTY_ID LIMIT {index}, {count}"
        CHUNK_SIZE: '1000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'email_status.csv'

    CREATE_PHYSICIAN_EMAIL_STATUS_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'email_status.csv'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'email_status.csv'

    CREATE_PHYSICIAN_TABLE:
        __MACRO_COUNT__: 10
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'physician_professional_data___MACRO_INDEX__.csv,physician_npi.csv,membership_year.csv,email_status.csv'
        CACHE_OUTPUT_FILES: 'physician___MACRO_INDEX__.csv'
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}

    CONCATENATE_PHYSICIAN_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'physician_0.csv,physician_1.csv,physician_2.csv,physician_3.csv,physician_4.csv,physician_5.csv,physician_6.csv,physician_7.csv,physician_8.csv,physician_9.csv'
        CACHE_OUTPUT_FILES: 'physician.csv'

    LOAD_PHYSICIAN_TABLE:
        OVERRIDES:
            TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchPythonTaskExecutorTask'

        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'physician.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.Physician'
        APPEND: 'True'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    PRUNE_PHYSICIAN_TABLE:
        OVERRIDES:
            TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchPythonTaskExecutorTask'

        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'physician.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.Physician'
        DELETE: 'True'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_TYPE_OF_PRACTICE:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: 'SELECT DISTINCT T.TOP_CD, T.DESC FROM AMAEDW.TOP T, AMAEDW.MED_PROF P WHERE T.TOP_ID=P.TOP_ID;'
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'type_of_practice.csv'


    CREATE_TYPE_OF_PRACTICE_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_FILES: 'type_of_practice.csv'

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}

    EXTRACT_PRESENT_EMPLOYMENT:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: "SELECT DISTINCT E.EMPLOYER_CD, E.DESC FROM AMAEDW.EMPLOYER E, AMAEDW.MED_PROF P WHERE E.EMPLOYER_ID=P.EMPLOYER_ID;"
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

    EXTRACT_PRESENT_EMPLOYMENT:
        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'present_employment.csv'

    CREATE_PRESENT_EMPLOYMENT_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_FILES: 'present_employment.csv'

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}

    EXTRACT_MAJOR_PROFESSIONAL_ACTIVITY:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: "SELECT DISTINCT M.MPA_CD, M.DESC FROM AMAEDW.MPA M;"
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'major_professional_activity.csv'

    CREATE_MAJOR_PROFESSIONAL_ACTIVITY_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_FILES: 'major_professional_activity.csv'

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}

    EXTRACT_FEDERAL_INFORMATION_PROCESSING_STANDARD_COUNTY:
        URLS: 'https://en.wikipedia.org/wiki/List_of_United_States_FIPS_codes_by_county'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'federal_information_processing_standard_county.xlsx'

    CREATE_FEDERAL_INFORMATION_PROCESSING_STANDARD_COUNTY_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_FILES: 'federal_information_processing_standard_county.xlsx'
        CACHE_OUTPUT_FILES: 'federal_information_processing_standard_county_partial.csv'
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}

    EXTRACT_FEDERAL_INFORMATION_PROCESSING_STANDARD_COUNTY_TABLE_SUPPLEMENT:
        BUCKET: ${S3_STAGED_DATA_BUCKET}
        BASE_PATH: ${S3_BASE_PATH}
        FILES: 'fips_county_supplement.csv'
        INCLUDE_DATESTAMP: 'False'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'fips_county_supplement.csv'

    SUPPLEMENT_FEDERAL_INFORMATION_PROCESSING_STANDARD_COUNTY_TABLE:
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'federal_information_processing_standard_county_partial.csv,fips_county_supplement.csv'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'federal_information_processing_standard_county.csv'

    EXTRACT_CORE_BASED_STATISTICAL_AREA:
        BUCKET: ${S3_STAGED_DATA_BUCKET}
        BASE_PATH: Census/CBSA
        FILES: list1_2020.xls
        INCLUDE_DATESTAMP: 'False'
        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'core_based_statistical_area.xls'

    CREATE_CORE_BASED_STATISTICAL_AREA_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'core_based_statistical_area.xls'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'core_based_statistical_area.csv'

    EXTRACT_SPECIALTY:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: "SELECT DISTINCT S.SPEC_CD, S.DESC FROM AMAEDW.SPEC S;"
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'specialty_all.csv'

    CREATE_SPECIALTY_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_FILES: 'specialty_all.csv'
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}

    REMOVE_UNUSED_SPECIALTIES:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'specialty_all.csv,physician.csv'
        CACHE_OUTPUT_FILES: 'specialty.csv'

    LOAD_SPECIALTY_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'specialty.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.Specialty'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_TYPE_OF_PRACTICE_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'type_of_practice.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.TypeOfPractice'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_MAJOR_PROFESSIONAL_ACTIVITY_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'major_professional_activity.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.MajorProfessionalActivity'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_FEDERAL_INFORMATION_PROCESSING_STANDARD_COUNTY_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'federal_information_processing_standard_county.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.FederalInformationProcessingStandardCounty'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_CORE_BASED_STATISTICAL_AREA_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'core_based_statistical_area.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.CoreBasedStatisticalArea'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_PRESENT_EMPLOYMENT_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'present_employment.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.PresentEmployment'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_RESIDENCY:
        BASE_PATH: 'Data Analytics/Data-Science/Data/Masterfile_OneView'
        FILES: 'Program Information table - Active.txt,Program Address table - Active.txt,Program Personnel table - Active.txt,Program Institution.txt,Institution Information - Active.txt'
        HOST: ${UDRIVE_HOST}
        USERNAME: ${UDRIVE_USERNAME}
        PASSWORD: ${UDRIVE_PASSWORD}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'residency_program.psv, residency_address.psv, residency_program_personnel_member.psv,residency_program_institution.psv,residency_institution_information.psv'

    CREATE_RESIDENCY_TABLES:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'residency_program.psv, residency_address.psv, residency_program_personnel_member.psv,residency_program_institution.psv,residency_institution_information.psv'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'residency_program.csv,residency_program_personnel_member.csv,residency_program_institution.csv'

    LOAD_RESIDENCY_INSTITUTION_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'residency_program_institution.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ResidencyProgramInstitution'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_RESIDENCY_PROGRAM_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'residency_program.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ResidencyProgram'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_RESIDENCY_PERSONNEL_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'residency_program_personnel_member.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ResidencyProgramPersonnelMember'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_IQVIA_BUSINESS:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        __MACRO_COUNT__: 6
        DATABASE_NAME: ${ODS_NAME}
        DATABASE_PORT: ${ODS_PORT}
        SQL: "SELECT B.IMS_ORG_ID, B.BUSINESS_NAME, B.DBA_NAME, B.ADDRESS_ID, B.PHYSICAL_ADDR_1, B.PHYSICAL_ADDR_2, B.PHYSICAL_CITY, B.PHYSICAL_STATE, B.PHYSICAL_ZIP, B.POSTAL_ADDR_1, B.POSTAL_ADDR_2, B.POSTAL_CITY, B.POSTAL_STATE, B.POSTAL_ZIP, B.PHONE, B.FAX, B.WEBSITE, B.LATITUDE, B.LONGITUDE, B.OWNER_STATUS, B.PROFIT_STATUS, B.PRIMARY_COT_ID, B.COT_CLASSIFICATION_ID, B.COT_CLASSIFICATION, B.COT_FACILITY_TYPE_ID, B.COT_FACILITY_TYPE, B.COT_SPECIALTY_ID, B.COT_SPECIALTY, B.RECORD_TYPE, B.TTL_LICENSE_BEDS, B.TTL_CENSUS_BEDS, B.TTL_STAFFED_BEDS, B.TEACHING_HOSP, B.COMMHOSP, B.MSA, B.FIPS_STATE, B.FIPS_COUNTY, B.NUM_OF_PROVIDERS, B.ELECTRONIC_MED_REC, B.EPRESCRIBE, B.PAYPERFORM, B.DEACTIVATION_REASON, B.REFERBACK_IMS_ORG_ID, B.STATUS_INDICATOR, B.BATCH_BUSINESS_DATE FROM ODS.ODS_IMS_BUSINESS B ORDER BY B.IMS_ORG_ID LIMIT {index}, {count};"
        DATABASE_HOST: ${ODS_HOST}
        DATABASE_USERNAME: ${ODS_USERNAME}
        DATABASE_PASSWORD: ${ODS_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '200000'
        COUNT: '200000'
        START_INDEX: '__MACRO_INDEX__'
        MAX_PARTS: '__MACRO_COUNT__'
        PART_INDEX: '__MACRO_INDEX__'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'iqvia_business___MACRO_INDEX__.csv'

    CREATE_BUSINESS_TABLE:
        __MACRO_COUNT__: 6
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'iqvia_business___MACRO_INDEX__.csv,class_of_trade.csv'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'business___MACRO_INDEX__.csv'

    CONCATENATE_BUSINESS_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'business_0.csv,business_1.csv,business_2.csv,business_3.csv,business_4.csv,business_5.csv'
        CACHE_OUTPUT_FILES: 'business.csv'

    CREATE_IQVIA_UPDATE_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'iqvia_business_0.csv'
        CACHE_OUTPUT_FILES: 'iqvia_update.csv'

    LOAD_BUSINESS_TABLE:
        __MACRO_COUNT__: 6
        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.Business'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        APPEND: 'True'
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'business___MACRO_INDEX__.csv'

    EXTRACT_IQVIA_PROVIDER:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${ODS_NAME}
        DATABASE_PORT: ${ODS_PORT}
        SQL: "SELECT P.PROFESSIONAL_ID, P.ME, P.FIRST_NAME, P.MIDDLE_NAME, P.LAST_NAME, P.GEN_SUFFIX, P.DESIGNATION, P.GENDER, P.ROLE, P.PRIMARY_SPEC, P.SECONDARY_SPEC, P.TERTIARY_SPEC, P.PRIMARY_PROF_CODE, P.PRIMARY_PROF_DESC, P.UPIN, P.NPI, P.STATUS_DESC, P.BATCH_BUSINESS_DATE FROM ODS.ODS_IMS_PROFESSIONAL P ORDER BY PROFESSIONAL_ID LIMIT {index}, {count};"
        DATABASE_HOST: ${ODS_HOST}
        DATABASE_USERNAME: ${ODS_USERNAME}
        DATABASE_PASSWORD: ${ODS_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '1000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'iqvia_provider.csv'

    EXTRACT_IQVIA_PROVIDER_AFFILIATION:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${ODS_NAME}
        DATABASE_PORT: ${ODS_PORT}
        SQL: >-
            SELECT
                P.AFFIL_TYPE_ID,
                P.IMS_ORG_ID,
                P.PROFESSIONAL_ID,
                A.AFFIL_TYPE_DESC,
                P.AFFIL_IND,
                P.AFFIL_RANK,
                A.AFFIL_GROUP_CODE,
                A.AFFIL_GROUP_DESC,
                P.BATCH_BUSINESS_DATE
            FROM ODS.ODS_IMS_PROVIDER_AFFILIATION_FACT P
            LEFT JOIN ODS.ODS_IMS_AFFILIATION_TYPE A
            ON P.AFFIL_TYPE_ID = A.AFFIL_TYPE_ID ORDER BY AFFIL_TYPE_ID
            LIMIT {index}, {count};
        DATABASE_HOST: ${ODS_HOST}
        DATABASE_USERNAME: ${ODS_USERNAME}
        DATABASE_PASSWORD: ${ODS_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '1000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'iqvia_provider_affiliation.csv'

    EXTRACT_IQVIA_BEST_PROVIDER_AFFILIATION:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${ODS_NAME}
        DATABASE_PORT: ${ODS_PORT}
        SQL: "SELECT P.AFFIL_TYPE_ID, P.IMS_ORG_ID,P.PROFESSIONAL_ID,A.AFFIL_TYPE_DESC,P.AFFIL_IND,P.AFFIL_RANK, A.AFFIL_GROUP_CODE, A.AFFIL_GROUP_DESC, P.BATCH_BUSINESS_DATE FROM ODS.ODS_IMS_PROVIDER_BEST_AFFILIATION_FACT P, ODS.ODS_IMS_AFFILIATION_TYPE A WHERE P.AFFIL_TYPE_ID = A.AFFIL_TYPE_ID ORDER BY AFFIL_TYPE_ID LIMIT {index}, {count};"
        DATABASE_HOST: ${ODS_HOST}
        DATABASE_USERNAME: ${ODS_USERNAME}
        DATABASE_PASSWORD: ${ODS_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '1000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'iqvia_best_provider_affiliation.csv'

    CREATE_PROVIDER_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'iqvia_provider.csv,iqvia_provider_affiliation.csv,iqvia_best_provider_affiliation.csv'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'iqvia_provider_full.csv,iqvia_provider_affiliation_full.csv'

    REMOVE_UNKNOWN_PROVIDERS:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'iqvia_provider_full.csv,iqvia_provider_affiliation_full.csv,physician.csv'
        CACHE_OUTPUT_FILES: 'iqvia_provider.csv,iqvia_provider_affiliation.csv'

    SPLIT_IQVIA_PROVIDER_TABLE:
        COUNT: '3'
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'iqvia_provider.csv'
        CACHE_OUTPUT_FILES: 'iqvia_provider_0.csv,iqvia_provider_1.csv,iqvia_provider_2.csv'

    SPLIT_IQVIA_PROVIDER_AFFILIATION_TABLE:
        COUNT: '6'
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'iqvia_provider_affiliation.csv'
        CACHE_OUTPUT_FILES: 'iqvia_provider_affiliation_0.csv,iqvia_provider_affiliation_1.csv,iqvia_provider_affiliation_2.csv,iqvia_provider_affiliation_3.csv,iqvia_provider_affiliation_4.csv,iqvia_provider_affiliation_5.csv'

    LOAD_IQVIA_PROVIDER_TABLE:
        __MACRO_COUNT__: 3
        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.Provider'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        APPEND: 'True'
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'iqvia_provider___MACRO_INDEX__.csv'

    LOAD_IQVIA_PROVIDER_AFFILIATION_TABLE:
        __MACRO_COUNT__: 6
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'iqvia_provider_affiliation___MACRO_INDEX__.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ProviderAffiliation'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        APPEND: 'True'

    LOAD_IQVIA_UPDATE_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'iqvia_update.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.IqviaUpdate'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_CREDENTIALING_CUSTOMER:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${DATAMART_NAME}
        DATABASE_PORT: ${DATAMART_PORT}
        SQL: "SELECT DISTINCT C.CUSTOMER_KEY, C.CUSTOMER_NBR, C.CUSTOMER_ISELL_LOGIN, C.CUSTOMER_NAME, C.CUSTOMER_TYPE_DESC, C.CUSTOMER_TYPE, C.CUSTOMER_CATEGORY, C.CUSTOMER_CATEGORY_DESC, C.CURRENT_IND FROM AMADM.dim_customer C LIMIT {index}, {count};"
        DATABASE_HOST: ${DATAMART_HOST}
        DATABASE_USERNAME: ${DATAMART_USERNAME}
        DATABASE_PASSWORD: ${DATAMART_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '1000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'credentialing_customer.csv'

    EXTRACT_CREDENTIALING_PRODUCT:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${DATAMART_NAME}
        DATABASE_PORT: ${DATAMART_PORT}
        SQL: "SELECT DISTINCT P.PRODUCT_ID, P.PRODUCT_DESC FROM AMADM.DIM_PRODUCT P LIMIT {index}, {count};"
        DATABASE_HOST: ${DATAMART_HOST}
        DATABASE_USERNAME: ${DATAMART_USERNAME}
        DATABASE_PASSWORD: ${DATAMART_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '10000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'credentialing_product.csv'

    EXTRACT_CREDENTIALING_ORDER_YEARS:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${DATAMART_NAME}
        DATABASE_PORT: ${DATAMART_PORT}
        SQL: "SELECT DISTINCT D.YR FROM AMADM.DIM_DATE D, AMADM.FACT_EPROFILE_ORDERS O, AMADM.DIM_PHYSICIAN_HIST H WHERE D.DATE_KEY = O.ORDER_DT_KEY AND H.PHYSICIAN_HIST_KEY = O.ORDER_PHYSICIAN_HIST_KEY ORDER BY D.YR DESC"
        DATABASE_HOST: ${DATAMART_HOST}
        DATABASE_USERNAME: ${DATAMART_USERNAME}
        DATABASE_PASSWORD: ${DATAMART_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'credentialing_order_years.csv'

    EXTRACT_CREDENTIALING_ORDER:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlParametricExtractorTask

        CACHE_INPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'credentialing_order_years.csv'

        __MACRO_COUNT__: 9
        DATABASE_NAME: ${DATAMART_NAME}
        DATABASE_PORT: ${DATAMART_PORT}
        SQL: "SELECT DISTINCT O.FACT_EPROFILE_KEY, O.ORDER_NBR, O.CUSTOMER_KEY, O.ORDER_PRODUCT_ID, O.QUANTITY, H.MED_EDU_NBR, H.UPIN_NBR, D.FULL_DT FROM AMADM.DIM_DATE D, AMADM.FACT_EPROFILE_ORDERS O, AMADM.DIM_PHYSICIAN_HIST H WHERE D.DATE_KEY = O.ORDER_DT_KEY AND H.PHYSICIAN_HIST_KEY = O.ORDER_PHYSICIAN_HIST_KEY AND D.YR = '{YR}' ORDER BY FACT_EPROFILE_KEY;"
        DATABASE_HOST: ${DATAMART_HOST}
        DATABASE_USERNAME: ${DATAMART_USERNAME}
        DATABASE_PASSWORD: ${DATAMART_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        MAX_PARTS: '__MACRO_COUNT__'
        PART_INDEX: '__MACRO_INDEX__'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'credentialing_order___MACRO_INDEX__.csv'

    CONCATENATE_CREDENTIALING_ORDER:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'credentialing_order_0.csv,credentialing_order_1.csv,credentialing_order_2.csv,credentialing_order_3.csv,credentialing_order_4.csv,credentialing_order_5.csv,credentialing_order_6.csv,credentialing_order_7.csv,credentialing_order_8.csv'
        CACHE_OUTPUT_FILES: 'credentialing_order.csv'

    EXTRACT_CREDENTIALING_ADDRESSES:
        BASE_PATH: 'Data Analytics/Data-Science/Data/Masterfile_OneView'
        FILES: 'Org_Addresses.xlsx'
        HOST: ${UDRIVE_HOST}
        USERNAME: ${UDRIVE_USERNAME}
        PASSWORD: ${UDRIVE_PASSWORD}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'credentialing_addresses.xlsx'

    MERGE_CREDENTIALING_ADDRESSES_INTO_CUSTOMER_TABLE:
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'credentialing_addresses.xlsx,credentialing_customer.csv'

        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'credentialing_customer.csv'

    CREATE_CREDENTIALING_CUSTOMER_PRODUCT_AND_ORDER_TABLES:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'credentialing_product.csv,credentialing_order.csv'
        CACHE_OUTPUT_FILES: 'credentialing_product.csv,credentialing_order_full.csv'

    REMOVE_UNKNOWN_ORDERS:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'credentialing_order_full.csv,physician.csv,credentialing_customer.csv'
        CACHE_OUTPUT_FILES: 'credentialing_order.csv'

    LOAD_CREDENTIALING_CUSTOMER_TABLE:
        OVERRIDES:
            TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchPythonTaskExecutorTask'

        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'credentialing_customer.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.CredentialingCustomer'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_CREDENTIALING_PRODUCT_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'credentialing_product.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.CredentialingProduct'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    SPLIT_CREDENTIALING_ORDER_TABLE:
        COUNT: '12'
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'credentialing_order.csv'
        CACHE_OUTPUT_FILES: 'credentialing_order_0.csv,credentialing_order_1.csv,credentialing_order_2.csv,credentialing_order_3.csv,credentialing_order_4.csv,credentialing_order_5.csv,credentialing_order_6.csv,credentialing_order_7.csv,credentialing_order_8.csv,credentialing_order_9.csv,credentialing_order_10.csv,credentialing_order_11.csv'

    LOAD_CREDENTIALING_ORDER_TABLE:
        __MACRO_COUNT__: 12
        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.CredentialingOrder'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        APPEND: 'True'
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'credentialing_order___MACRO_INDEX__.csv'

    EXTRACT_PHYSICIAN_RACE_ETHNICITY:
        BASE_PATH: 'Data Analytics/Data-Science/Data/Masterfile_OneView'
        FILES: 'PhysicianRaceEthnicity-ETL.psv'
        HOST: ${UDRIVE_HOST}
        USERNAME: ${UDRIVE_USERNAME}
        PASSWORD: ${UDRIVE_PASSWORD}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'race_ethnicity.psv'

    CREATE_RESIDENCY_PROGRAM_PHYSICIAN_TABLE:
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'residency_program_personnel_member.csv,physician.csv'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'residency_program_physician.csv'

    LOAD_LINKING_TABLES:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'residency_program_physician.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ResidencyProgramPhysician'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_MELISSA:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: "SELECT * FROM AMAEDW.ZIP_CITY_STATE_ZR LIMIT {index}, {count};SELECT * FROM AMAEDW.COUNTY_ZR LIMIT {index}, {count};SELECT * FROM AMAEDW.FONE_ZR LIMIT {index}, {count};SELECT * FROM AMAEDW.CENSUS_ZR LIMIT {index}, {count};SELECT * FROM AMAEDW.CBSA_ZR LIMIT {index}, {count};SELECT * FROM AMAEDW.ZIP_CBSA_ZR LIMIT {index}, {count};SELECT * FROM AMAEDW.MSA_ZR LIMIT {index}, {count};"
        CHUNK_SIZE: '1000000'
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'zip_code.csv,county.csv,area_code.csv,census.csv,core_based_statistical_area_melissa.csv,zip_code_core_based_statistical_areas.csv,metropolitan_statistical_area.csv'

    CREATE_MELISSA_TABLES:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'zip_code.csv,county.csv,area_code.csv,census.csv,core_based_statistical_area_melissa.csv,zip_code_core_based_statistical_areas.csv,metropolitan_statistical_area.csv'
        CACHE_OUTPUT_FILES: 'zip_code.csv,county.csv,area_code.csv,census.csv,core_based_statistical_area_melissa.csv,zip_code_core_based_statistical_areas.csv,metropolitan_statistical_area.csv'

    LOAD_METROPOLITAN_STATISTICAL_AREA_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'metropolitan_statistical_area.csv'
        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.MetropolitanStatisticalArea'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_COUNTY_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'county.csv'
        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.County'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_CORE_BASED_STATISTICAL_AREA_MELISSA_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'core_based_statistical_area_melissa.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.CoreBasedStatisticalAreaMelissa'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_ZIP_CODE_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'zip_code.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ZipCode'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_AREA_CODE_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'area_code.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.AreaCode'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_CENSUS_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'census.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.Census'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    LOAD_ZIP_CODE_CORE_BASED_STATISTICAL_AREA_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'zip_code_core_based_statistical_areas.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ZipCodeCoreBasedStatisticalArea'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_HISTORICAL_RESIDENT:
        BASE_PATH: ''
        FILES: 'historical_resident.psv'
        HOST: ${EFT_HOST}
        USERNAME: ${EFT_USERNAME}
        PASSWORD: ${EFT_PASSWORD}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'historical_resident.psv'

    CREATE_HISTORICAL_RESIDENT_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'historical_resident.psv'
        CACHE_OUTPUT_FILES: 'historical_resident_full.csv'

    REMOVE_UNKNOWN_HISTORICAL_RESIDENTS:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'historical_resident_full.csv,physician.csv'
        CACHE_OUTPUT_FILES: 'historical_resident.csv'

    SPLIT_HISTORICAL_RESIDENT_TABLE:
        COUNT: '6'
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'historical_resident.csv'
        CACHE_OUTPUT_FILES: 'historical_resident_0.csv,historical_resident_1.csv,historical_resident_2.csv,historical_resident_3.csv,historical_resident_4.csv,historical_resident_5.csv'

    LOAD_HISTORICAL_RESIDENT_TABLE:
        __MACRO_COUNT__: 6
        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.HistoricalResident'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        APPEND: 'True'
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'historical_resident___MACRO_INDEX__.csv'

    EXTRACT_MEDICAL_STUDENT:
        BASE_PATH: ''
        FILES: 'medical_student.psv'
        HOST: ${EFT_HOST}
        USERNAME: ${EFT_USERNAME}
        PASSWORD: ${EFT_PASSWORD}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'medical_student.psv'

    EXTRACT_STATE:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        SQL: "SELECT * FROM AMAEDW.STATE LIMIT {index}, {count};"
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '1000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'state.csv'

    CREATE_STATE_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'state.csv'
        CACHE_OUTPUT_FILES: 'state.csv'

    LOAD_STATE_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'state.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.State'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_CLASS_OF_TRADE:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${ODS_NAME}
        DATABASE_PORT: ${ODS_PORT}
        SQL: "SELECT * FROM ODS.ODS_IMS_CLASS_OF_TRADE LIMIT {index}, {count};"
        DATABASE_HOST: ${ODS_HOST}
        DATABASE_USERNAME: ${ODS_USERNAME}
        DATABASE_PASSWORD: ${ODS_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '1000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'class_of_trade.csv'

    CREATE_CLASS_OF_TRADE_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'class_of_trade.csv'
        CACHE_OUTPUT_FILES: 'class_of_trade_specialty.csv,class_of_trade_facility.csv,class_of_trade_classification.csv'

    LOAD_CLASS_OF_TRADE_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'class_of_trade_specialty.csv,class_of_trade_facility.csv,class_of_trade_classification.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ClassOfTradeSpecialty,datalabs.model.masterfile.oneview.ClassOfTradeFacilityType,datalabs.model.masterfile.oneview.ClassOfTradeClassification'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    CREATE_STATIC_REFERENCE_TABLE:
        CACHE_OUTPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'provider_affiliation_group.csv,provider_affiliation_type.csv,profit_status.csv,owner_status.csv'

    LOAD_STATIC_REFERENCE_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'provider_affiliation_group.csv,provider_affiliation_type.csv,profit_status.csv,owner_status.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.ProviderAffiliationGroup,datalabs.model.masterfile.oneview.ProviderAffiliationType,datalabs.model.masterfile.oneview.ProfitStatus,datalabs.model.masterfile.oneview.OwnerStatus'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_MEDICAL_SCHOOL:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        SQL: "SELECT K.KEY_VAL, N.ORG_NM FROM AMAEDW.PARTY_KEY K, AMAEDW.ORG_NM N WHERE K.KEY_TYPE_ID=23 AND K.PARTY_ID=N.PARTY_ID AND N.THRU_DT IS NULL LIMIT {index}, {count};"
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}
        CHUNK_SIZE: '1000000'

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'medical_school.csv'

    CREATE_MEDICAL_SCHOOL_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'medical_school.csv'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'medical_school.csv'

    LOAD_MEDICAL_SCHOOL_TABLE:
        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'medical_school.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.MedicalSchool'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    EXTRACT_MEDICAL_LICENSES:
        OVERRIDES:
            LAMBDA_FUNCTION: 'OneView-${ENVIRONMENT}-Extract'
            DAG_STATE_PARAMETERS:
                DAG_STATE_CLASS: datalabs.etl.dag.state.dynamodb.DagState
                DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
                STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'

        TASK_CLASS: datalabs.etl.sql.SqlExtractorTask

        DATABASE_NAME: ${EDW_NAME}
        DATABASE_PORT: ${EDW_PORT}
        DATABASE_HOST: ${EDW_HOST}
        DATABASE_USERNAME: ${EDW_USERNAME}
        DATABASE_PASSWORD: ${EDW_PASSWORD}
        SQL: "SELECT DISTINCT L.PARTY_ID, L.LIC_NBR, S.SRC_STATE_CD as LIC_STATE, L.ISS_DT, L.EXP_DT, L.RNW_DT, L.DEGREE_CD, ST.DESC as LIC_STATUS, T.DESC as LIC_TYPE FROM AMAEDW.LIC L, AMAEDW.STATE S, AMAEDW.STS_TYPE ST, AMAEDW.LIC_TYPE T WHERE L.THRU_DT IS NULL AND L.DELETE_IND='N' AND L.LIC_NBR<>' ' AND L.STATE_ID=S.STATE_ID AND L.STS_TYPE_ID=ST.STS_TYPE_ID AND L.LIC_TYPE_ID=T.LIC_TYPE_ID AND L.STS_TYPE_ID=40"
        DRIVER: ${DB2_DRIVER}
        DRIVER_TYPE: ${DB2_DRIVER_TYPE}
        JAR_PATH: ${DB2_JAR_PATH}

        CACHE_OUTPUT_CLASS: ${S3_CACHE_JAVA_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'medical_licenses.csv'

    CLEAN_MEDICAL_LICENSES:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'medical_licenses.csv'

        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'medical_licenses_full.csv'

    CREATE_MEDICAL_LICENSES_TABLE:
        CACHE_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_BASE_PATH: ${S3_BASE_PATH}

        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'medical_licenses_full.csv, physician_npi.csv, physician.csv'

        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_FILES: 'medical_licenses.csv'

    LOAD_MEDICAL_LICENSES_TABLE:
        OVERRIDES:
            TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchPythonTaskExecutorTask'

        CACHE_INPUT_CLASS: ${S3_CACHE_PYTHON_CLASS}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_FILES: 'medical_licenses.csv'

        MODEL_CLASSES: 'datalabs.model.masterfile.oneview.content.MedicalLicense'
        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}

    REFRESH_PHYSICIAN_VIEW:
        OVERRIDES:
            TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchPythonTaskExecutorTask'

        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        VIEWS: 'oneview.mat_phy_view'

    REINDEX_PHYSICIAN_VIEW:
        OVERRIDES:
            TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchPythonTaskExecutorTask'

        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        TABLES: 'oneview.mat_phy_view'

    REFRESH_PROVIDER_VIEW:
        OVERRIDES:
            TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchPythonTaskExecutorTask'

        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        VIEWS: 'oneview.mat_phy_pro_view'

    REINDEX_PROVIDER_VIEW:
        OVERRIDES:
            TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchPythonTaskExecutorTask'

        DATABASE_HOST: ${DATABASE_HOST}
        DATABASE_PORT: ${DATABASE_PORT}
        DATABASE_BACKEND: ${DATABASE_BACKEND}
        DATABASE_NAME: ${DATABASE_NAME}
        DATABASE_USERNAME: ${DATABASE_USERNAME}
        DATABASE_PASSWORD: ${DATABASE_PASSWORD}
        TABLES: 'oneview.mat_phy_pro_view'
