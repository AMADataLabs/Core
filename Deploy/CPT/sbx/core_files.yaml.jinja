---
CPT_CORE:
    GLOBAL:
    ENVIRONMENT: sbx
    ACCOUNT: '644454719059'

    S3_INGESTED_DATA_BUCKET: ama-${ENVIRONMENT}-datalake-ingest-us-east-1
    S3_PROCESSED_DATA_BUCKET: ama-${ENVIRONMENT}-datalake-process-us-east-1

    PYTHON_S3_CACHE_CLASS: 'datalabs.etl.dag.cache.s3.S3TaskDataCache'
    JAVA_S3_CACHE_CLASS: 'datalabs.task.cache.S3TaskDataCache'
    S3_BASE_PATH: 'AMA/CPT/Core'
    S3_CACHE_JAVA_CLASS: 'datalabs.etl.dag.cache.S3TaskDataCache'

    CORE_OUTPUT_ZIP: output.zip

    DAG:
        LAMBDA_FUNCTION: 'CPT-API-${ENVIRONMENT}-BuilderDAG'
        DAG_CLASS: 'datalabs.etl.dag.cpt.files.core.CPTCoreDAG'
        DAG_STATE_CLASS: 'datalabs.etl.dag.state.dynamodb.DAGState'
        DAG_STATE_TABLE: 'DataLake-dag-state-${ENVIRONMENT}'
        STATE_LOCK_TABLE: 'DataLake-scheduler-locks-${ENVIRONMENT}'
        DAG_TOPIC_ARN: 'arn:aws:sns:us-east-1:${ACCOUNT}:DataLake-${ENVIRONMENT}-DAGProcessor'
        TASK_TOPIC_ARN: 'arn:aws:sns:us-east-1:${ACCOUNT}:DataLake-${ENVIRONMENT}-TaskProcessor'
        DAG_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.awslambda.LambdaDAGExecutorTask'
        TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.awslambda.LambdaTaskExecutorTask'
        ENVIRONMENT: ${ENVIRONMENT}
        STATUS_NOTIFICATION_EMAILS: 'datalabs@ama-assn.org,rudainah.najeeb@ama-assn.org'
        STATUS_NOTIFICATION_FROM: 'datalabs@ama-assn.org'
        JOB_QUEUE: 'CPT-API-${ENVIRONMENT}-Files'
        JOB_DEFINITION: 'CPT-API-${ENVIRONMENT}-Files'
        TASK_CLASS: ''

    FIND_INPUT_FILES:
        BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        BASE_PATH: ${S3_BASE_PATH}
        CORE_FILES_ZIP: ${CORE_OUTPUT_ZIP}

        CACHE_OUTPUT_CLASS: ${PYTHON_S3_CACHE_CLASS}
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: input_files.txt


    EXTRACT_INPUT_FILES:
        CACHE_CLASS: ${PYTHON_S3_CACHE_CLASS}

        CACHE_INPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: input_files.txt

        BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        BASE_PATH: ${S3_BASE_PATH}
        INCLUDE_DATESTAMP: 'False'

        CACHE_OUTPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: 'input/annual_core.zip,input/incremental_core.zip'

    BUILD_CORE:
        TASK_EXECUTOR_CLASS: 'datalabs.etl.dag.execute.batch.BatchJavaTaskExecutorTask'
        TASK_CLASS: datalabs.etl.cpt.build.CoreBuilderTask
        DAG_STATE_CLASS: 'datalabs.etl.dag.state.dynamodb.DagState'
        CACHE_CLASS: ${JAVA_S3_CACHE_CLASS}

        CACHE_INPUT_BUCKET: ${S3_INGESTED_DATA_BUCKET}
        CACHE_INPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_INPUT_FILES: 'input/annual_core.zip,input/incremental_core.zip'

        HOST: 'ec2-35-169-124-185.compute-1.amazonaws.com'
        USERNAME: 'admin'
        PASSWORD: '{{marklogic_password}}'
        PORT: '8022'
        CACHE_OUTPUT_BUCKET: ${S3_PROCESSED_DATA_BUCKET}
        CACHE_OUTPUT_BASE_PATH: ${S3_BASE_PATH}
        CACHE_OUTPUT_FILES: ${CORE_OUTPUT_ZIP}

























    #


