image:
  name: 644454719059.dkr.ecr.us-east-1.amazonaws.com/datalabs-bitbucket-pipelines:1.3.0
  aws:
    access-key: $AWS_ACCESS_KEY_ID_SANDBOX
    secret-key: $AWS_SECRET_ACCESS_KEY_SANDBOX

options:
  docker: true

pipelines:
    branches:
        master:
        - step:
            name: Build
            caches:
                - build-dependencies
            script:
            - bash Script/bitbucket-pipelines-build.sh
    tags:
        'datalabs-*_*.*.*':
        - step:
            name: Build Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - source Deploy/Master/release-info.sh $BITBUCKET_TAG
            - >-
                bash Deploy/Master/deploy-package --project ${PROJECT} --version ${RELEASE_VERSION}
    custom:
        ##############################################################
        # global targets
        ##############################################################

        Test:
        - step:
            name: Unit and Lint Tests
            caches:
                - test-dependencies
            script:
                - bash Script/bitbucket-pipelines-test.sh


        ##############################################################
        # master branch targets
        ##############################################################

        AMC:
        - step:
            name: Create Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project AMC
        - step:
            name: Update ETL Bundle
            caches:
                - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - >-
                bash Deploy/Master/deploy-lambda-function
                --environment sbx
                --project AMC
                --bundle Masterfile/AMC.zip
                --jdbc-driver Informix
                --use-package
        # - step:
        #     name: Update Lambda Functions
        #     script:
        #     - export ENABLE_FEATURE_DEV=True
        #     - export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID_SANDBOX
        #     - export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY_SANDBOX
        #     - export AWS_DEFAULT_REGION='us-east-1'
        #     - export ENVIRONMENT=sbx
        #     - bash Deploy/Master/update-functions -e sbx -s OneView -p Masterfile AMC=AMC.zip

        HelloWorld:
        - step:
            name: Update Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project HelloWorld

        - parallel:
            - step:
                name: Update Sandbox Bundle
                caches:
                    - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project HelloWorld
                    --bundle HelloWorld.zip
                    --use-package
            - step:
                name: Update Development Bundle
                caches:
                    - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment dev
                    --project HelloWorld
                    --bundle Masterfile/HelloWorld.zip
                    --use-package
            - step:
                name: Update Test Bundle
                caches:
                    - environment-test
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment tst
                    --project HelloWorld
                    --bundle Masterfile/HelloWorld.zip
                    --use-package
            - step:
                name: Update Staging Bundle
                caches:
                    - environment-stage
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e itg -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment itg
                    --project HelloWorld
                    --bundle Masterfile/HelloWorld.zip
                    --use-package
            - step:
                name: Update Production Bundle
                caches:
                    - environment-prod
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment prd
                    --project HelloWorld
                    --bundle Masterfile/HelloWorld.zip
                    --use-package

        - parallel:
            - step:
                name: Update Sandbox Lambda Function
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - bash Deploy/Master/update-functions -e sbx -s DataLake HelloWorld=HelloWorld.zip
            - step:
                name: Update Development Lambda Function
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s DataLake
                    HelloWorld=HelloWorld.zip
            - step:
                name: Update Test Lambda Function
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s DataLake
                    HelloWorld=HelloWorld.zip
            - step:
                name: Update Production Lambda Function
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s DataLake
                    HelloWorld=HelloWorld.zip
            - step:
                name: Update Staging Lambda Function
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e itg -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e itg -s DataLake
                    HelloWorld=HelloWorld.zip


        ContactID:
        - step:
            name: Update Bundle
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - >-
                bash Deploy/Master/deploy-lambda-function
                --environment sbx
                --project ContactID
                --bundle CustomerIntelligence/ContactID.zip
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/update-functions -e sbx -s DataLake -p CustomerIntelligence ContactID=ContactID.zip


        CPT-API-ETL:
        - step:
            name: Create Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project CPT/API/ETL
        - parallel:
            - step:
                name: Update Sandbox Bundle
                caches:
                    - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project CPT/API/ETL
                    --bundle CPT/API/ETL.zip
                    --use-package
            - step:
                name: Update Development Bundle
                caches:
                    - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment dev
                    --project CPT/API/ETL
                    --bundle CPT/API/ETL.zip
                    --use-package
            - step:
                name: Update Test Bundle
                caches:
                    - environment-test
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment tst
                    --project CPT/API/ETL
                    --bundle CPT/API/ETL.zip
                    --use-package
            - step:
                name: Update Ttaging Bundle
                caches:
                    - environment-stage
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e itg -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment itg
                    --project CPT/API/ETL
                    --bundle CPT/API/ETL.zip
                    --use-package
            - step:
                name: Update Production Bundle
                caches:
                    - environment-prod
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment prd
                    --project CPT/API/ETL
                    --bundle CPT/API/ETL.zip
                    --use-package
        - parallel:
            - step:
                name: Update Sandbox Lambda Functions
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - bash Deploy/Master/update-functions -e sbx -s CPT-API -p CPT/API ETL=ETL.zip
            - step:
                name: Update Development Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s CPT-API -p CPT/API
                    ETL=ETL.zip
            - step:
                name: Update Test Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s CPT-API -p CPT/API
                    ETL=ETL.zip
            - step:
                name: Update Production Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s CPT-API -p CPT/API
                    ETL=ETL.zip

        CPT-API-Endpoint:
        - step:
            name: Create Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project CPT/API/Endpoint
        - parallel:
            - step:
                name: Update Sandbox Bundle
                caches:
                    - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project CPT/API/Endpoint
                    --bundle CPT/API/Endpoint.zip
                    --use-package
            - step:
                name: Update Development Bundle
                caches:
                    - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment dev
                    --project CPT/API/Endpoint
                    --bundle CPT/API/Endpoint.zip
                    --use-package
            - step:
                name: Update Test Bundle
                caches:
                    - environment-test
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment tst
                    --project CPT/API/Endpoint
                    --bundle CPT/API/Endpoint.zip
                    --use-package
            - step:
                name: Update Staging Bundle
                caches:
                    - environment-stage
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e itg -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment itg
                    --project CPT/API/Endpoint
                    --bundle CPT/API/Endpoint.zip
                    --use-package
            # - step:
            #     name: Update Production Bundle
            #     caches:
            #         - environment-prod
            #     script:
            #     - >-
            #         bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            #         -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            #     - >-
            #         bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
            #         --environment prd
            #         --project CPT/API/Endpoint
            #         --bundle CPT/API/Endpoint.zip
            #         --use-package
        - parallel:
            - step:
                name: Update Sandbox Lambda Functions
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/update-functions -e sbx -s CPT-API -p CPT/API
                    Authorizer=Endpoint.zip
                    Endpoint=Endpoint.zip
                    BulkAuthorizer=Endpoint.zip
                    BulkEndpoint=Endpoint.zip
            - step:
                name: Update Development Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i
                    Deploy/Master/update-functions -e dev -s CPT-API -p CPT/API
                    Authorizer=Endpoint.zip
                    Endpoint=Endpoint.zip
                    BulkAuthorizer=Endpoint.zip
                    BulkEndpoint=Endpoint.zip
            - step:
                name: Update Test Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i
                    Deploy/Master/update-functions -e tst -s CPT-API -p CPT/API
                    Authorizer=Endpoint.zip
                    Endpoint=Endpoint.zip
                    BulkAuthorizer=Endpoint.zip
                    BulkEndpoint=Endpoint.zip
            - step:
                name: Update Staging Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e itg -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i
                    Deploy/Master/update-functions -e itg -s CPT-API -p CPT/API
                    Authorizer=Endpoint.zip
                    Endpoint=Endpoint.zip
                    BulkAuthorizer=Endpoint.zip
                    BulkEndpoint=Endpoint.zip
            # - step:
            #     name: Update Production Lambda Functions
            #     script:
            #     - >-
            #         bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            #         -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            #     - >-
            #         bash --rcfile assume_role.rc -i
            #         Deploy/Master/update-functions -e prd -s CPT-API -p CPT/API
            #         Authorizer=Endpoint.zip
            #         Endpoint=Endpoint.zip
            #         BulkAuthorizer=Endpoint.zip
            #         BulkEndpoint=Endpoint.zip

        CPT-Files-Watermark:
        - step:
            name: Create Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project CPT/Files/Watermark
        - parallel:
            - step:
                name: Update sandbox Bundle
                caches:
                    - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project CPT/Files/Watermark
                    --bundle CPT/Files/Watermark.zip
                    --use-package
            - step:
                name: Update development Bundle
                caches:
                    - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment dev
                    --project CPT/Files/Watermark
                    --bundle CPT/Files/Watermark.zip
                    --use-package
            - step:
                name: Update test Bundle
                caches:
                    - environment-test
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment tst
                    --project CPT/Files/Watermark
                    --bundle CPT/Files/Watermark.zip
                    --use-package
            - step:
                name: Update staging Bundle
                caches:
                    - environment-stage
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e itg -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment itg
                    --project CPT/Files/Watermark
                    --bundle CPT/Files/Watermark.zip
                    --use-package
            - step:
                name: Update production Bundle
                caches:
                    - environment-prod
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment prd
                    --project CPT/Files/Watermark
                    --bundle CPT/Files/Watermark.zip
                    --use-package
        - parallel:
            - step:
                name: Update sandbox Lambda Functions
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - bash Deploy/Master/update-functions -e sbx -s CPT-API -p CPT/Files WatermarkDAG=Watermark.zip
            - step:
                name: Update development Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s CPT-API -p CPT/Files
                    WatermarkDAG=Watermark.zip
            # - step:
            #     name: Update test Lambda Functions
            #     script:
            #     - >-
            #         bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            #         -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            #     - >-
            #         bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s CPT-API -p CPT/Files
            #         WatermarkDAG=Watermark.zip
            # - step:
            #     name: Update production Lambda Functions
            #     script:
            #     - >-
            #         bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            #         -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            #     - >-
            #         bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s CPT-API -p CPT/Files
            #         WatermarkDAG=Watermark.zip

        DBL:
        - step:
            name: Create Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project DBL
        - step:
            name: Update ETL Bundle
            caches:
                - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - >-
                bash Deploy/Master/deploy-lambda-function
                --environment sbx
                --project DBL
                --bundle Masterfile/DBLReport.zip
                --use-package

        HelloWorldJava:
        - step:
            name: Create Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project HelloWorldJava/Task
        - parallel:
            - step:
                name: Update DAG Bundle
                caches:
                - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project HelloWorldJava/DAG
                    --bundle HelloWorldJava/DAG.zip
                    --use-package
            - step:
                name: Update Task Bundle
                caches:
                - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project HelloWorldJava/Task
                    --bundle HelloWorldJava/Task.zip
                    --use-package

                # Create the Docker image
                - export VERSION=`cat Build/HelloWorldJava/Task/VERSION`
                - cp Bundle/target/hello_world_java-${VERSION}.jar ./hello_world_java.jar
                - docker build -t hello_world_java-sbx -f Build/HelloWorldJava/Task/Dockerfile ./

                # Push the Docker image to ECR
                - export VERSION=`cat Build/HelloWorldJava/Task/VERSION`
                - pipe: atlassian/aws-ecr-push-image:1.5.0
                  variables:
                    AWS_ACCESS_KEY_ID: $AWS_ACCESS_KEY_ID_SANDBOX
                    AWS_SECRET_ACCESS_KEY: $AWS_SECRET_ACCESS_KEY_SANDBOX
                    AWS_DEFAULT_REGION: 'us-east-1'
                    IMAGE_NAME: 'hello_world_java-sbx'
                    TAGS: '$VERSION latest'
        - step:
            name: Update Lambda Functions
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - >-
                bash Deploy/Master/update-functions -e sbx -s DataLake -p HelloWorldJava
                HelloWorldJavaDAG=DAG.zip
                HelloWorldJavaTask=Task.jar

        HelloWorldVault:
        - step:
            name: Create Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project HelloWorldVault
        - parallel:
            - step:
                name: Update Sandbox Bundle
                caches:
                    - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project HelloWorldVault
                    --bundle HelloWorldVault.zip
                    --use-package
            - step:
                name: Update Development Bundle
                caches:
                    - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment dev
                    --project HelloWorldVault
                    --bundle HelloWorldVault.zip
                    --runtime Python
        - parallel:
            - step:
                name: Update Sandbox Lambda Function
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - bash Deploy/Master/update-functions -e sbx -s DataLake HelloWorldVault=HelloWorldVault.zip
            - step:
                name: Update Development Lambda Function
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s DataLake
                    HelloWorldVault=HelloWorldVault.zip

        OneView-ETL:
        - step:
            name: Create New Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project OneView/ETL
        - parallel:
            - step:
                name: Update Sandbox Lambda Bundle
                caches:
                    - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project OneView/ETL
                    --bundle OneView/ETL.zip
                    --jdbc-driver DB2
                    --jdbc-driver Informix
                    --use-package
            - step:
                name: Update Development Lambda Bundle
                caches:
                    - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment dev
                    --project OneView/ETL
                    --bundle OneView/ETL.zip
                    --jdbc-driver DB2
                    --jdbc-driver Informix
                    --use-package
            - step:
                name: Update Test Lambda Bundle
                caches:
                    - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment tst
                    --project OneView/ETL
                    --bundle OneView/ETL.zip
                    --jdbc-driver DB2
                    --jdbc-driver Informix
                    --use-package
            - step:
                name: Update Production Lambda Bundle
                caches:
                    - environment-prod
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment prd
                    --project OneView/ETL
                    --bundle OneView/ETL.zip
                    --jdbc-driver DB2
                    --jdbc-driver Informix
                    --use-package
        - parallel:
            - step:
                name: Update Sandbox Lambda Function
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - bash Deploy/Master/update-functions -e sbx -s OneView -p OneView ETL=ETL.zip
            - step:
                name: Update Development Lambda Function
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s OneView -p OneView
                    ETL=ETL.zip
            - step:
                name: Update Test Lambda Function
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s OneView -p OneView
                    ETL=ETL.zip
            - step:
                name: Update Production Lambda Function
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s OneView -p OneView
                    ETL=ETL.zip

        OneView-Reindex:
        - step:
            name: Create New Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project OneView/ETL/Reindex
        - parallel:
            - step:
                name: Update Development Batch Job Image
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -N ecr -I $AWS_ACCESS_KEY_ID_SHARED -S $AWS_SECRET_ACCESS_KEY_SHARED
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-container-image
                    --environment dev
                    --project OneView/ETL/Reindex
                    --repo oneview-dev
            - step:
                name: Update Test Batch Job Image
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -N ecr -I $AWS_ACCESS_KEY_ID_SHARED -S $AWS_SECRET_ACCESS_KEY_SHARED
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-container-image
                    --environment tst
                    --project OneView/ETL/Reindex
                    --runtime Python
                    --repo oneview-tst
            - step:
                name: Update Production Batch Job Image
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -N ecr -I $AWS_ACCESS_KEY_ID_SHARED -S $AWS_SECRET_ACCESS_KEY_SHARED
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-container-image
                    --environment prd
                    --project OneView/ETL/Reindex
                    --runtime Python
                    --repo oneview-prd

        OneView-API:
        - step:
            name: Create New Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project OneView/API
        - parallel:
            - step:
                name: Update Sandbox Lambda Bundle
                caches:
                    - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project OneView/API
                    --bundle OneView/API.zip
                    --use-package
            - step:
                name: Update Development Lambda Bundle
                caches:
                    - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment dev
                    --project OneView/API
                    --bundle OneView/API.zip
                    --use-package
            - step:
                name: Update Test Lambda Bundle
                caches:
                    - environment-test
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment tst
                    --project OneView/API
                    --bundle OneView/API.zip
                    --use-package
            - step:
                name: Update Production Lambda Bundle
                caches:
                    - environment-prod
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment prd
                    --project OneView/API
                    --bundle OneView/API.zip
                    --use-package
        - parallel:
            - step:
                name: Reload Sandbox Lambda Functions
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - bash Deploy/Master/update-functions -e sbx -s OneView -p OneView API=API.zip
            - step:
                name: Reload Development Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s OneView -p OneView
                    API=API.zip
            - step:
                name: Reload Test Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s OneView -p OneView
                    API=API.zip
            - step:
                name: Reload Production Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s OneView -p OneView
                    API=API.zip

        Organizations:
        - step:
            name: Update ETL Bundle
            caches:
                - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - >-
                bash Deploy/Master/deploy-lambda-function
                --environment sbx
                --project CPT/Organizations
                --bundle IntelligentPlatform/OrganizationsETL.zip
                --runtime Python
                --jdbc-driver SQLServer

        Scheduler:
        - step:
            name: Create Development Component Package
            caches:
            - environment-master
            script:
            - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
            - bash Deploy/Master/deploy-python-package --project Scheduler
        - parallel:
            - step:
                name: Update Sandbox Bundle
                caches:
                - environment-master
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/deploy-lambda-function
                    --environment sbx
                    --project Scheduler
                    --bundle Scheduler.zip
                    --use-package
            - step:
                name: Update Development Bundle
                caches:
                - environment-dev
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment dev
                    --project Scheduler
                    --bundle Scheduler.zip
                    --use-package
            - step:
                name: Update Test Bundle
                caches:
                - environment-test
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment tst
                    --project Scheduler
                    --bundle Scheduler.zip
                    --use-package
            - step:
                name: Update Staging Bundle
                caches:
                - environment-stage
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment itg
                    --project Scheduler
                    --bundle Scheduler.zip
                    --use-package
            - step:
                name: Update Production Bundle
                caches:
                - environment-prod
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                    --environment prd
                    --project Scheduler
                    --bundle Scheduler.zip
                    --use-package
        - parallel:
            - step:
                name: Reload Sandbox Lambda Functions
                script:
                - bash Deploy/Master/setup-aws-cli -e sbx -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                - >-
                    bash Deploy/Master/update-functions -e sbx -s DataLake
                    Scheduler=Scheduler.zip
                    DAGProcessor=Scheduler.zip
                    TaskProcessor=Scheduler.zip
            - step:
                name: Reload Development Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s DataLake
                    Scheduler=Scheduler.zip
                    DAGProcessor=Scheduler.zip
                    TaskProcessor=Scheduler.zip
            - step:
                name: Reload Test Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s DataLake
                    Scheduler=Scheduler.zip
                    DAGProcessor=Scheduler.zip
                    TaskProcessor=Scheduler.zip
            - step:
                name: Reload Staging Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e itg -s DataLake
                    Scheduler=Scheduler.zip
                    DAGProcessor=Scheduler.zip
                    TaskProcessor=Scheduler.zip
            - step:
                name: Reload Production Lambda Functions
                script:
                - >-
                    bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                    -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
                - >-
                    bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s DataLake
                    Scheduler=Scheduler.zip
                    DAGProcessor=Scheduler.zip
                    TaskProcessor=Scheduler.zip


        ##############################################################
        # dev branch targets
        ##############################################################

        AMC-dev:
        - step:
            name: Update ETL Bundle
            caches:
            - environment-dev
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment dev
                --project AMC
                --bundle Masterfile/AMC.zip
                --jdbc-driver Informix
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - export ENABLE_FEATURE_DEV=True
            - export ENVIRONMENT=dev
            - >-
                bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s OneView -p Masterfile
                AMC=AMC.zip

        CPT-API-Endpoint-dev:
        - step:
            name: Update Bundle
            caches:
                - environment-dev
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment dev
                --project CPT/API/Endpoint
                --bundle CPT/API/Endpoint.zip
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s CPT-API -p CPT/API
                Authorizer=Endpoint.zip
                Endpoint=Endpoint.zip
                BulkAuthorizer=Endpoint.zip
                BulkEndpoint=Endpoint.zip

        DBL-dev:
        - step:
            name: Update ETL Bundle
            caches:
            - environment-dev
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment dev
                --project DBL
                --bundle Masterfile/DBLReport.zip
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - export ENABLE_FEATURE_DEV=True
            - export ENVIRONMENT=dev
            - >-
                bash Deploy/Master/setup-aws-cli -e dev -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s OneView -p Masterfile
                DBLReport=DBLReport.zip

        OneView-dev:
        - parallel:
            # - step:
            #     name: Create Database
            #     caches:
            #       - environment-dev
            #     script:
            #     - bash Script/setup-virtual-environment OneView
            #     - export ENABLE_FEATURE_DEV=True
            #     - export DATABASE_NAME=oneview_content
            #     - export DATABASE_NAME_ADMIN=postgres
            #     - export DATABASE_BACKEND=postgresql+psycopg2
            #     - export DATABASE_HOST=$ONEVIEW_DATABASE_HOST_DEV
            #     - export DATABASE_PORT=5432
            #     - export DATABASE_USERNAME=$ONEVIEW_DATABASE_USERNAME_DEV
            #     - export DATABASE_PASSWORD=$ONEVIEW_DATABASE_PASSWORD_DEV
            #     - bash Deploy/Master/create-database OneView
            - step:
                name: Update ETL Batch Job Image
                caches:
                    - environment-dev
                script:
                # Assume ECR role
                - aws configure set profile.shared.aws_access_key_id $AWS_ACCESS_KEY_ID_SHARED
                - aws configure set profile.shared.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_SHARED
                - aws configure set profile.shared.region us-east-1
                - aws configure set profile.shared.output json
                - bash Script/ecr_assume_role.sh | grep source > assume_role.rc
                - source assume_role.rc

                # Build the image
                - >-
                    docker build -t oneview-dev
                    -f ./Build/OneView/ETL/Reindex/Dockerfile ./

                # Push the image to ECR
                - >-
                    aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin
                    394406051370.dkr.ecr.us-east-1.amazonaws.com
                - docker tag oneview-dev 394406051370.dkr.ecr.us-east-1.amazonaws.com/oneview-dev:1.0.1
                - docker push 394406051370.dkr.ecr.us-east-1.amazonaws.com/oneview-dev:1.0.1
                - docker tag oneview-dev 394406051370.dkr.ecr.us-east-1.amazonaws.com/oneview-dev:latest
                - docker push 394406051370.dkr.ecr.us-east-1.amazonaws.com/oneview-dev:latest

            - step:
                name: Update ETL Bundle
                caches:
                    - environment-dev
                script:
                # Setup virtual environment
                - bash Script/setup-virtual-environment Master/BitBucketPipelines
                - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
                - export PATH="$VIRTUAL_ENV/bin:$PATH"

                # Setup AWS CLI
                - export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID_SANDBOX
                - export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY_SANDBOX
                - export AWS_DEFAULT_REGION='us-east-1'

                # Install the DB2 JDBC driver
                - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/Db2JdbcDriver.zip Db2JdbcDriver.zip
                - unzip ./Db2JdbcDriver.zip

                # Install the Informix JDBC driver
                - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/InformixJdbcDriver.zip InformixJdbcDriver.zip
                - unzip ./InformixJdbcDriver.zip
                - echo "db2.jcc.charsetDecoderEncoder=3" >> ./DB2JccConfiguration.properties

                # Assume maintenance role
                - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
                - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
                - aws configure set profile.apigw.region us-east-1
                - aws configure set profile.apigw.output json
                - bash Script/apigw_assume_role.sh dev | grep source > assume_role.rc

                # Create the code bundle
                - export ENABLE_FEATURE_DEV=True
                - >-
                    bash Deploy/Master/create-python-bundle --project OneView/ETL
                    -f db2jcc4.jar -f DB2JccConfiguration.properties -f jdbc-4.50.4.1.jar -f bson-4.2.0.jar

                # Upload the code bundle
                - export AWS_S3_BUCKET='ama-dev-datalake-lambda-us-east-1'
                - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle OneView/ETL
            - step:
                name: Update API Bundle
                caches:
                    - environment-dev
                script:
                # Setup virtual environment
                - bash Script/setup-virtual-environment Master/BitBucketPipelines
                - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
                - export PATH="$VIRTUAL_ENV/bin:$PATH"

                # Assume maintenance role
                - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
                - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
                - aws configure set profile.apigw.region us-east-1
                - aws configure set profile.apigw.output json
                - bash Script/apigw_assume_role.sh dev | grep source > assume_role.rc

                # Create the code bundle
                - export ENABLE_FEATURE_DEV=True
                - bash Deploy/Master/create-python-bundle --project OneView/API

                # Upload the code bundle
                - export AWS_S3_BUCKET='ama-dev-datalake-lambda-us-east-1'
                - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle OneView/API
        - parallel:
            # - step:
            #     name: Migrate Database
            #     caches:
            #       - environment-dev
            #     script:
            #     - bash Script/setup-virtual-environment Master/BitBucketPipelines
            #     - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
            #     - export PATH="$VIRTUAL_ENV/bin:$PATH"
            #     - bash Script/migrate-database --host $ONEVIEW_DATABASE_HOST_DEV --name oneview --username $ONEVIEW_DATABASE_USERNAME_DEV --password $ONEVIEW_DATABASE_PASSWORD_DEV upgrade OneView
            - step:
                name: Update Lambda Functions
                script:
                # Assume maintenance role
                - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
                - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
                - aws configure set profile.apigw.region us-east-1
                - aws configure set profile.apigw.output json
                - bash Script/apigw_assume_role.sh dev | grep source > assume_role.rc

                # Update Lambda functions
                - export ENABLE_FEATURE_DEV=True
                - export ENVIRONMENT=dev
                - bash --rcfile assume_role.rc -i Deploy/OneView/update-functions

        Organizations-dev:
        - step:
            name: Update ETL Bundle
            caches:
                - environment-dev
            script:
            # Setup virtual environment
            - bash Script/setup-virtual-environment Master/BitBucketPipelines
            - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
            - export PATH="$VIRTUAL_ENV/bin:$PATH"

            # Setup AWS CLI
            - export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID_SANDBOX
            - export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY_SANDBOX
            - export AWS_DEFAULT_REGION='us-east-1'

            # Install the SQL Server JDBC driver
            - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/SqlServerJdbcDriver.zip SqlServerJdbcDriver.zip
            - unzip ./SqlServerJdbcDriver.zip
            - mv sqljdbc_10.2\\enu/mssql-jdbc-10.2.0.jre8.jar mssql-jdbc-10.2.0.jre8.jar

            # Create the code bundle
            - export ENABLE_FEATURE_DEV=True
            - bash Deploy/Master/create-python-bundle --project CPT/Organizations -f mssql-jdbc-10.2.0.jre8.jar

            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh dev | grep source > assume_role.rc

            # Upload the code bundle
            - export AWS_S3_BUCKET='ama-dev-datalake-lambda-us-east-1'
            - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle IntelligentPlatform/OrganizationsETL
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh dev | grep source > assume_role.rc

            # Update Lambda functions
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s AIP -p IntelligentPlatform
                OrganizationsETL=OrganizationsETL.zip

        Scheduler-dev:
        - step:
            name: Update Bundle
            caches:
                - environment-dev
            script:
            # Setup virtual environment
            - bash Script/setup-virtual-environment Master/BitBucketPipelines
            - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
            - export PATH="${VIRTUAL_ENV}/bin:$PATH"

            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh dev | grep source > assume_role.rc

            # Create the code bundle
            - export ENABLE_FEATURE_DEV=True
            - bash Deploy/Master/create-python-bundle --project Scheduler

            # Upload the code bundle
            - export AWS_S3_BUCKET='ama-dev-datalake-lambda-us-east-1'
            - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle Scheduler
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh dev | grep source > assume_role.rc

            # Update Lambda functions
            - export ENABLE_FEATURE_DEV=True
            - export ENVIRONMENT=dev
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e dev -s DataLake
                Scheduler=Scheduler.zip
                DAGProcessor=Scheduler.zip
                TaskProcessor=Scheduler.zip


        ##############################################################
        # test branch targets
        ##############################################################

        AMC-test:
        - step:
            name: Update ETL Bundle
            caches:
            - environment-test
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment tst
                --project AMC
                --bundle Masterfile/AMC.zip
                --jdbc-driver Informix
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - export ENABLE_FEATURE_TEST=True
            - export ENVIRONMENT=tst
            - >-
                bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s OneView -p Masterfile
                AMC=AMC.zip

        CPT-API-Endpoint-test:
        - step:
            name: Update Bundle
            caches:
                - environment-test
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment tst
                --project CPT/API/Endpoint
                --bundle CPT/API/Endpoint.zip
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s CPT-API -p CPT/API
                Authorizer=Endpoint.zip
                Endpoint=Endpoint.zip
                BulkAuthorizer=Endpoint.zip
                BulkEndpoint=Endpoint.zip

        DBL-test:
        - step:
            name: Update ETL Bundle
            caches:
            - environment-test
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment tst
                --project DBL
                --bundle Masterfile/DBLReport.zip
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - export ENABLE_FEATURE_TEST=True
            - export ENVIRONMENT=tst
            - >-
                bash Deploy/Master/setup-aws-cli -e tst -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s OneView -p Masterfile
                DBLReport=DBLReport.zip

        OneView-test:
        - parallel:
            - step:
                name: Update ETL Bundle
                caches:
                    - environment-test
                script:
                # Setup virtual environment
                - bash Script/setup-virtual-environment Master/BitBucketPipelines
                - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
                - export PATH="$VIRTUAL_ENV/bin:$PATH"

                # Setup AWS CLI
                - export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID_SANDBOX
                - export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY_SANDBOX
                - export AWS_DEFAULT_REGION='us-east-1'

                # Install the DB2 JDBC driver
                - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/Db2JdbcDriver.zip Db2JdbcDriver.zip
                - unzip ./Db2JdbcDriver.zip

                # Install the Informix JDBC driver
                - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/InformixJdbcDriver.zip InformixJdbcDriver.zip
                - unzip ./InformixJdbcDriver.zip
                - echo "db2.jcc.charsetDecoderEncoder=3" >> ./DB2JccConfiguration.properties

                # Assume maintenance role
                - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
                - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
                - aws configure set profile.apigw.region us-east-1
                - aws configure set profile.apigw.output json
                - bash Script/apigw_assume_role.sh tst | grep source > assume_role.rc

                # Create the code bundle
                - export ENABLE_FEATURE_TEST=True
                - >-
                    bash Deploy/Master/create-python-bundle --project OneView/ETL
                    -f db2jcc4.jar -f DB2JccConfiguration.properties -f jdbc-4.50.4.1.jar -f bson-4.2.0.jar

                # Upload the code bundle
                - export AWS_S3_BUCKET='ama-tst-datalake-lambda-us-east-1'
                - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle OneView/ETL
            - step:
                name: Update API Bundle
                caches:
                    - environment-test
                script:
                # Setup virtual environment
                - bash Script/setup-virtual-environment Master/BitBucketPipelines
                - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
                - export PATH="$VIRTUAL_ENV/bin:$PATH"

                # Assume maintenance role
                - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
                - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
                - aws configure set profile.apigw.region us-east-1
                - aws configure set profile.apigw.output json
                - bash Script/apigw_assume_role.sh tst | grep source > assume_role.rc

                # Create the code bundle
                - export ENABLE_FEATURE_TEST=True
                - bash Deploy/Master/create-python-bundle --project OneView/API

                # Upload the code bundle
                - export AWS_S3_BUCKET='ama-tst-datalake-lambda-us-east-1'
                - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle OneView/API
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh tst | grep source > assume_role.rc

            # Update Lambda functions
            - export ENABLE_FEATURE_TEST=True
            - export ENVIRONMENT=tst
            - bash --rcfile assume_role.rc -i Deploy/OneView/update-functions

        Organizations-test:
        - step:
            name: Update ETL Bundle
            caches:
                - environment-test
            script:
            # Setup virtual environment
            - bash Script/setup-virtual-environment Master/BitBucketPipelines
            - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
            - export PATH="$VIRTUAL_ENV/bin:$PATH"

            # Setup AWS CLI
            - export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID_SANDBOX
            - export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY_SANDBOX
            - export AWS_DEFAULT_REGION='us-east-1'

            # Install the SQL Server JDBC driver
            - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/SqlServerJdbcDriver.zip SqlServerJdbcDriver.zip
            - unzip ./SqlServerJdbcDriver.zip
            - mv sqljdbc_10.2\\enu/mssql-jdbc-10.2.0.jre8.jar mssql-jdbc-10.2.0.jre8.jar

            # Create the code bundle
            - export ENABLE_FEATURE_TEST=True
            - bash Deploy/Master/create-python-bundle --project CPT/Organizations -f mssql-jdbc-10.2.0.jre8.jar

            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh tst | grep source > assume_role.rc

            # Upload the code bundle
            - export AWS_S3_BUCKET='ama-tst-datalake-lambda-us-east-1'
            - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle IntelligentPlatform/OrganizationsETL
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh tst | grep source > assume_role.rc

            # Update Lambda functions
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s AIP -p IntelligentPlatform
                OrganizationsETL=OrganizationsETL.zip

        Scheduler-test:
        - step:
            name: Update Bundle
            caches:
                - environment-test
            script:
            # Setup virtual environment
            - bash Script/setup-virtual-environment Master/BitBucketPipelines
            - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
            - export PATH="${VIRTUAL_ENV}/bin:$PATH"

            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh tst | grep source > assume_role.rc

            # Create the code bundle
            - export ENABLE_FEATURE_TEST=True
            - bash Deploy/Master/create-python-bundle --project Scheduler

            # Upload the code bundle
            - export AWS_S3_BUCKET='ama-tst-datalake-lambda-us-east-1'
            - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle Scheduler
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh tst | grep source > assume_role.rc

            # Update Lambda functions
            - export ENABLE_FEATURE_TEST=True
            - export ENVIRONMENT=tst
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e tst -s DataLake
                Scheduler=Scheduler.zip
                DAGProcessor=Scheduler.zip
                TaskProcessor=Scheduler.zip


        ##############################################################
        # stage branch targets
        ##############################################################

        CPT-API-Endpoint-stage:
        - step:
            name: Update Bundle
            caches:
                - environment-stage
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e itg -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment itg
                --project CPT/API/Endpoint
                --bundle CPT/API/Endpoint.zip
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e itg -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e itg -s CPT-API -p CPT/API
                Authorizer=Endpoint.zip
                Endpoint=Endpoint.zip
                BulkAuthorizer=Endpoint.zip
                BulkEndpoint=Endpoint.zip

        Scheduler-stage:
        - step:
            name: Update Bundle
            caches:
                - environment-stage
            script:
            # Setup virtual environment
            - bash Script/setup-virtual-environment Master/BitBucketPipelines
            - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
            - export PATH="${VIRTUAL_ENV}/bin:$PATH"

            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

            # Create the code bundle
            - export ENABLE_FEATURE_STAGE=True
            - bash Deploy/Master/create-python-bundle --project Scheduler

            # Upload the code bundle
            - export AWS_S3_BUCKET='ama-itg-datalake-lambda-us-east-1'
            - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle Scheduler
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

            # Update Lambda functions
            - export ENABLE_FEATURE_STAGE=True
            - export ENVIRONMENT=itg
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e itg -s DataLake
                Scheduler=Scheduler.zip
                DAGProcessor=Scheduler.zip
                TaskProcessor=Scheduler.zip


        ##############################################################
        # prod branch targets
        ##############################################################

        AMC-prod:
        - step:
            name: Update ETL Bundle
            caches:
            - environment-prod
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment prd
                --project AMC
                --bundle Masterfile/AMC.zip
                --jdbc-driver Informix
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - export ENABLE_FEATURE_PROD=True
            - export ENVIRONMENT=prd
            - >-
                bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s OneView -p Masterfile
                AMC=AMC.zip

        CPT-API-Endpoint-production:
        - step:
            name: Update Bundle
            caches:
                - environment-prod
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment prd
                --project CPT/API/Endpoint
                --bundle CPT/API/Endpoint.zip
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s CPT-API -p CPT/API
                Authorizer=Endpoint.zip
                Endpoint=Endpoint.zip
                BulkAuthorizer=Endpoint.zip
                BulkEndpoint=Endpoint.zip

        DBL-prod:
        - step:
            name: Update ETL Bundle
            caches:
            - environment-prod
            script:
            - >-
                bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/deploy-lambda-function
                --environment prd
                --project DBL
                --bundle Masterfile/DBLReport.zip
                --use-package
        - step:
            name: Update Lambda Functions
            script:
            - export ENABLE_FEATURE_PROD=True
            - export ENVIRONMENT=prd
            - >-
                bash Deploy/Master/setup-aws-cli -e prd -i $AWS_ACCESS_KEY_ID_SANDBOX -s $AWS_SECRET_ACCESS_KEY_SANDBOX
                -I $AWS_ACCESS_KEY_ID_APIGW -S $AWS_SECRET_ACCESS_KEY_APIGW
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s OneView -p Masterfile
                DBLReport=DBLReport.zip

        OneView-prod:
        - step:
            name: Send Deployment Request
            script:
            - echo "A OneView deployment has been triggered via BitBucket Pipelines. Please run the OneView-production target if you approve."

        OneView-production:
        - parallel:
            - step:
                name: Update ETL Bundle
                caches:
                    - environment-prod
                script:
                # Setup virtual environment
                - bash Script/setup-virtual-environment Master/BitBucketPipelines
                - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
                - export PATH="$VIRTUAL_ENV/bin:$PATH"

                # Setup AWS CLI
                - export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID_SANDBOX
                - export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY_SANDBOX
                - export AWS_DEFAULT_REGION='us-east-1'

                # Install the DB2 JDBC driver
                - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/Db2JdbcDriver.zip Db2JdbcDriver.zip
                - unzip ./Db2JdbcDriver.zip

                # Install the Informix JDBC driver
                - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/InformixJdbcDriver.zip InformixJdbcDriver.zip
                - unzip ./InformixJdbcDriver.zip
                - echo "db2.jcc.charsetDecoderEncoder=3" >> ./DB2JccConfiguration.properties

                # Assume maintenance role
                - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
                - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
                - aws configure set profile.apigw.region us-east-1
                - aws configure set profile.apigw.output json
                - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

                # Create the code bundle
                - export ENABLE_FEATURE_PROD=True
                - >-
                    bash Deploy/Master/create-python-bundle --project OneView/ETL
                    -f db2jcc4.jar -f DB2JccConfiguration.properties -f jdbc-4.50.4.1.jar -f bson-4.2.0.jar

                # Upload the code bundle
                - export AWS_S3_BUCKET='ama-prd-datalake-lambda-us-east-1'
                - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle OneView/ETL
            - step:
                name: Update API Bundle
                caches:
                    - environment-prod
                script:
                # Setup virtual environment
                - bash Script/setup-virtual-environment Master/BitBucketPipelines
                - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
                - export PATH="$VIRTUAL_ENV/bin:$PATH"

                # Assume maintenance role
                - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
                - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
                - aws configure set profile.apigw.region us-east-1
                - aws configure set profile.apigw.output json
                - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

                # Create the code bundle
                - export ENABLE_FEATURE_PROD=True
                - bash Deploy/Master/create-python-bundle --project OneView/API

                # Upload the code bundle
                - export AWS_S3_BUCKET='ama-prd-datalake-lambda-us-east-1'
                - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle OneView/API
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

            # Update Lambda functions
            - export ENABLE_FEATURE_PROD=True
            - export ENVIRONMENT=prd
            - bash --rcfile assume_role.rc -i Deploy/OneView/update-functions

        Organizations-prod:
        - step:
            name: Send Deployment Request
            script:
            - echo "A Organizations deployment has been triggered via BitBucket Pipelines. Please run the Organizations-production target if you approve."

        Organizations-production:
        - step:
            name: Update ETL Bundle
            caches:
                - environment-prod
            script:
            # Setup virtual environment
            - bash Script/setup-virtual-environment Master/BitBucketPipelines
            - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
            - export PATH="$VIRTUAL_ENV/bin:$PATH"

            # Setup AWS CLI
            - export AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID_SANDBOX
            - export AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY_SANDBOX
            - export AWS_DEFAULT_REGION='us-east-1'

            # Install the SQL Server JDBC driver
            - aws s3 cp s3://ama-sbx-datalake-lambda-us-east-1/JDBC/SqlServerJdbcDriver.zip SqlServerJdbcDriver.zip
            - unzip ./SqlServerJdbcDriver.zip
            - mv sqljdbc_10.2\\enu/mssql-jdbc-10.2.0.jre8.jar mssql-jdbc-10.2.0.jre8.jar

            # Create the code bundle
            - export ENABLE_FEATURE_PROD=True
            - bash Deploy/Master/create-python-bundle --project CPT/Organizations -f mssql-jdbc-10.2.0.jre8.jar

            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

            # Upload the code bundle
            - export AWS_S3_BUCKET='ama-prd-datalake-lambda-us-east-1'
            - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle IntelligentPlatform/OrganizationsETL
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

            # Update Lambda functions
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s AIP -p IntelligentPlatform
                OrganizationsETL=OrganizationsETL.zip

        Scheduler-prod:
        - step:
            name: Send Deployment Request
            script:
            - echo "A Scheduler deployment has been triggered via BitBucket Pipelines. Please run the Scheduler-production target if you approve."

        Scheduler-production:
        - step:
            name: Update Bundle
            caches:
                - environment-prod
            script:
            # Setup virtual environment
            - bash Script/setup-virtual-environment Master/BitBucketPipelines
            - export VIRTUAL_ENV=${PWD}/Environment/Master/BitBucketPipelines
            - export PATH="${VIRTUAL_ENV}/bin:$PATH"

            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

            # Create the code bundle
            - export ENABLE_FEATURE_PROD=True
            - bash Deploy/Master/create-python-bundle --project Scheduler

            # Upload the code bundle
            - export AWS_S3_BUCKET='ama-prd-datalake-lambda-us-east-1'
            - bash --rcfile assume_role.rc -i Deploy/Master/upload-python-bundle Scheduler
        - step:
            name: Update Lambda Functions
            script:
            # Assume maintenance role
            - aws configure set profile.apigw.aws_access_key_id $AWS_ACCESS_KEY_ID_APIGW
            - aws configure set profile.apigw.aws_secret_access_key $AWS_SECRET_ACCESS_KEY_APIGW
            - aws configure set profile.apigw.region us-east-1
            - aws configure set profile.apigw.output json
            - bash Script/apigw_assume_role.sh prd | grep source > assume_role.rc

            # Update Lambda functions
            - export ENABLE_FEATURE_PROD=True
            - export ENVIRONMENT=prd
            - >-
                bash --rcfile assume_role.rc -i Deploy/Master/update-functions -e prd -s DataLake
                Scheduler=Scheduler.zip
                DAGProcessor=Scheduler.zip
                TaskProcessor=Scheduler.zip

definitions:
  caches:
    build-dependencies: Environment
    test-dependencies: Environment

    environment-master: Environment
    environment-dev: Environment
    environment-test: Environment
    environment-stage: Environment
    environment-prod: Environment
