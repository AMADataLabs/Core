{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from auth import username, password\n",
    "import pgeocode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Connect to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"DSN=PRDDW; UID={}; PWD={}\".format(username, password)\n",
    "AMAEDW = pyodbc.connect(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read in all latest insurance addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query = \\\n",
    "    \"\"\" \n",
    "    SELECT DISTINCT\n",
    "    A.PARTY_ID, \n",
    "    K.KEY_VAL AS ME, \n",
    "    A.POST_CD_ID,\n",
    "    A.FROM_DT,\n",
    "    C.PURPOSE_TYPE_DESC AS ADDR_TYPE, \n",
    "    P.ADDR_1, \n",
    "    P.ADDR_2, \n",
    "    P.ADDR_3, \n",
    "    P.CITY, \n",
    "    S.SRC_STATE_CD AS STATE_CD, \n",
    "    P.POST_CD AS ZIP\n",
    "    FROM \n",
    "    AMAEDW.PARTY_KEY K, AMAEDW.PARTY_ADDR A, AMAEDW.CONT_PURPOSE_TYPE C, AMAEDW.POST_CD P, AMAEDW.STATE S \n",
    "    WHERE  \n",
    "    A.THRU_DT IS NULL\n",
    "    AND\n",
    "    K.PARTY_ID = A.PARTY_ID \n",
    "    AND \n",
    "    K.KEY_TYPE_ID = 18 \n",
    "    AND \n",
    "    K.ACTIVE_IND = 'Y'\n",
    "    AND\n",
    "    C.PURPOSE_TYPE_ID IN (1)\n",
    "    AND\n",
    "    A.POST_CD_ID = P.POST_CD_ID \n",
    "    AND\n",
    "    P.STATE_ID = S.STATE_ID\n",
    "    ORDER BY A.FROM_DT DESC;\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14092157, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARTY_ID</th>\n",
       "      <th>ME</th>\n",
       "      <th>POST_CD_ID</th>\n",
       "      <th>FROM_DT</th>\n",
       "      <th>ADDR_TYPE</th>\n",
       "      <th>ADDR_1</th>\n",
       "      <th>ADDR_2</th>\n",
       "      <th>ADDR_3</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE_CD</th>\n",
       "      <th>ZIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2285633</td>\n",
       "      <td>03509902011</td>\n",
       "      <td>11139370</td>\n",
       "      <td>2019-10-28 00:15:23</td>\n",
       "      <td>Billing</td>\n",
       "      <td>703 E Marshall Ave Ste 5008</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Longview</td>\n",
       "      <td>TX</td>\n",
       "      <td>75601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2306701</td>\n",
       "      <td>03979820037</td>\n",
       "      <td>14853676</td>\n",
       "      <td>2019-10-28 00:15:23</td>\n",
       "      <td>Billing</td>\n",
       "      <td>5344 S Kenwood Dr</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Salt Lake Cty</td>\n",
       "      <td>UT</td>\n",
       "      <td>84107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6091054</td>\n",
       "      <td>03701150294</td>\n",
       "      <td>16384777</td>\n",
       "      <td>2019-10-28 00:15:23</td>\n",
       "      <td>Billing</td>\n",
       "      <td>1301 8th St S</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Moorhead</td>\n",
       "      <td>MN</td>\n",
       "      <td>56560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4834079</td>\n",
       "      <td>05107110102</td>\n",
       "      <td>16407225</td>\n",
       "      <td>2019-10-28 00:15:23</td>\n",
       "      <td>Billing</td>\n",
       "      <td>1406 6th Ave N</td>\n",
       "      <td>St. Cloud Hospital</td>\n",
       "      <td></td>\n",
       "      <td>Saint Cloud</td>\n",
       "      <td>MN</td>\n",
       "      <td>56303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6674375</td>\n",
       "      <td>02608170238</td>\n",
       "      <td>22162877</td>\n",
       "      <td>2019-10-28 00:15:23</td>\n",
       "      <td>Billing</td>\n",
       "      <td>200 Bunker Hill Dr</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Aitkin</td>\n",
       "      <td>MN</td>\n",
       "      <td>56431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PARTY_ID           ME  POST_CD_ID             FROM_DT ADDR_TYPE  \\\n",
       "0   2285633  03509902011    11139370 2019-10-28 00:15:23   Billing   \n",
       "1   2306701  03979820037    14853676 2019-10-28 00:15:23   Billing   \n",
       "2   6091054  03701150294    16384777 2019-10-28 00:15:23   Billing   \n",
       "3   4834079  05107110102    16407225 2019-10-28 00:15:23   Billing   \n",
       "4   6674375  02608170238    22162877 2019-10-28 00:15:23   Billing   \n",
       "\n",
       "                        ADDR_1              ADDR_2 ADDR_3  \\\n",
       "0  703 E Marshall Ave Ste 5008                              \n",
       "1            5344 S Kenwood Dr                              \n",
       "2                1301 8th St S                              \n",
       "3               1406 6th Ave N  St. Cloud Hospital          \n",
       "4           200 Bunker Hill Dr                              \n",
       "\n",
       "                           CITY STATE_CD         ZIP  \n",
       "0  Longview                           TX  75601       \n",
       "1  Salt Lake Cty                      UT  84107       \n",
       "2  Moorhead                           MN  56560       \n",
       "3  Saint Cloud                        MN  56303       \n",
       "4  Aitkin                             MN  56431       "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance = pd.read_sql(con=AMAEDW, sql=sql_query)\n",
    "insurance = insurance.drop_duplicates(subset = 'PARTY_ID', keep='first')\n",
    "print(insurance.shape)\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_2 = insurance.drop_duplicates(subset = 'PARTY_ID', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read all latest PPMA & POLO addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_PPMA = \\\n",
    "    '''\n",
    "    SELECT DISTINCT \n",
    "    A.PARTY_ID, \n",
    "    A.POST_CD_ID,\n",
    "    P.ADDR_1, \n",
    "    P.ADDR_2, \n",
    "    P.ADDR_3, \n",
    "    P.CITY, \n",
    "    S.SRC_STATE_CD AS STATE_CD, \n",
    "    P.POST_CD AS ZIP,\n",
    "    A.FROM_DT\n",
    "    FROM \n",
    "    AMAEDW.POST_CD P, AMAEDW.STATE S , AMAEDW.PARTY_ADDR A, AMAEDW.CONT_PURPOSE_TYPE C\n",
    "    WHERE \n",
    "    A.PURPOSE_TYPE_ID=C.PURPOSE_TYPE_ID\n",
    "    AND\n",
    "    K.PARTY_ID = A.PARTY_ID \n",
    "    AND\n",
    "    C.PURPOSE_CAT_CD='A'\n",
    "    AND\n",
    "    C.PURPOSE_USG_CD='PP'\n",
    "    AND\n",
    "    A.POST_CD_ID = P.POST_CD_ID \n",
    "    AND\n",
    "    P.STATE_ID = S.STATE_ID\n",
    "    AND \n",
    "    A.THRU_DT IS NULL\n",
    "    ORDER BY A.FROM_DT DESC\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPMA = pd.read_sql(con=AMAEDW, sql=sql_query_PPMA)\n",
    "print(PPMA.shape)\n",
    "PPMA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_query_POLO = \\\n",
    "    '''\n",
    "    SELECT DISTINCT \n",
    "    A.PARTY_ID, \n",
    "    A.POST_CD_ID,\n",
    "    P.ADDR_1, \n",
    "    P.ADDR_2, \n",
    "    P.ADDR_3, \n",
    "    P.CITY, \n",
    "    S.SRC_STATE_CD AS STATE_CD, \n",
    "    P.POST_CD AS ZIP,\n",
    "    A.FROM_DT,\n",
    "    P.SRC_POST_KEY AS POST_KEY,\n",
    "    K.KEY_VAL AS ME\n",
    "    FROM \n",
    "    AMAEDW.POST_CD P, AMAEDW.STATE S , AMAEDW.PARTY_ADDR A, AMAEDW.CONT_PURPOSE_TYPE C\n",
    "    WHERE \n",
    "    A.PURPOSE_TYPE_ID=C.PURPOSE_TYPE_ID\n",
    "    AND\n",
    "    C.PURPOSE_CAT_CD='A'\n",
    "    AND\n",
    "    C.PURPOSE_USG_CD='PO'\n",
    "    AND\n",
    "    A.POST_CD_ID = P.POST_CD_ID \n",
    "    AND\n",
    "    P.STATE_ID = S.STATE_ID\n",
    "    AND \n",
    "    A.THRU_DT IS NULL\n",
    "    ORDER BY A.FROM_DT DESC\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLO = pd.read_sql(con=AMAEDW, sql=sql_query_POLO)\n",
    "print(POLO.shape)\n",
    "POLO.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLO = POLO.drop_duplicates(subset = 'PARTY_ID', keep='first')\n",
    "print(POLO.shape)\n",
    "PPMA= PPMA.drop_duplicates(subset = 'PARTY_ID', keep='first')\n",
    "print(PPMA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Read latest PPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"..\\PhysicianProfessionalDataFile_20191012_062051504\"\n",
    "cols = [\n",
    "        'ME',\n",
    "        'RECORD_ID',\n",
    "        'UPDATE_TYPE',\n",
    "        'ADDRESS_TYPE',\n",
    "        'MAILING_NAME',\n",
    "        'LAST_NAME',\n",
    "        'FIRST_NAME',\n",
    "        'MIDDLE_NAME',\n",
    "        'SUFFIX',\n",
    "        'MAILING_LINE_1',\n",
    "        'MAILING_LINE_2',\n",
    "        'CITY',\n",
    "        'STATE',\n",
    "        'ZIP',\n",
    "        'SECTOR',\n",
    "        'CARRIER_ROUTE',\n",
    "        'ADDRESS_UNDELIVERABLE_FLAG',\n",
    "        'FIPS_COUNTY',\n",
    "        'FIPS_STATE',\n",
    "        'PRINTER_CONTROL_CODE',\n",
    "        'PC_ZIP',\n",
    "        'PC_SECTOR',\n",
    "        'DELIVERY_POINT_CODE',\n",
    "        'CHECK_DIGIT',\n",
    "        'PRINTER_CONTROL_CODE_2',\n",
    "        'REGION',\n",
    "        'DIVISION',\n",
    "        'GROUP',\n",
    "        'TRACT',\n",
    "        'SUFFIX_CENSUS',\n",
    "        'BLOCK_GROUP',\n",
    "        'MSA_POPULATION_SIZE',\n",
    "        'MICRO_METRO_IND',\n",
    "        'CBSA',\n",
    "        'CBSA_DIV_IND',\n",
    "        'MD_DO_CODE',\n",
    "        'BIRTH_YEAR',\n",
    "        'BIRTH_CITY',\n",
    "        'BIRTH_STATE',\n",
    "        'BIRTH_COUNTRY',\n",
    "        'GENDER',\n",
    "        'TELEPHONE_NUMBER',\n",
    "        'PRESUMED_DEAD_FLAG',\n",
    "        'FAX_NUMBER',\n",
    "        'TOP_CD',\n",
    "        'PE_CD',\n",
    "        'PRIM_SPEC_CD',\n",
    "        'SEC_SPEC_CD',\n",
    "        'MPA_CD',\n",
    "        'PRA_RECIPIENT',\n",
    "        'PRA_EXP_DT',\n",
    "        'GME_CONF_FLG',\n",
    "        'FROM_DT',\n",
    "        'TO_DT',\n",
    "        'YEAR_IN_PROGRAM',\n",
    "        'POST_GRADUATE_YEAR',\n",
    "        'GME_SPEC_1',\n",
    "        'GME_SPEC_2',\n",
    "        'TRAINING_TYPE',\n",
    "        'GME_INST_STATE',\n",
    "        'GME_INST_ID',\n",
    "        'MEDSCHOOL_STATE',\n",
    "        'MEDSCHOOL_ID',\n",
    "        'MEDSCHOOL_GRAD_YEAR',\n",
    "        'NO_CONTACT_IND',\n",
    "        'NO_WEB_FLAG',\n",
    "        'PDRP_FLAG',\n",
    "        'PDRP_START_DT',\n",
    "        'POLO_MAILING_LINE_1',\n",
    "        'POLO_MAILING_LINE_2',\n",
    "        'POLO_CITY',\n",
    "        'POLO_STATE',\n",
    "        'POLO_ZIP',\n",
    "        'POLO_SECTOR',\n",
    "        'POLO_CARRIER_ROUTE',\n",
    "        'MOST_RECENT_FORMER_LAST_NAME',\n",
    "        'MOST_RECENT_FORMER_MIDDLE_NAME',\n",
    "        'MOST_RECENT_FORMER_FIRST_NAME',\n",
    "        'NEXT_MOST_RECENT_FORMER_LAST',\n",
    "        'NEXT_MOST_RECENT_FORMER_MIDDLE',\n",
    "        'NEXT_MOST_RECENT_FORMER_FIRST'\n",
    "    ]\n",
    "ppd = pd.read_csv(path, names=cols, sep='|', encoding='IBM437', index_col=False, dtype=object)\n",
    "PPD = ppd[['ME','MAILING_NAME', 'FIRST_NAME', 'LAST_NAME', 'MIDDLE_NAME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Merge PPMA, POLO, PPD, and Insurance by ME and PARTY_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppma_polo = pd.merge(PPMA, POLO, on = 'PARTY_ID', how= 'outer', suffixes = ('_PPMA', '_POLO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_insurance_2 = pd.merge(insurance_2, PPD, on = 'ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSURANCE_2 = ppd_insurance_2.drop(columns=['PARTY_ID','ME', 'POST_CD_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSURANCE_2.to_csv('insurance_current.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSURANCE.to_csv('insurance_historical.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_insurance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_polo = pd.merge(ppd_insurance, POLO, on = 'PARTY_ID', suffixes = ('_insurance', '_POLO'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_ppma = pd.merge(ppd_insurance, PPMA, on = 'PARTY_ID', suffixes = ('_insurance', '_PPMA'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_ppma_polo = pd.merge(ppd_insurance, ppma_polo, on = 'PARTY_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_ppma_polo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_ppma_polo = insurance_ppma_polo.drop_duplicates(subset = 'PARTY_ID', keep='first')\n",
    "print(insurance_ppma_polo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Summarize the address differences and generate a table of mismat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define summarizing function (PPMA)\n",
    "def sum_it_up_ppma(df):\n",
    "    count =0 \n",
    "    add_count = 0\n",
    "    zip_count = 0\n",
    "    state_count = 0\n",
    "    cd_count  =0 \n",
    "    dict_list = []\n",
    "    date_count = 0\n",
    "    city_count = 0\n",
    "    for row in df.itertuples():\n",
    "        count += 1\n",
    "        if row.FROM_DT_insurance > row.FROM_DT_PPMA:\n",
    "            if row.POST_CD_ID_PPMA != row.POST_CD_ID_insurance:\n",
    "                cd_count +=1\n",
    "            \n",
    "                new_dict = {}\n",
    "                new_dict['ME'] = row.ME\n",
    "                new_dict['ADDR_1_insurance'] = row.ADDR_1_insurance\n",
    "                new_dict['ADDR_1_PPMA'] = row.ADDR_1_PPMA\n",
    "                new_dict['ADDR_2_insurance'] = row.ADDR_2_insurance\n",
    "                new_dict['ADDR_2_PPMA'] = row.ADDR_2_PPMA\n",
    "                new_dict['ADDR_3_insurance'] = row.ADDR_3_insurance\n",
    "                new_dict['ADDR_3_PPMA'] = row.ADDR_3_PPMA\n",
    "                new_dict['ZIP_insurance'] = row.ZIP_insurance\n",
    "                new_dict['ZIP_PPMA'] = row.ZIP_PPMA\n",
    "                new_dict['CITY_insurance'] = row.CITY_insurance\n",
    "                new_dict['CITY_PPMA'] = row.CITY_PPMA\n",
    "                new_dict['DATE_insurance'] = row.FROM_DT_insurance\n",
    "                new_dict['DATE_PPMA'] = row.FROM_DT_PPMA\n",
    "                new_dict['STATE_insurance'] = row.STATE_CD_insurance\n",
    "                new_dict['STATE_PPMA'] = row.STATE_CD_PPMA\n",
    "                dict_list.append(new_dict)\n",
    "\n",
    "    print(f'''\n",
    "    {cd_count/count * 100}% ({cd_count}) POST_CD_IDs do not match \n",
    "    ''')\n",
    "    return(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define summarizing function (POLO)\n",
    "def sum_it_up_polo(df):\n",
    "    count =0 \n",
    "    add_count = 0\n",
    "    zip_count = 0\n",
    "    state_count = 0\n",
    "    cd_count  =0 \n",
    "    dict_list = []\n",
    "    date_count = 0\n",
    "    city_count = 0\n",
    "    for row in df.itertuples():\n",
    "        count += 1\n",
    "        if row.FROM_DT_insurance > row.FROM_DT_POLO:\n",
    "            if row.POST_CD_ID_POLO == row.POST_CD_ID_insurance:\n",
    "                cd_count +=1\n",
    "            \n",
    "                new_dict = {}\n",
    "                new_dict['ME'] = row.ME\n",
    "                new_dict['ADDR_1_insurance'] = row.ADDR_1_insurance\n",
    "                new_dict['ADDR_1_POLO'] = row.ADDR_1_POLO\n",
    "                new_dict['ADDR_2_insurance'] = row.ADDR_2_insurance\n",
    "                new_dict['ADDR_2_POLO'] = row.ADDR_2_POLO\n",
    "                new_dict['ADDR_3_insurance'] = row.ADDR_3_insurance\n",
    "                new_dict['ADDR_3_POLO'] = row.ADDR_3_POLO\n",
    "                new_dict['ZIP_insurance'] = row.ZIP_insurance\n",
    "                new_dict['ZIP_POLO'] = row.ZIP_POLO\n",
    "                new_dict['CITY_insurance'] = row.CITY_insurance\n",
    "                new_dict['CITY_POLO'] = row.CITY_POLO\n",
    "                new_dict['DATE_insurance'] = row.FROM_DT_insurance\n",
    "                new_dict['DATE_POLO'] = row.FROM_DT_POLO\n",
    "                new_dict['STATE_insurance'] = row.STATE_CD_insurance\n",
    "                new_dict['STATE_POLO'] = row.STATE_CD_POLO\n",
    "                dict_list.append(new_dict)\n",
    "\n",
    "    print(f'''\n",
    "    {cd_count/count * 100}% ({cd_count}) POST_CD_IDs match \n",
    "    ''')\n",
    "    return(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define summarizing function (ALL)\n",
    "def sum_it_up(df):\n",
    "    count =0 \n",
    "    add_count = 0\n",
    "    zip_count = 0\n",
    "    state_count = 0\n",
    "    cd_count  =0 \n",
    "    dict_list = []\n",
    "    date_count = 0\n",
    "    city_count = 0\n",
    "    for row in df.itertuples():\n",
    "        count += 1\n",
    "        if row.FROM_DT > row.FROM_DT_PPMA and row.FROM_DT > row.FROM_DT_POLO:\n",
    "            if row.POST_CD_ID_POLO != row.POST_CD_ID and row.POST_CD_ID != row.POST_CD_ID_PPMA:\n",
    "                cd_count +=1\n",
    "            \n",
    "                new_dict = {}\n",
    "                new_dict['ME'] = row.ME\n",
    "                new_dict['ADDR_1_insurance'] = row.ADDR_1\n",
    "                new_dict['ADDR_1_POLO'] = row.ADDR_1_POLO\n",
    "                new_dict['ADDR_1_PPMA'] = row.ADDR_1_PPMA\n",
    "                new_dict['ADDR_2_insurance'] = row.ADDR_2\n",
    "                new_dict['ADDR_2_POLO'] = row.ADDR_2_POLO\n",
    "                new_dict['ADDR_2_PPMA'] = row.ADDR_2_PPMA\n",
    "                new_dict['ADDR_3_insurance'] = row.ADDR_3\n",
    "                new_dict['ADDR_3_POLO'] = row.ADDR_3_POLO\n",
    "                new_dict['ADDR_3_PPMA'] = row.ADDR_3_PPMA\n",
    "                new_dict['ZIP_insurance'] = row.ZIP\n",
    "                new_dict['ZIP_POLO'] = row.ZIP_POLO\n",
    "                new_dict['ZIP_PPMA'] = row.ZIP_PPMA\n",
    "                new_dict['CITY_insurance'] = row.CITY\n",
    "                new_dict['CITY_POLO'] = row.CITY_POLO\n",
    "                new_dict['CITY_PPMA'] = row.CITY_PPMA\n",
    "                new_dict['DATE_insurance'] = row.FROM_DT\n",
    "                new_dict['DATE_POLO'] = row.FROM_DT_POLO\n",
    "                new_dict['DATE_PPMA'] = row.FROM_DT_PPMA\n",
    "                new_dict['STATE_insurance'] = row.STATE_CD\n",
    "                new_dict['STATE_POLO'] = row.STATE_CD_POLO\n",
    "                new_dict['STATE_PPMA'] = row.STATE_CD_PPMA\n",
    "                dict_list.append(new_dict)\n",
    "\n",
    "                if row.ADDR_1 != row.ADDR_1_PPMA and row.ADDR_1 != row.ADDR_1_POLO:\n",
    "                    add_count +=1\n",
    "                if row.CITY != row.CITY_PPMA and row.CITY != row.CITY_POLO:\n",
    "                    city_count +=1\n",
    "                if row.ZIP != row.ZIP_PPMA and row.ZIP != row.ZIP_POLO:\n",
    "                    zip_count +=1\n",
    "                if row.STATE_CD != row.STATE_CD_PPMA and row.STATE_CD != row.STATE_CD_POLO:\n",
    "                    state_count +=1\n",
    "    print(f'''\n",
    "    {cd_count/count * 100}% ({cd_count}) POST_CD_IDs do not match \n",
    "    {add_count/cd_count*100}% ({add_count}) addresses do not match\n",
    "    {zip_count/cd_count * 100}% ({zip_count})zipcodes do not match\n",
    "    {state_count/cd_count * 100}% ({state_count})states do not match\n",
    "    {city_count/cd_count * 100}% ({city_count})cities do not match\n",
    "    ''')\n",
    "    return(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_mismatch = sum_it_up(insurance_ppma_polo)\n",
    "insurance_mismatch_df = pd.DataFrame(insurance_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polo_match = sum_it_up_polo(insurance_polo)\n",
    "polo_match_df = pd.DataFrame(polo_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppma_mismatch = sum_it_up_ppma(insurance_ppma)\n",
    "ppma_mismatch_df = pd.DataFrame(ppma_mismatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(ppma_match_df, polo_match_df, on = ['ME','ADDR_1_insurance','ADDR_2_insurance','ADDR_3_insurance', 'CITY_insurance', 'DATE_insurance', 'STATE_insurance', 'ZIP_insurance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define summarizing function\n",
    "def narrow_it_down(df, address_type):\n",
    "    dict_list = []\n",
    "    for row in df.itertuples():\n",
    "        if address_type == 'PPMA'\n",
    "            if row.STATE_insurance != row.STATE_PPMA:\n",
    "                if row.CITY_insurance != row.CITY_PPMA:\n",
    "                    if row.ADDR_1_insurance != row.ADDR_1_PPMA:\n",
    "                        if row.ZIP_insurance != row.ZIP_PPMA:\n",
    "                            new_dict = {}\n",
    "                            new_dict['ME'] = row.ME\n",
    "                            new_dict['ADDR_1_insurance'] = row.ADDR_1_insurance\n",
    "\n",
    "                            new_dict['ADDR_1_PPMA'] = row.ADDR_1_PPMA\n",
    "                            new_dict['ADDR_2_insurance'] = row.ADDR_2_insurance\n",
    "\n",
    "                            new_dict['ADDR_2_PPMA'] = row.ADDR_2_PPMA\n",
    "                            new_dict['ADDR_3_insurance'] = row.ADDR_3_insurance\n",
    "\n",
    "                            new_dict['ADDR_3_PPMA'] = row.ADDR_3_PPMA\n",
    "                            new_dict['ZIP_insurance'] = row.ZIP_insurance\n",
    "\n",
    "                            new_dict['ZIP_PPMA'] = row.ZIP_PPMA\n",
    "                            new_dict['CITY_insurance'] = row.CITY_insurance\n",
    "\n",
    "                            new_dict['CITY_PPMA'] = row.CITY_PPMA\n",
    "                            new_dict['DATE_insurance'] = row.DATE_insurance\n",
    "\n",
    "                            new_dict['DATE_PPMA'] = row.DATE_PPMA\n",
    "                            new_dict['STATE_insurance'] = row.STATE_insurance\n",
    "\n",
    "                            new_dict['STATE_PPMA'] = row.STATE_PPMA\n",
    "                            dict_list.append(new_dict)\n",
    "                            \n",
    "        if address_type == 'POLO'\n",
    "            if row.STATE_insurance != row.STATE_POLO:\n",
    "                if row.CITY_insurance != row.CITY_POLO:\n",
    "                    if row.ADDR_1_insurance != row.ADDR_1_POLO:\n",
    "                        if row.ZIP_insurance != row.ZIP_POLO:\n",
    "                            new_dict = {}\n",
    "                            new_dict['ME'] = row.ME\n",
    "                            new_dict['ADDR_1_insurance'] = row.ADDR_1_insurance\n",
    "\n",
    "                            new_dict['ADDR_1_POLO'] = row.ADDR_1_POLO\n",
    "                            new_dict['ADDR_2_insurance'] = row.ADDR_2_insurance\n",
    "\n",
    "                            new_dict['ADDR_2_POLO'] = row.ADDR_2_POLO\n",
    "                            new_dict['ADDR_3_insurance'] = row.ADDR_3_insurance\n",
    "\n",
    "                            new_dict['ADDR_3_POLO'] = row.ADDR_3_POLO\n",
    "                            new_dict['ZIP_insurance'] = row.ZIP_insurance\n",
    "\n",
    "                            new_dict['ZIP_POLO'] = row.ZIP_POLO\n",
    "                            new_dict['CITY_insurance'] = row.CITY_insurance\n",
    "\n",
    "                            new_dict['CITY_POLO'] = row.CITY_POLO\n",
    "                            new_dict['DATE_insurance'] = row.DATE_insurance\n",
    "\n",
    "                            new_dict['DATE_POLO'] = row.DATE_POLO\n",
    "                            new_dict['STATE_insurance'] = row.STATE_insurance\n",
    "\n",
    "                            new_dict['STATE_POLO'] = row.STATE_POLO\n",
    "                            dict_list.append(new_dict)          \n",
    "    NEW_DF=pd.DataFrame(dict_list)\n",
    "    return(NEW_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define summarizing function\n",
    "def narrow_it_down(df):\n",
    "    dict_list = []\n",
    "    for row in df.itertuples():\n",
    "        if row.STATE_insurance != row.STATE_PPMA and row.STATE_insurance != row.STATE_POLO:\n",
    "            if row.CITY_insurance != row.CITY_PPMA and row.CITY_insurance != row.CITY_POLO:\n",
    "                if row.ADDR_1_insurance != row.ADDR_1_PPMA and row.ADDR_1_insurance != row.ADDR_1_POLO:\n",
    "                    if row.ZIP_insurance != row.ZIP_PPMA and row.ZIP_insurance != row.ZIP_POLO:\n",
    "                        new_dict = {}\n",
    "                        new_dict['ME'] = row.ME\n",
    "                        new_dict['ADDR_1_insurance'] = row.ADDR_1_insurance\n",
    "                        new_dict['ADDR_1_POLO'] = row.ADDR_1_POLO\n",
    "                        new_dict['ADDR_1_PPMA'] = row.ADDR_1_PPMA\n",
    "                        new_dict['ADDR_2_insurance'] = row.ADDR_2_insurance\n",
    "                        new_dict['ADDR_2_POLO'] = row.ADDR_2_POLO\n",
    "                        new_dict['ADDR_2_PPMA'] = row.ADDR_2_PPMA\n",
    "                        new_dict['ADDR_3_insurance'] = row.ADDR_3_insurance\n",
    "                        new_dict['ADDR_3_POLO'] = row.ADDR_3_POLO\n",
    "                        new_dict['ADDR_3_PPMA'] = row.ADDR_3_PPMA\n",
    "                        new_dict['ZIP_insurance'] = row.ZIP_insurance\n",
    "                        new_dict['ZIP_POLO'] = row.ZIP_POLO\n",
    "                        new_dict['ZIP_PPMA'] = row.ZIP_PPMA\n",
    "                        new_dict['CITY_insurance'] = row.CITY_insurance\n",
    "                        new_dict['CITY_POLO'] = row.CITY_POLO\n",
    "                        new_dict['CITY_PPMA'] = row.CITY_PPMA\n",
    "                        new_dict['DATE_insurance'] = row.DATE_insurance\n",
    "                        new_dict['DATE_POLO'] = row.DATE_POLO\n",
    "                        new_dict['DATE_PPMA'] = row.DATE_PPMA\n",
    "                        new_dict['STATE_insurance'] = row.STATE_insurance\n",
    "                        new_dict['STATE_POLO'] = row.STATE_POLO\n",
    "                        new_dict['STATE_PPMA'] = row.STATE_PPMA\n",
    "                        dict_list.append(new_dict)\n",
    "    NEW_DF=pd.DataFrame(dict_list)\n",
    "    return(NEW_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_no_matches  = narrow_it_down(insurance_mismatch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches = narrow_it_down(mismatch_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip_distance(df, DIST=pgeocode.GeoDistance('US')):\n",
    "    distance = DIST.query_postal_code(df[],df[])*0.621371\n",
    "    return(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to get distances between zipcodes in dataframe\n",
    "def get_zip_distances(df):    \n",
    "    distances = []\n",
    "    TOTAL = df.shape[0]\n",
    "    print(TOTAL)\n",
    "    count =0\n",
    "    DIST=pgeocode.GeoDistance('US')\n",
    "    dict_list = []\n",
    "    num_list =[]\n",
    "    for row in df.itertuples():\n",
    "        try:\n",
    "            new_dict={}\n",
    "            new_dict[\"ME\"]=row.ME\n",
    "            count += 1\n",
    "            if int(count/TOTAL*100) in list(range(1,100)) and int(count/TOTAL*100) not in num_list:\n",
    "                num_list.append(int(count/TOTAL*100))\n",
    "                print (f'{int(count/TOTAL*100)}% done!')\n",
    "            try:\n",
    "                mf = int(row.ZIP_POLO)\n",
    "    #             print(mf)\n",
    "                ins = int(row.ZIP_insurance)\n",
    "    #             print(ins)\n",
    "            except:\n",
    "                mf='nan'\n",
    "                ins='nan'\n",
    "        #     print(f'{mf} {ins}')\n",
    "            try:\n",
    "                ZIP_distance = get_zip_distance(mf,ins)\n",
    "    #             print(ZIP_distance)\n",
    "                if np.isnan(ZIP_distance)==False:\n",
    "                    distances.append(ZIP_distance)     \n",
    "                else:\n",
    "                    print(f'{count}: {row.ME} \\nMasterfile:{mf} \\nInsurance:{ins}')\n",
    "            except:\n",
    "                ZIP_distance = 'nan'\n",
    "                print(f'{count}: {row.ME} \\nMasterfile:{mf} \\nInsurance:{ins}')\n",
    "            new_dict['ZIP_distance']=ZIP_distance\n",
    "            dict_list.append(new_dict)\n",
    "        # print(distances2)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupting...\")\n",
    "            return(dict_list, distances)\n",
    "        try:\n",
    "            avg = sum(distances)/len(distances)\n",
    "        except:\n",
    "            avg=0\n",
    "    print(f'Average distance between insurance and masterfile addressses is {avg} miles.')\n",
    "    return(dict_list, distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_dicts_polo, zip_dists_polo = get_zip_distances(no_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zip_distance(zip1,zip2):\n",
    "    zip1 = clean_zipcode(zip1)\n",
    "    zip2 = clean_zipcode(zip2)\n",
    "    Distance = DIST.query_postal_code(zip1, zip2)*0.621371\n",
    "    return(Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zippos = zip_dicts+zip_dicts2 + zip_dicts3\n",
    "pd.DataFrame(zippos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_zipcode(zipcode):\n",
    "    zipcode=str(zipcode)\n",
    "    zipcode = zipcode.replace(\" \",\"\")\n",
    "    zipcode = zipcode.replace(\".0\",\"\")\n",
    "    if len(zipcode)==3:\n",
    "        zipcode = \"00\"+zipcode\n",
    "    if len(zipcode)==4: \n",
    "        zipcode = \"0\"+zipcode\n",
    "    else:\n",
    "        zipcode = zipcode[0:5]\n",
    "    return(zipcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches.to_csv('no_matches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polo_dist = pd.DataFrame(zip_dicts_polo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppma_dist=pd.DataFrame(zippos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_matches = no_matches.drop(columns=['POLO_distance'])\n",
    "with_zips = pd.merge(no_matches, polo_dist, on='ME', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_zips = pd.merge(with_zips, ppma_dist, on='ME', how='outer', suffixes = ('_polo', '_ppma'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_zips['ZIP_distance_polo'] = with_zips['ZIP_distance_polo'].astype(float)\n",
    "with_zips['ZIP_distance_ppma'] = with_zips['ZIP_distance_ppma'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far_places = with_zips[(with_zips['ZIP_distance_polo']>300) & (with_zips['ZIP_distance_ppma']>300)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far_places[['DATE_POLO', 'DATE_PPMA', 'DATE_insurance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_addresses[['PARTY_ID','ME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_table = all_addresses[['PARTY_ID','POST_CD_ID', 'ME']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_ids = pd.merge(small_table, far_places, on='ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(with_ids, long_time, on=['PARTY_ID', 'POST_CD_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_ids.to_csv('Insurance_Updates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "far_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppma_match_df.to_csv('PPMA_Insurance_Matches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppma_mismatch_df.to_csv('PPMA_Insurance_POST_CD_ID_Mismatches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppma_extreme_mismatches = narrow_it_down_ppma(ppma_mismatch_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{ppma_extreme_mismatches.shape} < {ppma_mismatch_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppma_extreme_mismatches.to_csv('PPMA_Insurance_Complete_Address_Mismatches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_no_matches.to_csv('PPMA_POLO_Insurance_Complete_Mismatches.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_no_matches.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppma_extreme_mismatches['STATUS']='BAD'\n",
    "ppma_match_df['STATUS']='GOOD'\n",
    "all_ppma_insurance = pd.concat([ppma_extreme_mismatches, ppma_match_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ppma_insurance.groupby('STATUS').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ppma_insurance.to_csv('Insurance_PPMA_2019_10_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "        'ME',\n",
    "        'RECORD_ID',\n",
    "        'UPDATE_TYPE',\n",
    "        'ADDRESS_TYPE',\n",
    "        'MAILING_NAME',\n",
    "        'LAST_NAME',\n",
    "        'FIRST_NAME',\n",
    "        'MIDDLE_NAME',\n",
    "        'SUFFIX',\n",
    "        'MAILING_LINE_1',\n",
    "        'MAILING_LINE_2',\n",
    "        'CITY',\n",
    "        'STATE',\n",
    "        'ZIP',\n",
    "        'SECTOR',\n",
    "        'CARRIER_ROUTE',\n",
    "        'ADDRESS_UNDELIVERABLE_FLAG',\n",
    "        'FIPS_COUNTY',\n",
    "        'FIPS_STATE',\n",
    "        'PRINTER_CONTROL_CODE',\n",
    "        'PC_ZIP',\n",
    "        'PC_SECTOR',\n",
    "        'DELIVERY_POINT_CODE',\n",
    "        'CHECK_DIGIT',\n",
    "        'PRINTER_CONTROL_CODE_2',\n",
    "        'REGION',\n",
    "        'DIVISION',\n",
    "        'GROUP',\n",
    "        'TRACT',\n",
    "        'SUFFIX_CENSUS',\n",
    "        'BLOCK_GROUP',\n",
    "        'MSA_POPULATION_SIZE',\n",
    "        'MICRO_METRO_IND',\n",
    "        'CBSA',\n",
    "        'CBSA_DIV_IND',\n",
    "        'MD_DO_CODE',\n",
    "        'BIRTH_YEAR',\n",
    "        'BIRTH_CITY',\n",
    "        'BIRTH_STATE',\n",
    "        'BIRTH_COUNTRY',\n",
    "        'GENDER',\n",
    "        'TELEPHONE_NUMBER',\n",
    "        'PRESUMED_DEAD_FLAG',\n",
    "        'FAX_NUMBER',\n",
    "        'TOP_CD',\n",
    "        'PE_CD',\n",
    "        'PRIM_SPEC_CD',\n",
    "        'SEC_SPEC_CD',\n",
    "        'MPA_CD',\n",
    "        'PRA_RECIPIENT',\n",
    "        'PRA_EXP_DT',\n",
    "        'GME_CONF_FLG',\n",
    "        'FROM_DT',\n",
    "        'TO_DT',\n",
    "        'YEAR_IN_PROGRAM',\n",
    "        'POST_GRADUATE_YEAR',\n",
    "        'GME_SPEC_1',\n",
    "        'GME_SPEC_2',\n",
    "        'TRAINING_TYPE',\n",
    "        'GME_INST_STATE',\n",
    "        'GME_INST_ID',\n",
    "        'MEDSCHOOL_STATE',\n",
    "        'MEDSCHOOL_ID',\n",
    "        'MEDSCHOOL_GRAD_YEAR',\n",
    "        'NO_CONTACT_IND',\n",
    "        'NO_WEB_FLAG',\n",
    "        'PDRP_FLAG',\n",
    "        'PDRP_START_DT',\n",
    "        'POLO_MAILING_LINE_1',\n",
    "        'POLO_MAILING_LINE_2',\n",
    "        'POLO_CITY',\n",
    "        'POLO_STATE',\n",
    "        'POLO_ZIP',\n",
    "        'POLO_SECTOR',\n",
    "        'POLO_CARRIER_ROUTE',\n",
    "        'MOST_RECENT_FORMER_LAST_NAME',\n",
    "        'MOST_RECENT_FORMER_MIDDLE_NAME',\n",
    "        'MOST_RECENT_FORMER_FIRST_NAME',\n",
    "        'NEXT_MOST_RECENT_FORMER_LAST',\n",
    "        'NEXT_MOST_RECENT_FORMER_MIDDLE',\n",
    "        'NEXT_MOST_RECENT_FORMER_FIRST'\n",
    "    ]\n",
    "PPD_countries = ppd[['ME','MAILING_NAME','BIRTH_YEAR','BIRTH_CITY','BIRTH_STATE','BIRTH_COUNTRY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD_countries = PPD_countries.dropna(subset=['BIRTH_CITY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD_counts = PPD_countries.groupby('BIRTH_COUNTRY').nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_no_us = PPD_countries[PPD_countries['BIRTH_COUNTRY']!='US1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_no_us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geonamescache as geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_list = geo.GeonamesCache().get_cities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df = pd.DataFrame(city_list).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df['name'] = city_df['name'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_trunc = city_df[['countrycode', 'name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_info = pd.merge(city_trunc, ppd_no_us, left_on = 'name', right_on = 'BIRTH_CITY', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_info = city_info.fillna('None')\n",
    "nones = city_info[city_info['BIRTH_COUNTRY']=='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nones.groupby('countrycode').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nones = nones.fillna('None')\n",
    "potential = nones[(nones['countrycode']=='None') & (nones['BIRTH_CITY']!='UNKNOWN') & (nones['BIRTH_COUNTRY']=='None')]\n",
    "potential.groupby('BIRTH_CITY').count().sort_values(by=['countrycode'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_no_us = ppd_no_us.replace('PUSAN', 'BUSAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_no_us[ppd_no_us['BIRTH_CITY']=='BUSAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_df.sort_values(by=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_trunc.to_csv('Cities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_info.to_csv('Country_Work.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = pd.read_csv('Insurance_PPMA_2019_10_16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['ME'] = full['ME'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPMA.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PPMA_2 = pd.merge(full, PPMA, left_on=('ME'), right_on=('ME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPMA= PPMA.drop_duplicates(subset = 'PARTY_ID', keep='first')\n",
    "print(PPMA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPMA.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPMA.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PPMA.drop_duplicates('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PPMA.to_csv('Insurance_PPMA_2019_10_21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PPMA.groupby('STATUS').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PPMA_2.drop_duplicates(subset='ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPMA['ME'] = PPMA['ME'].apply(lambda x: ('0000' + str(x))[-11:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full['ME'] = full['ME'].apply(lambda x: ('0000' + str(x))[-11:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_PPMA_2.to_csv('Insurance_PPMA_2019_10_21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1596297, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12811241, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INSURANCE_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257687, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INSURANCE_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
