{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import machine learning library\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv into dataframe\n",
    "numbers = pd.read_csv('GetPhoneInfo/wrong_and_connect.csv')\n",
    "numbers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers2 = numbers.drop(columns =['Index','Toll free','First Name Match', 'Last Name Match', 'Unknown phone type', 'Possibly Portable VOIP'])\n",
    "numbers.groupby('label').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save labels and inputs as seperate variables\n",
    "X = numbers3.drop(columns =[\"label\",'OFFICE_TELEPHONE'])\n",
    "y = numbers3['label']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split training and testing data (75%/25%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 12, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a scaler model and fit it to the data\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform str labels to numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import model and layers from keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create model with 21 inputs, two hidden layers with 100 nodes, and 2 outputs\n",
    "model = Sequential()\n",
    "model.add(Dense(units=3, activation='relu', input_dim=29))\n",
    "# model.add(Dense(units=3, activation='relu'))\n",
    "# model.add(Dense(units=21, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "model.compile(optimizer ='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model to scaled data\n",
    "history = model.fit(X_train_scaled,\n",
    "         y_train_categorical,\n",
    "         epochs=50,\n",
    "         shuffle=True,\n",
    "         verbose=2\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantify Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "# plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print model loss and accuracy on testing dataset\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f'Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_accuracy = model.evaluate(X_train_scaled, y_train_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get predictions\n",
    "predictions = model.predict_classes(X_test_scaled)\n",
    "prediction_labels = label_encoder.inverse_transform(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print prediction dataframe\n",
    "data = {'Predicted': prediction_labels, 'Actual':list(y_test)}\n",
    "pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save testing set to csv\n",
    "X_test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = confusion_matrix(list(y_test), prediction_labels, labels = ['disconnected','connected'])\n",
    "precision = confusion[0,0]/(confusion[0,0] + confusion[0,1])\n",
    "recall = confusion[0,0]/(confusion[0,0] + confusion[1,0])\n",
    "false_positives  = confusion[0,1]\n",
    "print(f'''\n",
    "      Precision: {precision}\n",
    "      Recall: {recall}\n",
    "      False Positives: {false_positives}\n",
    "      ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save(\"GetPhoneInfo_model_trained_new.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_numbers = pd.read_csv('GetPhoneInfo/already_done.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with_numbers['Index'] = list(range(0,252))\n",
    "actually_numbers=with_numbers[['Index','OFFICE_TELEPHONE','label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['Predicted']=prediction_labels\n",
    "X_test['Actual']=list(y_test)\n",
    "X_test.to_csv('getphoneinfo_test_monday.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boop = pd.read_csv('getphoneinfo_test_monday.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boop = boop.rename(columns={'Unnamed: 0': 'Index'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom = pd.merge(boop, actually_numbers, on='Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom.to_csv('getphoneinfo_model2_results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numbers = pd.read_csv('GetPhoneInfo/testing_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save labels and inputs as seperate variables\n",
    "testX = new_numbers.drop(columns =[\"Unnamed: 0\",'OFFICE_TELEPHONE'])\n",
    "# testy = numbers['label']\n",
    "print(testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = pd.read_csv('GetPhoneInfo/all_numbers.csv')\n",
    "testX = testing_set.drop(columns=['OFFICE_TELEPHONE', 'Index', 'label'])\n",
    "testY = testing_set['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model.predict_classes(testX)\n",
    "prediction_labels2 = label_encoder.inverse_transform(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goop = pd.DataFrame(prediction_labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goop.to_csv('goop.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = [{'TrainAccuracy': train_accuracy,\n",
    "             'TrainLoss': train_loss,\n",
    "             'TestAccuracy': model_accuracy,\n",
    "             'TestLoss': model_loss,\n",
    "             'Precision': precision,\n",
    "             'Recall':recall,\n",
    "             'FalsePositives':false_positives\n",
    "            }]\n",
    "all_df = all_df.append(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 7, stratify = y)\n",
    "    X_scaler = MinMaxScaler().fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(y_train)\n",
    "    encoded_y_train = label_encoder.transform(y_train)\n",
    "    encoded_y_test = label_encoder.transform(y_test)\n",
    "    y_train_categorical = to_categorical(encoded_y_train)\n",
    "    y_test_categorical = to_categorical(encoded_y_test)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=3, activation='relu', input_dim=X.shape[1]))\n",
    "    # model.add(Dense(units=3, activation='relu'))\n",
    "    # model.add(Dense(units=21, activation='relu'))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    model.compile(optimizer ='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(X_train_scaled,\n",
    "         y_train_categorical,\n",
    "         epochs=35,\n",
    "         shuffle=True,\n",
    "         verbose=2\n",
    "         )\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    # plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    # plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "    print(f'Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}')\n",
    "    train_loss, train_accuracy = model.evaluate(X_train_scaled, y_train_categorical)\n",
    "    predictions = model.predict_classes(X_test_scaled)\n",
    "    prediction_labels = label_encoder.inverse_transform(predictions)\n",
    "    confusion = confusion_matrix(list(y_test), prediction_labels, labels = ['disconnected','connected'])\n",
    "    precision = confusion[0,0]/(confusion[0,0] + confusion[0,1])\n",
    "    recall = confusion[0,0]/(confusion[0,0] + confusion[1,0])\n",
    "    false_positives  = confusion[0,1]\n",
    "    new_list = {'Variables': X.shape[1],\n",
    "                 'TrainAccuracy': train_accuracy,\n",
    "                 'TrainLoss': train_loss,\n",
    "                 'TestAccuracy': model_accuracy,\n",
    "                 'TestLoss': model_loss,\n",
    "                 'Precision': precision,\n",
    "                 'Recall':recall,\n",
    "                 'FalsePositives':false_positives\n",
    "                }\n",
    "    print(new_list)\n",
    "    return(model, new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_many_models(df):\n",
    "    col_list =[]\n",
    "    for col in df.columns:\n",
    "        col_list.append(col)\n",
    "    col_list.remove('label')\n",
    "    all_results = []\n",
    "    X = df.drop(columns = ['label'])\n",
    "    y = df['label']\n",
    "    model, first_model_results = train_model(X,y)\n",
    "        #pd.DataFrame(columns=['Variables','TrainAccuracy','TestAccuracy','Precision','Recall','FalsePositives'])\n",
    "    for col in col_list:\n",
    "        print(f'Take out {col}')\n",
    "        variable = col\n",
    "        X = df.drop(columns = ['label',col])\n",
    "        y = df['label']\n",
    "        model_new, model_results = train_model(X,y)\n",
    "        model_results['Variable']=variable\n",
    "        all_results.append(model_results)\n",
    "    new_df = pd.DataFrame(all_results)\n",
    "    new_df = new_df.sort_values(by=['Precision'])\n",
    "    best_precision = new_df.loc[new_df['Precision'].idxmax()]['Precision']\n",
    "    next_variable = new_df.loc[new_df['Precision'].idxmax()]['Variable']\n",
    "    return(model, first_model_results, new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best(df):\n",
    "    continue_ = True\n",
    "    this_list = []\n",
    "    while continue_ == True:\n",
    "        model, first_model_results, new_df = train_many_models(df)\n",
    "        og_precision = first_model_results['Precision']\n",
    "        best_precision = new_df.loc[new_df['Precision'].idxmax()]['Precision']\n",
    "        this_list.append(new_df)\n",
    "        if best_precision > og_precision:\n",
    "            next_variable = new_df.loc[new_df['Precision'].idxmax()]['Variable']\n",
    "            df = df.drop(columns = [next_variable])\n",
    "        else:\n",
    "            continue_ == False\n",
    "            column_list= []\n",
    "            for col in df.columns:\n",
    "                column_list.append(col)\n",
    "    return(model, first_model_results, new_df, column_list, this_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model, final_model_results, final_df, best_variables, results = find_best(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers4 = numbers3.drop(columns='Relevant SIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPV = pd.read_csv('RPV_archive.csv')\n",
    "def compare_rpv(model, X_test, predicted, y_test):\n",
    "    X_test['predicted'] = predicted\n",
    "    X_test['actual']=y_test\n",
    "    X_test.to_csv('matching2.csv')\n",
    "    matching = pd.read_csv('matching2.csv')\n",
    "    matching = matching.rename(columns={'Unnamed: 0':'Index'})\n",
    "    JUST_NUMS = new_numbers[['Index', 'OFFICE_TELEPHONE']]\n",
    "    woop = pd.merge(matching, JUST_NUMS, on='Index')\n",
    "    yummu = pd.merge(woop, RPV, left_on='OFFICE_TELEPHONE', right_on = 'phone')\n",
    "    yummu[['status', 'predicted','actual']]\n",
    "    grouped = yummu.groupby(['actual', 'status', 'predicted']).count()\n",
    "    return(yummu, grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_numbers.drop(columns =[\"label\",'OFFICE_TELEPHONE'])\n",
    "y = new_numbers['label']\n",
    "model1, new_list1, X_test1, y_test1 = train_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numbers = numbers.drop(columns=['Toll free', 'Unknown phone type', 'Workplace Match', 'Wireless type', 'Wireless note', 'No Geocoordinates', 'Last Name Match', 'Landline', 'First Name Match'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stuff, grouped = compare_rpv(model1, X_test1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 7, stratify = y)\n",
    "X_scaler = MinMaxScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "model = Sequential()\n",
    "model.add(Dense(units=3, activation='relu', input_dim=X.shape[1]))\n",
    "    # model.add(Dense(units=3, activation='relu'))\n",
    "    # model.add(Dense(units=21, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "model.compile(optimizer ='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_scaled,\n",
    "         y_train_categorical,\n",
    "         epochs=35,\n",
    "         shuffle=True,\n",
    "         verbose=2\n",
    "         )\n",
    "    # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "    # plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "    # summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "    # plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test_categorical, verbose=2)\n",
    "print(f'Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}')\n",
    "train_loss, train_accuracy = model.evaluate(X_train_scaled, y_train_categorical)\n",
    "predictions = model.predict_classes(X_test_scaled)\n",
    "prediction_labels = label_encoder.inverse_transform(predictions)\n",
    "confusion = confusion_matrix(list(y_test), prediction_labels, labels = ['disconnected','connected'])\n",
    "precision = confusion[0,0]/(confusion[0,0] + confusion[0,1])\n",
    "recall = confusion[0,0]/(confusion[0,0] + confusion[1,0])\n",
    "false_positives  = confusion[0,1]\n",
    "new_list = {'Variables': X.shape[1],\n",
    "                 'TrainAccuracy': train_accuracy,\n",
    "                 'TrainLoss': train_loss,\n",
    "                 'TestAccuracy': model_accuracy,\n",
    "                 'TestLoss': model_loss,\n",
    "                 'Precision': precision,\n",
    "                 'Recall':recall,\n",
    "                 'FalsePositives':false_positives\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stuff, grouped = compare_rpv(model, X_test, prediction_labels, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predictions']=prediction_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rpv(X_test, y_test, prediction_labels):\n",
    "    X_test['predicted'] = prediction_labels\n",
    "    X_test['actual']=y_test\n",
    "    index_list = []\n",
    "    for row in X_test.itertuples():\n",
    "        index_list.append(row._1)\n",
    "    X_test['Index']=index_list\n",
    "    JUST_NUMS = new_numbers[['Index', 'OFFICE_TELEPHONE']]\n",
    "    woop = pd.merge(X_test, JUST_NUMS, on='Index')\n",
    "    yummu = pd.merge(woop, RPV, left_on='OFFICE_TELEPHONE', right_on = 'phone')\n",
    "    yummu[['status', 'predicted','actual']]\n",
    "    grouped = yummu.groupby(['actual', 'status', 'predicted']).count()\n",
    "    return(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = numbers.drop(columns='Toll free')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_numbers = numbers[['label','Address Match','City Match','Connected','Disconnected','High Quality','INF','Low Quality','NO SIC','No Date','Ported','Relevant Name','Relevant SIC','State Match','ZipCode Match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_numbers.drop(columns =[\"label\"])\n",
    "y = new_numbers['label']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_best(new_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_numbers = new_numbers[['ZipCode Match','Connected','High Quality', 'INF','NO SIC','Ported','Relevant Name','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_new_numbers.drop(columns =[\"label\"])\n",
    "y = new_new_numbers['label']\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 7, stratify = y)\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "y_train_categorical = to_categorical(encoded_y_train)\n",
    "y_test_categorical = to_categorical(encoded_y_test)\n",
    "model = Sequential()\n",
    "model.add(Dense(units=3, activation='relu', input_dim=X.shape[1]))\n",
    "# model.add(Dense(units=5, activation='relu'))\n",
    "    # model.add(Dense(units=21, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "model.compile(optimizer ='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train,\n",
    "         y_train_categorical,\n",
    "         epochs=25,\n",
    "         shuffle=True,\n",
    "         verbose=2\n",
    "         )\n",
    "    # summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "    # plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "    # summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "    # plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "    # plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test_categorical, verbose=2)\n",
    "print(f'Normal Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}')\n",
    "train_loss, train_accuracy = model.evaluate(X_train, y_train_categorical)\n",
    "predictions = model.predict_classes(X_test)\n",
    "prediction_labels = label_encoder.inverse_transform(predictions)\n",
    "confusion = confusion_matrix(list(y_test), prediction_labels, labels = ['disconnected','connected'])\n",
    "precision = confusion[0,0]/(confusion[0,0] + confusion[0,1])\n",
    "recall = confusion[0,0]/(confusion[0,0] + confusion[1,0])\n",
    "false_positives  = confusion[0,1]\n",
    "new_list = {'Variables': X.shape[1],\n",
    "                 'TrainAccuracy': train_accuracy,\n",
    "                 'TrainLoss': train_loss,\n",
    "                 'TestAccuracy': model_accuracy,\n",
    "                 'TestLoss': model_loss,\n",
    "                 'Precision': precision,\n",
    "                 'Recall':recall,\n",
    "                 'FalsePositives':false_positives\n",
    "                }\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['predicted'] = prediction_labels\n",
    "X_test['actual']=y_test\n",
    "X_test.to_csv('matching2.csv')\n",
    "matching = pd.read_csv('matching2.csv')\n",
    "matching = matching.rename(columns={'Unnamed: 0':'Index'})\n",
    "JUST_NUMS = numbers[['Index', 'OFFICE_TELEPHONE']]\n",
    "woop = pd.merge(matching, JUST_NUMS, on='Index')\n",
    "yummu = pd.merge(woop, RPV, left_on='OFFICE_TELEPHONE', right_on = 'phone')\n",
    "yummu[['status', 'predicted','actual']]\n",
    "grouped = yummu.groupby(['actual', 'status', 'predicted']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RPV = RPV.drop_duplicates(subset='phone', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yummu.groupby(['status', 'predicted','actual']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Predicted': prediction_labels, 'Actual':list(y_test)}\n",
    "Z = pd.DataFrame(data)\n",
    "Z.groupby('Actual').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
