{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import usaddress\n",
    "import pyodbc\n",
    "from fuzzywuzzy import fuzz\n",
    "from datamart import fix_me\n",
    "from functools import reduce\n",
    "import useful_functions as use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My thought here is that we would first look for a phone/address combination between IQVIA/Symphony/DHC/Data.gov where there was some agreement between multiple sources. If we did not find agreement between multiple sources, we would default to what was present on the IQVIA, assuming it was different than what we already had, in particular with POLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#POLOs\n",
    "older_polos = pd.read_csv('../../Data/POLO_Filter/Older_Filtered_POLOs_2021-08-26.csv', low_memory=False)\n",
    "older_polos['ME'] = use.fix_me(older_polos.ME)\n",
    "older_polos['IQVIA_ME'] = [x[0:10] for x in older_polos.ME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dhc\n",
    "dhc = pd.read_csv('../../Data/DHC/DHC_2021-07.csv', low_memory=False)\n",
    "dhc = dhc.rename(columns={\n",
    "    'Zip_Code':'ZIP_DHC',\n",
    "    'State':'STATE_DHC',\n",
    "    'City':'CITY_DHC',\n",
    "    'Address': 'ADDRESS_1_DHC',\n",
    "    'Address1': 'ADDRESS_2_DHC'\n",
    "})\n",
    "dhc = dhc.fillna('None')\n",
    "dhc['ME'] = use.fix_me(dhc.ME)\n",
    "dhc = dhc[dhc.ME.isin(older_polos.ME)]\n",
    "dhc['DHC_PHONE'] = [use.fix_phone(x) for x in dhc['Phone_Number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.gov\n",
    "gov = pd.read_csv('../../Data/DataGov/All_Data_210826.csv', low_memory=False)\n",
    "gov = gov.fillna('None')\n",
    "gov['ME'] = use.fix_me(gov.ME)\n",
    "gov = gov[gov.ME.isin(older_polos.ME)]\n",
    "gov['GOV_PHONE'] = [use.fix_phone(x) if x !='None' else x for x in gov['phone']]\n",
    "gov = gov.rename(columns={\n",
    "    'zip':'ZIP_GOV',\n",
    "    'st':'STATE_GOV',\n",
    "    'cty':'CITY_GOV',\n",
    "    'adr_ln_2': 'ADDRESS_2_GOV',\n",
    "    'adr_ln_1': 'ADDRESS_1_GOV'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iqvia\n",
    "username = 'vigrose'\n",
    "password = 'Ravenclaw~10946'\n",
    "q = \"DSN=eprdods; UID={}; PWD={}\".format(username, password)\n",
    "ODS = pyodbc.connect(q)\n",
    "iqvia_query = \\\n",
    "        \"\"\"\n",
    "        SELECT DISTINCT \n",
    "        B.PHONE,\n",
    "        B.PHYSICAL_ADDR_1,\n",
    "        B.PHYSICAL_ADDR_2,\n",
    "        B.PHYSICAL_CITY,\n",
    "        B.PHYSICAL_STATE,\n",
    "        B.PHYSICAL_ZIP,\n",
    "        P.ME,\n",
    "        T.AFFIL_TYPE_DESC,\n",
    "        A.AFFIL_IND,\n",
    "        A.AFFIL_RANK\n",
    "        FROM \n",
    "        ODS.ODS_IMS_BUSINESS B, ODS.SAS_ODS_IMS_PROVIDER_AFFIL A, ODS.ODS_IMS_PROFESSIONAL P, ODS.ODS_IMS_AFFILIATION_TYPE T\n",
    "        WHERE  \n",
    "        B.IMS_ORG_ID = A.IMS_ORG_ID\n",
    "        AND\n",
    "        A.PROFESSIONAL_ID = P.PROFESSIONAL_ID\n",
    "        AND\n",
    "        A.AFFIL_TYPE_ID = T.AFFIL_TYPE_ID\n",
    "        AND\n",
    "        P.CURRENT_BATCH_FLAG='Y'\n",
    "        AND\n",
    "        A.CURRENT_BATCH_FLAG='Y'\n",
    "        AND\n",
    "        B.CURRENT_BATCH_FLAG='Y'\n",
    "        \"\"\"\n",
    "iqvia = pd.read_sql(con=ODS, sql=iqvia_query)\n",
    "iqvia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqvia =iqvia.fillna('None')\n",
    "iqvia = iqvia[iqvia.ME.isin(older_polos.IQVIA_ME)]\n",
    "iqvia['IQVIA_PHONE'] = [use.fix_phone(x) if x !='None' else x for x in iqvia['PHONE']]\n",
    "iqvia = iqvia.rename(columns={\n",
    "    'PHYSICAL_ZIP':'ZIP_IQVIA',\n",
    "    'PHYSICAL_STATE':'STATE_IQVIA',\n",
    "    'PHYSICAL_CITY':'CITY_IQVIA',\n",
    "    'PHYSICAL_ADDR_1': 'ADDRESS_1_IQVIA',\n",
    "    'PHYSICAL_ADDR_2': 'ADDRESS_2_IQVIA'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symphony\n",
    "sym_query = \\\n",
    "        \"\"\"\n",
    "        SELECT\n",
    "        d.ADDR_LINE_2_TXT AS MAILING_LINE_1,\n",
    "        d.ADDR_LINE_1_TXT AS MAILING_LINE_2,\n",
    "        d.ADDR_CITY_NAM AS CITY,\n",
    "        d.ADDR_ST_CDE AS STATE,\n",
    "        d.ADDR_ZIP_CDE AS ZIP,\n",
    "        d.ADDR_FRST_TLPHN_NBR AS TELEPHONE,\n",
    "        l.OTHER_ID AS SYM_ME\n",
    "        FROM\n",
    "        ODS.PRACTITIONER_DEMOGRAPHIC_LAYOUT d, ODS.PRACTITIONER_ADDL_IDS_LAYOUT l\n",
    "        WHERE\n",
    "        d.DS_PRCTR_ID = l.DS_PRCTR_ID\n",
    "        and\n",
    "        l.ID_QLFR_TYP_CDE = 38\n",
    "        \"\"\"  \n",
    "symphony = pd.read_sql(con=ODS, sql=sym_query)\n",
    "symphony.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symphony =symphony.fillna('None')\n",
    "symphony= symphony[symphony.SYM_ME.isin(older_polos.IQVIA_ME)]\n",
    "symphony['SYM_PHONE'] = [use.fix_phone(x) for x in symphony['TELEPHONE']]\n",
    "symphony = symphony.rename(columns={\n",
    "    'ZIP':'ZIP_SYMPHONY',\n",
    "    'STATE':'STATE_SYMPHONY',\n",
    "    'CITY':'CITY_SYMPHONY',\n",
    "    'MAILING_LINE_1': 'ADDRESS_2_SYMPHONY',\n",
    "    'MAILING_LINE_2': 'ADDRESS_1_SYMPHONY'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS = older_polos[['ME','IQVIA_ME']]\n",
    "THIS = pd.merge(THIS, symphony, left_on='IQVIA_ME', right_on='SYM_ME', how='left')\n",
    "THIS = pd.merge(THIS, iqvia, left_on='IQVIA_ME', right_on='ME', how='left', suffixes = ['','_iqvia'])\n",
    "THIS = pd.merge(THIS, dhc, on='ME', how='left')\n",
    "THIS = pd.merge(THIS, gov, on='ME', how='left')[['ME','IQVIA_ME', 'SYM_PHONE','IQVIA_PHONE', 'DHC_PHONE', 'GOV_PHONE']].drop_duplicates()\n",
    "THIS = THIS.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "for row in THIS.itertuples():\n",
    "    count = 0\n",
    "    phone_num = 'None'\n",
    "    symph_phone = row.SYM_PHONE\n",
    "    dhc_phone = row.DHC_PHONE\n",
    "    iqvia_phone = row.IQVIA_PHONE\n",
    "    data_phone = row.GOV_PHONE\n",
    "    if symph_phone == dhc_phone and symph_phone != 'None':\n",
    "        MATCHES = 'Symphony, DHC'\n",
    "        phone_num = symph_phone\n",
    "        if dhc_phone == iqvia_phone:\n",
    "            count = 2\n",
    "            MATCHES = 'Symphony, DHC, IQVia'\n",
    "            if dhc_phone == data_phone:\n",
    "                count = 3\n",
    "                MATCHES = 'Symphony, DHC, IQVia, DataGov'\n",
    "        elif dhc_phone == data_phone:\n",
    "            count = 2\n",
    "            MATCHES = 'Symphony, DHC, DataGov'\n",
    "        else:\n",
    "            count = 1       \n",
    "    elif symph_phone == iqvia_phone and symph_phone != 'None':\n",
    "        phone_num = symph_phone\n",
    "        MATCHES = 'Symphony, IQVia'\n",
    "        count = 1\n",
    "        if symph_phone == data_phone:\n",
    "            count = 2\n",
    "            MATCHES = 'Symphony, IQVia, DataGov'\n",
    "    elif symph_phone == data_phone and symph_phone != 'None':\n",
    "        phone_num = symph_phone\n",
    "        MATCHES = 'Symphony, DataGov'\n",
    "        count = 1\n",
    "    elif dhc_phone == iqvia_phone and dhc_phone != 'None':\n",
    "        phone_num = dhc_phone\n",
    "        MATCHES = 'DHC, IQVia'\n",
    "        count = 1\n",
    "        if dhc_phone == data_phone:\n",
    "            MATCHES = 'DHC, IQVia, DataGov'\n",
    "            count = 2\n",
    "    elif dhc_phone == data_phone and dhc_phone != 'None':\n",
    "        phone_num = dhc_phone\n",
    "        MATCHES = 'DHC, DataGov'\n",
    "        count = 1\n",
    "    elif data_phone== iqvia_phone and data_phone != 'None':\n",
    "        phone_num = data_phone\n",
    "        MATCHES = 'IQVia, DataGov'\n",
    "        count = 1\n",
    "        \n",
    "    if phone_num!='None':\n",
    "        dicto = {\n",
    "        'ME': row.ME,\n",
    "        'IQVIA_ME': row.IQVIA_ME,\n",
    "        'PHONE': phone_num,\n",
    "        'MATCHED': count,\n",
    "        'MATCHES': MATCHES\n",
    "    }\n",
    "        dict_list.append(dicto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_matches = pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phones = phone_matches.drop_duplicates().sort_values('MATCHED').drop_duplicates('ME',keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_address_two(add_1):\n",
    "    add_1 = add_1.strip()\n",
    "    if add_1 == 'None':\n",
    "        addr_1 = ' '\n",
    "    elif add_1 == 'NAN':\n",
    "        addr_1 = ' '\n",
    "    else:\n",
    "        addr_1 = ',' + add_1\n",
    "    return(addr_1)\n",
    "\n",
    "def is_a_match(thing_1, thing_2):\n",
    "    if thing_1 == thing_2:\n",
    "        match = True\n",
    "    elif thing_1 in thing_2:\n",
    "        match = True\n",
    "    elif thing_2 in thing_1:\n",
    "        match = True\n",
    "    elif fuzz.ratio(thing_1, thing_2)>75:\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    return(match)\n",
    "\n",
    "def is_match(thing_1, thing_2):\n",
    "    if thing_1 == thing_2:\n",
    "        match = True\n",
    "    elif thing_1 in thing_2:\n",
    "        match = True\n",
    "    elif thing_2 in thing_1:\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    return(match)\n",
    "\n",
    "def error_handle(parsed_string):\n",
    "    new_dict = {}\n",
    "    for thing in parsed_string:\n",
    "        if thing[1] in new_dict.keys():\n",
    "            a_list = [new_dict[thing[1]], thing[0]]\n",
    "            new_dict[thing[1]] = max(a_list, key=len)\n",
    "        else:\n",
    "            new_dict[thing[1]] = thing[0]\n",
    "    return(new_dict)\n",
    "\n",
    "# def get_all_keys(moar):\n",
    "#     all_keys =[]\n",
    "#     for row in moar.itertuples():\n",
    "#         addr_2 = clean_address_two(row.ADDRESS_2)\n",
    "#         address = f'{row.ADDRESS_1}{addr_2}, {row.CITY}, {row.STATE}'\n",
    "#         try:\n",
    "#             new_dict = usaddress.tag(address)[0]\n",
    "#         except usaddress.RepeatedLabelError as e:\n",
    "#             print(e.original_string)\n",
    "#             new_dict = error_handle(e.parsed_string)\n",
    "#             print('')\n",
    "#         le_keys = list(new_dict.keys())\n",
    "#         for key in le_keys:\n",
    "#             if key not in all_keys:\n",
    "#                 all_keys.append(key)\n",
    "#         return (all_keys)\n",
    "    \n",
    "# def parse_address(moar):\n",
    "#     dict_list = []\n",
    "#     for row in moar.itertuples():\n",
    "#         new_dict = {}\n",
    "#         new_dict['ME'] = row.ME\n",
    "#         new_dict['IQVIA_ME'] = row.IQVIA_ME\n",
    "#         new_dict['PHONE'] = row.PHONE\n",
    "#         new_dict['ZIP'] = row.ZIP\n",
    "#         addr_2 = clean_address_two(row.ADDRESS_2)\n",
    "#         address = f'{row.ADDRESS_1}{addr_2}, {row.CITY}, {row.STATE}'\n",
    "#         try:\n",
    "#             address_dict = usaddress.tag(address)[0]\n",
    "#         except usaddress.RepeatedLabelError as e:\n",
    "#             print(e.original_string)\n",
    "#             address_dict = error_handle(e.parsed_string)\n",
    "#             print('')\n",
    "#         dict_list.append(new_dict)\n",
    "#     return (dict_list)\n",
    "\n",
    "# LE_KEYS = get_all_keys(all_file)\n",
    "# new_list = parse_address(all_file, LE_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(THIS):\n",
    "    dict_list = []\n",
    "    for row in THIS.itertuples():\n",
    "        count = 0\n",
    "        phone_num = 'None'\n",
    "        symph_phone = row.ADDRESS_1_SYMPHONY.upper().strip()\n",
    "        dhc_phone = row.ADDRESS_1_DHC.upper().strip()\n",
    "        iqvia_phone = row.ADDRESS_1_IQVIA.upper().strip()\n",
    "        data_phone = row.ADDRESS_1_GOV.upper().strip()\n",
    "        if is_a_match(symph_phone, dhc_phone) and symph_phone != 'NONE':\n",
    "            MATCHES = 'Symphony, DHC'\n",
    "            phone_num = symph_phone\n",
    "            if is_a_match(dhc_phone,iqvia_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, DHC, IQVia'\n",
    "                if is_a_match(dhc_phone,data_phone):\n",
    "                    count = 3\n",
    "                    MATCHES = 'Symphony, DHC, IQVia, DataGov'\n",
    "            elif is_a_match(dhc_phone,data_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, DHC, DataGov'\n",
    "            else:\n",
    "                count = 1       \n",
    "        elif is_a_match(symph_phone,iqvia_phone) and symph_phone != 'NONE':\n",
    "            phone_num = symph_phone\n",
    "            MATCHES = 'Symphony, IQVia'\n",
    "            count = 1\n",
    "            if is_a_match(symph_phone,data_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, IQVia, DataGov'\n",
    "        elif is_a_match(symph_phone,data_phone) and symph_phone != 'NONE':\n",
    "            phone_num = symph_phone\n",
    "            MATCHES = 'Symphony, DataGov'\n",
    "            count = 1\n",
    "\n",
    "        elif is_a_match(dhc_phone,iqvia_phone) and dhc_phone != 'NONE':\n",
    "            phone_num = iqvia_phone\n",
    "            MATCHES = 'DHC, IQVia'\n",
    "            count = 1\n",
    "            if dhc_phone == data_phone:\n",
    "                MATCHES = 'DHC, IQVia, DataGov'\n",
    "                count = 2\n",
    "        elif is_a_match(dhc_phone,data_phone) and dhc_phone != 'NONE':\n",
    "            phone_num = data_phone\n",
    "            MATCHES = 'DHC, DataGov'\n",
    "            count = 1\n",
    "        elif is_a_match(data_phone,iqvia_phone) and data_phone != 'NONE':\n",
    "            phone_num = data_phone\n",
    "            MATCHES = 'IQVia, DataGov'\n",
    "            count = 1\n",
    "\n",
    "        if phone_num!='None':\n",
    "            dicto = {\n",
    "            'ME': row.ME,\n",
    "            'IQVIA_ME': row.IQVIA_ME,\n",
    "            'ADDRESS': phone_num,\n",
    "            'MATCHED': count,\n",
    "            'ADDRESS_MATCHES': MATCHES,\n",
    "            'STATE_PPMA':\n",
    "            'STATE_PPMA'\n",
    "        }\n",
    "            dict_list.append(dicto)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this = older_polos[['ME','IQVIA_ME','STATE_PPMA','STATE_POLO']]\n",
    "this = pd.merge(this, symphony, left_on='IQVIA_ME', right_on='SYM_ME', how='left')\n",
    "this = pd.merge(this, iqvia, left_on='IQVIA_ME', right_on='ME', how='left', suffixes = ['','_iqvia'])\n",
    "this = pd.merge(this, dhc, on='ME', how='left')\n",
    "this = pd.merge(this, gov, on='ME', how='left').drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this = this.fillna('None')\n",
    "ADD_LIST = count_matches(this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDRESSES = pd.DataFrame(ADD_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = ADDRESSES.sort_values('MATCHED').drop_duplicates('ME', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alls = pd.merge(addresses, phones, on=['ME','IQVIA_ME'], how='outer', suffixes=['_ADDRESS','_PHONE']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alls.sort_values('MATCHED_PHONE', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEES = pd.merge(alls, THIS, on=['ME','IQVIA_ME']).sort_values('MATCHED_PHONE', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = pd.merge(TEES, this, on=['ME','IQVIA_ME']).sort_values('MATCHED_PHONE', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzed_xx = pd.merge(fuzzed_cont, this, on=['ME','IQVIA_ME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this[['ME', 'IQVIA_ME', 'ADDRESS_2_SYMPHONY', 'ZIP_SYMPHONY',  'ADDRESS_1_IQVIA', \n",
    "       'ZIP_IQVIA', 'ZIP_DHC', 'ADDRESS_1_DHC', 'First Name', 'Physician Name',\n",
    "       'Middle Name', 'Primary Specialty', 'Primary Hospital Affiliation',\n",
    "       'Last Name', 'ADDRESS_2_DHC', 'DHC_PHONE', 'NPI_y', ' Ind_PAC_ID',\n",
    "       ' Ind_enrl_ID', ' lst_nm', ' frst_nm', ' mid_nm', ' suff', ' gndr',\n",
    "       ' Cred', ' Med_sch', ' Grd_yr', ' pri_spec', ' sec_spec_1',\n",
    "       ' sec_spec_2', ' sec_spec_3', ' sec_spec_4', ' sec_spec_all', ' org_nm',\n",
    "       ' org_pac_id', ' num_org_mem', 'ADDRESS_1_GOV', 'ADDRESS_2_GOV',\n",
    "       ' ln_2_sprs', 'CITY_GOV', 'STATE_GOV', 'ZIP_GOV', ' phn_numbr',\n",
    "       ' hosp_afl_1', ' hosp_afl_lbn_1', ' hosp_afl_2', ' hosp_afl_lbn_2',\n",
    "       ' hosp_afl_3', ' hosp_afl_lbn_3', ' hosp_afl_4', ' hosp_afl_lbn_4',\n",
    "       ' hosp_afl_5', ' hosp_afl_lbn_5', ' ind_assgn', ' grp_assgn',\n",
    "       ' adrs_id', 'PARTY_ID', 'GOV_PHONE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqvia[iqvia.ME.isin(TEES.IQVIA_ME)==False].drop_duplicates('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEES.drop_duplicates('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_matches.drop_duplicates('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8161+5294"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(testt, older_polos, on=['ME','IQVIA_ME'])[['ADDRESS','STATE_DHC','STATE_IQVIA','STATE_SYMPHONY','STATE_GOV','STATE_POLO','STATE_PPMA','ADDRESS_MATCHES']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "older_polos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(older_polos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testt = XX[['ME', 'IQVIA_ME', 'ADDRESS', 'MATCHED_ADDRESS', 'ADDRESS_MATCHES',\n",
    "       'PHONE_x', 'MATCHED_PHONE', 'MATCHES', 'STATE_SYMPHONY', 'STATE_IQVIA', 'STATE_DHC',\n",
    "       'STATE_GOV']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = XX.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_matches():\n",
    "    dictss = []\n",
    "    mes = []\n",
    "    for row in XX.itertuples():\n",
    "        if row.ADDRESS_MATCHES == 'None':\n",
    "            continue\n",
    "        if row.ME in mes:\n",
    "            continue\n",
    "        sources = row.ADDRESS_MATCHES\n",
    "        address = row.ADDRESS.upper().strip()\n",
    "        phone = row.PHONE_x\n",
    "        phone_source = 'Multiple'\n",
    "        address_source = sources\n",
    "        if \"IQVia\" in sources and row.ADDRESS_1_IQVIA.upper().strip() == address:\n",
    "            state = row.STATE_IQVIA\n",
    "            zipcode = row.ZIP_IQVIA\n",
    "            city = row.CITY_IQVIA\n",
    "            address_2 = row.ADDRESS_2_SYMPHONY\n",
    "            if phone == 'None':\n",
    "                phone = row.IQVIA_PHONE_x\n",
    "                phone_source = 'IQVia'\n",
    "            address_source = 'IQVia'\n",
    "        elif \"Symphony\" in sources and row.ADDRESS_1_SYMPHONY.upper().strip() == address:\n",
    "            state = row.STATE_SYMPHONY\n",
    "            zipcode = row.ZIP_SYMPHONY\n",
    "            city = row.CITY_SYMPHONY\n",
    "            address_2 = row.ADDRESS_2_SYMPHONY\n",
    "            if phone == 'None':\n",
    "                phone = row.SYM_PHONE_x\n",
    "                phone_source = 'Symphony'\n",
    "            address_source = 'Symphony'\n",
    "        elif \"DataGov\" in sources and row.ADDRESS_1_GOV.upper().strip() == address:\n",
    "            state = row.STATE_GOV\n",
    "            zipcode = row.ZIP_GOV\n",
    "            city = row.CITY_GOV\n",
    "            address_2 = row.ADDRESS_2_GOV\n",
    "            if phone == 'None':\n",
    "                phone = row.GOV_PHONE_x\n",
    "                phone_source = 'DataGov'\n",
    "            address_source = 'DataGov'\n",
    "        NEW_DICT = {\n",
    "            'ME': row.ME,\n",
    "            'ME_IQVIA': row.IQVIA_ME,\n",
    "            'ADDRESS_MATCHES': row.ADDRESS_MATCHES,\n",
    "            'PHONE_MATCHES': row.MATCHES,\n",
    "            'ADDRESS_1': address,\n",
    "            'ADDRESS_2': address_2,\n",
    "            'CITY': city,\n",
    "            'STATE': state,\n",
    "            'ZIPCODE': zipcode,\n",
    "            'PHONE': phone,\n",
    "            'PHONE_SOURCE': phone_source,\n",
    "            'ADDRESS_SOURCE': address_source\n",
    "        }\n",
    "        dictss.append(NEW_DICT)\n",
    "        if phone!='None':\n",
    "            mes.append(row.ME)\n",
    "        return mes, dictss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.DataFrame(dictss).drop_duplicates(['ME','ADDRESS_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX[XX.ADDRESS_MATCHES == 'None'][['ME','MATCHES',  'ADDRESS_1_SYMPHONY', 'CITY_SYMPHONY', 'STATE_SYMPHONY', 'ADDRESS_1_IQVIA',\n",
    "       'CITY_IQVIA', 'STATE_IQVIA', 'STATE_DHC',\n",
    "       'CITY_DHC', 'ADDRESS_1_DHC', 'ADDRESS_1_GOV', 'CITY_GOV', 'STATE_GOV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_address = XX[XX.ADDRESS_MATCHES == 'None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fuzzy_matches(THIS):\n",
    "    dict_list = []\n",
    "    for row in THIS.itertuples():\n",
    "        count = 0\n",
    "        phone_num = 'None'\n",
    "        symph_phone = row.ADDRESS_1_SYMPHONY.upper().strip()\n",
    "        dhc_phone = row.ADDRESS_1_DHC.upper().strip()\n",
    "        iqvia_phone = row.ADDRESS_1_IQVIA.upper().strip()\n",
    "        data_phone = row.ADDRESS_1_GOV.upper().strip()\n",
    "        print(iqvia_phone)\n",
    "        if is_a_match(symph_phone,dhc_phone) and symph_phone != 'NONE':\n",
    "            MATCHES = 'Symphony, DHC'\n",
    "            phone_num = symph_phone\n",
    "            if is_a_match(dhc_phone,iqvia_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, DHC, IQVia'\n",
    "                if is_a_match(dhc_phone,data_phone):\n",
    "                    count = 3\n",
    "                    MATCHES = 'Symphony, DHC, IQVia, DataGov'\n",
    "            elif is_a_match(dhc_phone,data_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, DHC, DataGov'\n",
    "            else:\n",
    "                count = 1       \n",
    "        elif is_a_match(symph_phone,iqvia_phone) and symph_phone != 'NONE':\n",
    "            phone_num = symph_phone\n",
    "            MATCHES = 'Symphony, IQVia'\n",
    "            count = 1\n",
    "            if is_a_match(symph_phone,data_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, IQVia, DataGov'\n",
    "        elif is_a_match(symph_phone,data_phone) and symph_phone != 'NONE':\n",
    "            phone_num = symph_phone\n",
    "            MATCHES = 'Symphony, DataGov'\n",
    "            count = 1\n",
    "\n",
    "        elif is_a_match(dhc_phone,iqvia_phone) and dhc_phone != 'NONE':\n",
    "            phone_num = iqvia_phone\n",
    "            MATCHES = 'DHC, IQVia'\n",
    "            count = 1\n",
    "            if is_a_match(iqvia_phone,data_phone):\n",
    "                MATCHES = 'DHC, IQVia, DataGov'\n",
    "                count = 2\n",
    "        elif is_a_match(dhc_phone,data_phone) and dhc_phone != 'NONE':\n",
    "            phone_num = data_phone\n",
    "            MATCHES = 'DHC, DataGov'\n",
    "            count = 1\n",
    "\n",
    "        if phone_num!='None':\n",
    "            dicto = {\n",
    "            'ME': row.ME,\n",
    "            'IQVIA_ME': row.IQVIA_ME,\n",
    "            'ADDRESS': phone_num,\n",
    "            'DHC_ADDRESS': dhc_phone,\n",
    "            'SYM_ADDRESS': symph_phone,\n",
    "            'IQV_ADDRESS': iqvia_phone,\n",
    "            'GOV_ADDRESS': data_phone,\n",
    "            'MATCHED': count,\n",
    "            'ADDRESS_MATCHES': MATCHES\n",
    "        }\n",
    "            dict_list.append(dicto)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boom = count_fuzzy_matches(no_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(boom).sort_values('MATCHED').drop_duplicates('ME', keep='last').to_csv(\"../../Data/POLO_Filter/Match_Test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FUZZED = pd.DataFrame(boom).sort_values('MATCHED').drop_duplicates('ME', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzed_cont = pd.merge(FUZZED, phone_matches, on=['ME','IQVIA_ME'], suffixes=['_ADDRESSES','_PHONES']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no phones?\n",
    "#still no phones\n",
    "#phones match but addresses do not\n",
    "#100 mile check\n",
    "#license check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_2 = []\n",
    "mes_2 = []\n",
    "for row in fuzzed_xx.itertuples():\n",
    "    if row.ADDRESS_MATCHES == 'None':\n",
    "        print('Addres mismatch')\n",
    "        continue\n",
    "    if row.ME in mes:\n",
    "        print('already found')\n",
    "        continue\n",
    "    sources = row.ADDRESS_MATCHES\n",
    "    address = row.ADDRESS.upper().strip()\n",
    "    phone = row.PHONE_x\n",
    "    phone_source = 'Multiple'\n",
    "    address_source = sources\n",
    "    if \"IQVia\" in sources and row.ADDRESS_1_IQVIA.upper().strip() == address:\n",
    "        state = row.STATE_IQVIA\n",
    "        zipcode = row.ZIP_IQVIA\n",
    "        city = row.CITY_IQVIA\n",
    "        address_2 = row.ADDRESS_2_SYMPHONY\n",
    "        if phone == 'None':\n",
    "            phone = row.IQVIA_PHONE_x\n",
    "            phone_source = 'IQVia'\n",
    "        address_source = 'IQVia'\n",
    "    elif \"Symphony\" in sources and row.ADDRESS_1_SYMPHONY.upper().strip() == address:\n",
    "        state = row.STATE_SYMPHONY\n",
    "        zipcode = row.ZIP_SYMPHONY\n",
    "        city = row.CITY_SYMPHONY\n",
    "        address_2 = row.ADDRESS_2_SYMPHONY\n",
    "        if phone == 'None':\n",
    "            phone = row.SYM_PHONE_x\n",
    "            phone_source = 'Symphony'\n",
    "        address_source = 'Symphony'\n",
    "    elif \"DataGov\" in sources and row.ADDRESS_1_GOV.upper().strip() == address:\n",
    "        state = row.STATE_GOV\n",
    "        zipcode = row.ZIP_GOV\n",
    "        city = row.CITY_GOV\n",
    "        address_2 = row.ADDRESS_2_GOV\n",
    "        if phone == 'None':\n",
    "            phone = row.GOV_PHONE_x\n",
    "            phone_source = 'DataGov'\n",
    "        address_source = 'DataGov'\n",
    "    NEW_DICT = {\n",
    "        'ME': row.ME,\n",
    "        'ME_IQVIA': row.IQVIA_ME,\n",
    "        'ADDRESS_MATCHES': row.ADDRESS_MATCHES,\n",
    "        'PHONE_MATCHES': row.MATCHES,\n",
    "        'ADDRESS_1': address,\n",
    "        'ADDRESS_2': address_2,\n",
    "        'CITY': city,\n",
    "        'STATE': state,\n",
    "        'ZIPCODE': zipcode,\n",
    "        'PHONE': phone,\n",
    "        'PHONE_SOURCE': phone_source,\n",
    "        'ADDRESS_SOURCE': address_source\n",
    "    }\n",
    "    dicts_2.append(NEW_DICT)\n",
    "    if phone!='None':\n",
    "        mes_2.append(row.ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dicts_2).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [dhc, gov, older_polos]\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='ME'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.merge(df2,on='name').merge(df3,on='name')\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THIS = older_polos[['ME','IQVIA_ME']]\n",
    "THIS = pd.merge(THIS, symphony, left_on='IQVIA_ME', right_on='SYM_ME', how='left')\n",
    "THIS = pd.merge(THIS, iqvia, left_on='IQVIA_ME', right_on='ME', how='left', suffixes = ['','_iqvia'])\n",
    "THIS = pd.merge(THIS, dhc, on='ME', how='left')\n",
    "THIS = pd.merge(THIS, gov, on='ME', how='left')[['ME','IQVIA_ME', 'SYM_PHONE','IQVIA_PHONE', 'DHC_PHONE', 'GOV_PHONE']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gov.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def universalize_columns(df, source):\n",
    "    df['ADDRESS_1'] = df[f'ADDRESS_1_{source}']\n",
    "    df['ADDRESS_2'] = df[f'ADDRESS_2_{source}']\n",
    "    df['CITY'] = df[f'CITY_{source}']\n",
    "    df['STATE'] = df[f'STATE_{source}']\n",
    "    df['ZIPCODE'] = df[f'ZIP_{source}']\n",
    "    df['PHONE'] = df[f'{source}_PHONE']\n",
    "    numb_list = list(range(0,len(df)))\n",
    "    df['KEY'] = [str(s) + source for s in numb_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_list = [\n",
    "    {'SOURCE':'DHC',\n",
    "    'DATA':dhc},\n",
    "    {'SOURCE':'IQVIA',\n",
    "    'DATA':iqvia},\n",
    "    {'SOURCE':'SYMPHONY',\n",
    "    'DATA':symphony},\n",
    "    {'SOURCE':'GOV',\n",
    "    'DATA':gov}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symphony['SYMPHONY_PHONE']=symphony.SYM_PHONE\n",
    "symphony['IQVIA_ME'] = symphony.SYM_ME\n",
    "iqvia['IQVIA_ME'] = iqvia.ME\n",
    "dhc['IQVIA_ME'] = [x[0:10] for x in fix_me(dhc.ME)]\n",
    "gov['IQVIA_ME'] = [x[0:10] for x in fix_me(gov.ME)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_dict in source_list:\n",
    "    universalize_columns(source_dict['DATA'], source_dict['SOURCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix(component):\n",
    "    component = component.strip().upper()\n",
    "    return component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_zipcode(num):\n",
    "    num = str(num).strip().replace('.0', '')\n",
    "    num = ''.join(filter(str.isdigit, num))\n",
    "    if len(num) > 5:\n",
    "        num = num[:-4]\n",
    "    if len(num) == 4:\n",
    "        num = '0' + num\n",
    "    elif len(num) == 3:\n",
    "        num = '00' + num\n",
    "    elif len(num) == 2:\n",
    "        num = '000' + num\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_address(moar, source):\n",
    "    dict_list = []\n",
    "    mes = []\n",
    "    for row in moar.itertuples():\n",
    "        addr_2 = clean_address_two(row.ADDRESS_2)\n",
    "        address = f'{fix(row.ADDRESS_1)}{addr_2}, {fix(row.CITY)}, {fix(row.STATE)}'\n",
    "        try:\n",
    "            address_dict = usaddress.tag(address)[0]\n",
    "        except usaddress.RepeatedLabelError as e:\n",
    "            print(e.original_string)\n",
    "            address_dict = error_handle(e.parsed_string)\n",
    "            print('')\n",
    "        address_dict['KEY'] = row.KEY\n",
    "        address_dict['PHONE'] = row.PHONE\n",
    "        address_dict['ZIPCODE'] = row.ZIPCODE\n",
    "        address_dict['ZIP'] = fix_zipcode(row.ZIPCODE)\n",
    "        dict_list.append(address_dict)\n",
    "        mes.append(row.IQVIA_ME)\n",
    "    parsed_df = pd.DataFrame(dict_list)\n",
    "    parsed_df.dropna(how='all', axis=1, inplace=True)\n",
    "    parsed_df.columns = [f'{c}_{source}' for c in parsed_df.columns.values]\n",
    "    parsed_df['IQVIA_ME'] = mes\n",
    "    return (parsed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source_dict in source_list:\n",
    "    source_dict['PARSED_DATA'] = parse_address(source_dict['DATA'], source_dict['SOURCE'])\n",
    "all_the_data = source_list[0]['PARSED_DATA'].merge(source_list[1]['PARSED_DATA'],on='IQVIA_ME',how='outer').merge(source_list[2]['PARSED_DATA'],on='IQVIA_ME',how='outer').merge(source_list[3]['PARSED_DATA'],on='IQVIA_ME',how='outer')\n",
    "all_the_data['ROW_KEY'] = list(range(0,len(all_the_data)))\n",
    "all_the_data = all_the_data.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = []\n",
    "for row in all_the_data.itertuples():\n",
    "    count = 0\n",
    "    phone_num = 'None'\n",
    "    symph_phone = row.PHONE_SYMPHONY\n",
    "    dhc_phone = row.PHONE_DHC\n",
    "    iqvia_phone = row.PHONE_IQVIA\n",
    "    data_phone = row.PHONE_GOV\n",
    "    if symph_phone == dhc_phone and symph_phone != 'None':\n",
    "        MATCHES = 'Symphony, DHC'\n",
    "        phone_num = symph_phone\n",
    "        if dhc_phone == iqvia_phone:\n",
    "            count = 2\n",
    "            MATCHES = 'Symphony, DHC, IQVia'\n",
    "            if dhc_phone == data_phone:\n",
    "                count = 3\n",
    "                MATCHES = 'Symphony, DHC, IQVia, DataGov'\n",
    "        elif dhc_phone == data_phone:\n",
    "            count = 2\n",
    "            MATCHES = 'Symphony, DHC, DataGov'\n",
    "        else:\n",
    "            count = 1       \n",
    "    elif symph_phone == iqvia_phone and symph_phone != 'None':\n",
    "        phone_num = symph_phone\n",
    "        MATCHES = 'Symphony, IQVia'\n",
    "        count = 1\n",
    "        if symph_phone == data_phone:\n",
    "            count = 2\n",
    "            MATCHES = 'Symphony, IQVia, DataGov'\n",
    "    elif symph_phone == data_phone and symph_phone != 'None':\n",
    "        phone_num = symph_phone\n",
    "        MATCHES = 'Symphony, DataGov'\n",
    "        count = 1\n",
    "        \n",
    "    elif dhc_phone == iqvia_phone and dhc_phone != 'None':\n",
    "        phone_num = dhc_phone\n",
    "        MATCHES = 'DHC, IQVia'\n",
    "        count = 1\n",
    "        if dhc_phone == data_phone:\n",
    "            MATCHES = 'DHC, IQVia, DataGov'\n",
    "            count = 2\n",
    "    elif dhc_phone == data_phone and dhc_phone != 'None':\n",
    "        phone_num = dhc_phone\n",
    "        MATCHES = 'DHC, DataGov'\n",
    "        count = 1\n",
    "    elif iqvia_phone == data_phone and iqvia_phone != 'None':\n",
    "            phone_num = iqvia_phone\n",
    "            MATCHES = 'IQVia, DataGov'\n",
    "            count = 1\n",
    "    if phone_num!='None':\n",
    "        dicto = {\n",
    "        'ROW_KEY': row.ROW_KEY,\n",
    "        'IQVIA_ME': row.IQVIA_ME,\n",
    "        'PHONE': phone_num,\n",
    "        'MATCHED': count,\n",
    "        'MATCHES': MATCHES\n",
    "    }\n",
    "        dict_list.append(dicto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_matches = pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_matches(THIS):\n",
    "    dict_list = []\n",
    "    for row in THIS.itertuples():\n",
    "        count = 0\n",
    "        phone_num = 'None'\n",
    "        symph_phone = row.AddressNumber_SYMPHONY + row.StreetName_SYMPHONY\n",
    "        dhc_phone = row.AddressNumber_DHC + row.StreetName_DHC\n",
    "        iqvia_phone = row.AddressNumber_IQVIA + row.StreetName_IQVIA\n",
    "        data_phone = row.AddressNumber_GOV + row.StreetName_GOV\n",
    "        if symph_phone == dhc_phone and symph_phone != 'NoneNone':\n",
    "            MATCHES = 'Symphony, DHC'\n",
    "            phone_num = symph_phone\n",
    "            if dhc_phone == iqvia_phone:\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, DHC, IQVia'\n",
    "                if dhc_phone == data_phone:\n",
    "                    count = 3\n",
    "                    MATCHES = 'Symphony, DHC, IQVia, DataGov'\n",
    "            elif dhc_phone == data_phone:\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, DHC, DataGov'\n",
    "            else:\n",
    "                count = 1       \n",
    "        elif symph_phone == iqvia_phone and symph_phone != 'NoneNone':\n",
    "            phone_num = symph_phone\n",
    "            MATCHES = 'Symphony, IQVia'\n",
    "            count = 1\n",
    "            if symph_phone == data_phone:\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, IQVia, DataGov'\n",
    "        elif symph_phone == data_phone and symph_phone != 'NoneNone':\n",
    "            phone_num = symph_phone\n",
    "            MATCHES = 'Symphony, DataGov'\n",
    "            count = 1\n",
    "\n",
    "        elif dhc_phone == iqvia_phone and dhc_phone != 'NoneNone':\n",
    "            phone_num = dhc_phone\n",
    "            MATCHES = 'DHC, IQVia'\n",
    "            count = 1\n",
    "            if dhc_phone == data_phone:\n",
    "                MATCHES = 'DHC, IQVia, DataGov'\n",
    "                count = 2\n",
    "        elif dhc_phone == data_phone and dhc_phone != 'NoneNone':\n",
    "            phone_num = dhc_phone\n",
    "            MATCHES = 'DHC, DataGov'\n",
    "            count = 1\n",
    "        elif iqvia_phone == data_phone and iqvia_phone != 'NoneNone':\n",
    "            phone_num = iqvia_phone\n",
    "            MATCHES = 'IQVia, DataGov'\n",
    "            count = 1\n",
    "        if phone_num!='None':\n",
    "            dicto = {\n",
    "            'ROW_KEY': row.ROW_KEY,\n",
    "            'IQVIA_ME': row.IQVIA_ME,\n",
    "            'ADDRESS': phone_num,\n",
    "            'MATCHED': count,\n",
    "            'ADDRESS_MATCHES': MATCHES\n",
    "        }\n",
    "            dict_list.append(dicto)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gah = count_matches(all_the_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gah_match = pd.DataFrame(gah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gah_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a_match(thing_1, thing_2):\n",
    "    if thing_1 == thing_2:\n",
    "        match = True\n",
    "    elif thing_1 in thing_2:\n",
    "        match = True\n",
    "    elif thing_2 in thing_1:\n",
    "        match = True\n",
    "    elif fuzz.ratio(thing_1, thing_2)>90:\n",
    "        match = True\n",
    "    else:\n",
    "        match = False\n",
    "    return(match)\n",
    "\n",
    "def count_fuzzy_matches(THIS):\n",
    "    dict_list = []\n",
    "    for row in THIS.itertuples():\n",
    "        count = 0\n",
    "        phone_num = 'None'\n",
    "        symph_phone = row.AddressNumber_SYMPHONY + row.StreetName_SYMPHONY\n",
    "        dhc_phone = row.AddressNumber_DHC + row.StreetName_DHC\n",
    "        iqvia_phone = row.AddressNumber_IQVIA + row.StreetName_IQVIA\n",
    "        data_phone = row.AddressNumber_GOV + row.StreetName_GOV\n",
    "        if is_a_match(symph_phone,dhc_phone) and symph_phone != 'NoneNone':\n",
    "            MATCHES = 'Symphony, DHC'\n",
    "            phone_num = symph_phone\n",
    "            if is_a_match(dhc_phone,iqvia_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, DHC, IQVia'\n",
    "                if is_a_match(dhc_phone,data_phone):\n",
    "                    count = 3\n",
    "                    MATCHES = 'Symphony, DHC, IQVia, DataGov'\n",
    "            elif is_a_match(dhc_phone,data_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, DHC, DataGov'\n",
    "            else:\n",
    "                count = 1       \n",
    "        elif is_a_match(symph_phone,iqvia_phone) and symph_phone != 'NoneNone':\n",
    "            phone_num = symph_phone\n",
    "            MATCHES = 'Symphony, IQVia'\n",
    "            count = 1\n",
    "            if is_a_match(symph_phone,data_phone):\n",
    "                count = 2\n",
    "                MATCHES = 'Symphony, IQVia, DataGov'\n",
    "        elif is_a_match(symph_phone,data_phone) and symph_phone != 'NoneNone':\n",
    "            phone_num = symph_phone\n",
    "            MATCHES = 'Symphony, DataGov'\n",
    "            count = 1\n",
    "\n",
    "        elif is_a_match(dhc_phone,iqvia_phone) and dhc_phone != 'NoneNone':\n",
    "            phone_num = iqvia_phone\n",
    "            MATCHES = 'DHC, IQVia'\n",
    "            count = 1\n",
    "            if is_a_match(iqvia_phone,data_phone):\n",
    "                MATCHES = 'DHC, IQVia, DataGov'\n",
    "                count = 2\n",
    "        elif is_a_match(dhc_phone,data_phone) and dhc_phone != 'NoneNone':\n",
    "            phone_num = data_phone\n",
    "            MATCHES = 'DHC, DataGov'\n",
    "            count = 1\n",
    "        elif is_a_match(iqvia_phone,data_phone) and iqvia_phone != 'NoneNone':\n",
    "            phone_num = iqvia_phone\n",
    "            MATCHES = 'IQVia, DataGov'\n",
    "            count = 1\n",
    "        if phone_num!='None':\n",
    "            dicto = {\n",
    "            'ROW_KEY': row.ROW_KEY,\n",
    "            'IQVIA_ME': row.IQVIA_ME,\n",
    "            'ADDRESS': phone_num,\n",
    "            'MATCHED': count,\n",
    "            'ADDRESS_MATCHES': MATCHES\n",
    "        }\n",
    "            dict_list.append(dicto)\n",
    "    return dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bah = count_fuzzy_matches(all_the_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_match = pd.DataFrame(bah)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bopbopbop = pd.merge(phone_matches, add_match, on=['ROW_KEY','IQVIA_ME'],suffixes=['_PHONE','_ADDRESS'], how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqvia[iqvia.IQVIA_ME.isin(bopbopbop.IQVIA_ME)==False].drop_duplicates('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bopbopbop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "15750+3514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_DEAL = pd.merge(bopbopbop, all_the_data, on=['ROW_KEY', 'IQVIA_ME']).drop_duplicates(['IQVIA_ME','PHONE','ADDRESS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_the_data[all_the_data.ROW_KEY==0].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqvia[iqvia.KEY=='23190IQVIA']['CITY'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count =0\n",
    "for row in bopbopbop.itertuples():\n",
    "    if row.MATCHES != row.ADDRESS_MATCHES:\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_DEAL = REAL_DEAL.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictss = []\n",
    "for row in REAL_DEAL.itertuples():\n",
    "    if row.ADDRESS_MATCHES == 'None':\n",
    "        print('Address mismatch')\n",
    "        continue\n",
    "    sources = row.ADDRESS_MATCHES\n",
    "    address = row.ADDRESS\n",
    "    phone = row.PHONE\n",
    "    phone_source = 'Multiple'\n",
    "    address_source = sources\n",
    "    if \"IQVia\" in sources and row.StreetName_IQVIA in address:\n",
    "        KEY = row.KEY_IQVIA\n",
    "        state = row.StateName_IQVIA\n",
    "        long_zipcode = row.ZIPCODE_IQVIA\n",
    "        zipcode = row.ZIP_IQVIA\n",
    "        city = iqvia[iqvia.KEY==KEY]['CITY'].values[0]\n",
    "        address_1 = iqvia[iqvia.KEY==KEY]['ADDRESS_1'].values[0]\n",
    "        address_2 = iqvia[iqvia.KEY==KEY]['ADDRESS_2'].values[0]\n",
    "        if phone == 'None':\n",
    "            phone = row.PHONE_IQVIA\n",
    "            phone_source = 'IQVia'\n",
    "        address_source = 'IQVia'\n",
    "    elif \"DataGov\" in sources and row.StreetName_GOV in address:\n",
    "        KEY = row.KEY_GOV\n",
    "        state = row.StateName_GOV\n",
    "        long_zipcode = row.ZIPCODE_GOV\n",
    "        zipcode = row.ZIP_GOV\n",
    "        city = gov[gov.KEY==KEY]['CITY'].values[0]\n",
    "        address_1 = gov[gov.KEY==KEY]['ADDRESS_1'].values[0]\n",
    "        address_2 = gov[gov.KEY==KEY]['ADDRESS_2'].values[0]\n",
    "        if phone == 'None':\n",
    "            phone = row.PHONE_GOV\n",
    "            phone_source = 'DataGov'\n",
    "        address_source = 'DataGov'\n",
    "    elif \"Symphony\" in sources and row.StreetName_SYMPHONY in address:\n",
    "        KEY = row.KEY_SYMPHONY\n",
    "        state = row.StateName_SYMPHONY\n",
    "        long_zipcode = row.ZIPCODE_SYMPHONY\n",
    "        zipcode = row.ZIP_SYMPHONY\n",
    "        city = symphony[symphony.KEY==KEY]['CITY'].values[0]\n",
    "        address_1 = symphony[symphony.KEY==KEY]['ADDRESS_1'].values[0]\n",
    "        address_2 = symphony[symphony.KEY==KEY]['ADDRESS_2'].values[0]\n",
    "        if phone == 'None':\n",
    "            phone = row.PHONE_SYMPHONY\n",
    "            phone_source = 'Symphony'\n",
    "        address_source = 'Symphony'\n",
    "    NEW_DICT = {\n",
    "        'ROW_KEY': row.ROW_KEY,\n",
    "        'ME_IQVIA': row.IQVIA_ME,\n",
    "        'ADDRESS_MATCHES': row.ADDRESS_MATCHES,\n",
    "        'PHONE_MATCHES': row.MATCHES,\n",
    "        'ADDRESS_1': address_1,\n",
    "        'ADDRESS_2': address_2,\n",
    "        'CITY': city,\n",
    "        'STATE': state,\n",
    "        'ZIPCODE_FULL': long_zipcode,\n",
    "        'ZIPCODE': zipcode,\n",
    "        'PHONE': phone,\n",
    "        'PHONE_SOURCE': phone_source,\n",
    "        'ADDRESS_SOURCE': address_source,\n",
    "        'ADDRESS_KEY': address,\n",
    "        'DATA_KEY': KEY\n",
    "    }\n",
    "    dictss.append(NEW_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data = pd.DataFrame(dictss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_good_data = good_data[good_data.PHONE!='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_adds = REAL_DEAL[REAL_DEAL.IQVIA_ME.isin(good_data.ME_IQVIA)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_adds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_dictss = []\n",
    "for row in no_adds.itertuples():\n",
    "    sources = row.MATCHES\n",
    "    phone = row.PHONE\n",
    "    phone_source = 'Multiple'\n",
    "    if \"IQVia\" in sources:\n",
    "        KEY = row.KEY_IQVIA\n",
    "        state = row.StateName_IQVIA\n",
    "        long_zipcode = row.ZIPCODE_IQVIA\n",
    "        zipcode = row.ZIP_IQVIA\n",
    "        city = iqvia[iqvia.KEY==KEY]['CITY'].values[0]\n",
    "        address_1 = iqvia[iqvia.KEY==KEY]['ADDRESS_1'].values[0]\n",
    "        address_2 = iqvia[iqvia.KEY==KEY]['ADDRESS_2'].values[0]\n",
    "        address_source = 'IQVia'\n",
    "        address = row.AddressNumber_IQVIA+row.StreetName_IQVIA\n",
    "    elif \"DataGov\" in sources:\n",
    "        KEY = row.KEY_GOV\n",
    "        state = row.StateName_GOV\n",
    "        long_zipcode = row.ZIPCODE_GOV\n",
    "        zipcode = row.ZIP_GOV\n",
    "        city = gov[gov.KEY==KEY]['CITY'].values[0]\n",
    "        address_1 = gov[gov.KEY==KEY]['ADDRESS_1'].values[0]\n",
    "        address_2 = gov[gov.KEY==KEY]['ADDRESS_2'].values[0]\n",
    "        address_source = 'DataGov'\n",
    "        address = row.AddressNumber_GOV+row.StreetName_GOV\n",
    "    elif \"Symphony\" in sources:\n",
    "        KEY = row.KEY_SYMPHONY\n",
    "        state = row.StateName_SYMPHONY\n",
    "        long_zipcode = row.ZIPCODE_SYMPHONY\n",
    "        zipcode = row.ZIP_SYMPHONY\n",
    "        city = symphony[symphony.KEY==KEY]['CITY'].values[0]\n",
    "        address_1 = symphony[symphony.KEY==KEY]['ADDRESS_1'].values[0]\n",
    "        address_2 = symphony[symphony.KEY==KEY]['ADDRESS_2'].values[0]\n",
    "        address_source = 'Symphony'\n",
    "        address = row.AddressNumber_SYMPHONY+row.StreetName_SYMPHONY\n",
    "    NEW_DICT = {\n",
    "        'ROW_KEY': row.ROW_KEY,\n",
    "        'ME_IQVIA': row.IQVIA_ME,\n",
    "        'ADDRESS_MATCHES': row.ADDRESS_MATCHES,\n",
    "        'PHONE_MATCHES': row.MATCHES,\n",
    "        'ADDRESS_1': address_1,\n",
    "        'ADDRESS_2': address_2,\n",
    "        'CITY': city,\n",
    "        'STATE': state,\n",
    "        'ZIPCODE_FULL': long_zipcode,\n",
    "        'ZIPCODE': zipcode,\n",
    "        'PHONE': phone,\n",
    "        'PHONE_SOURCE': phone_source,\n",
    "        'ADDRESS_SOURCE': address_source,\n",
    "        'ADDRESS_KEY': address,\n",
    "        'DATA_KEY': KEY\n",
    "    }\n",
    "    phone_dictss.append(NEW_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_good_data = pd.concat([good_data, pd.DataFrame(phone_dictss)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_good_data.drop_duplicates('ME_IQVIA').groupby('PHONE_MATCHES').count()[['ROW_KEY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_iqvia = iqvia[(iqvia.IQVIA_ME.isin(more_good_data.ME_IQVIA)==False)&(iqvia.PHONE!='None')].sort_values('AFFIL_RANK', ascending=False).drop_duplicates('ME', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['ROW_KEY', 'ME_IQVIA', 'ADDRESS_MATCHES', 'PHONE_MATCHES', 'ADDRESS_1',\n",
    "       'ADDRESS_2', 'CITY', 'STATE', 'ZIPCODE_FULL', 'ZIPCODE', 'PHONE',\n",
    "       'PHONE_SOURCE', 'ADDRESS_SOURCE', 'ADDRESS_KEY', 'DATA_KEY']\n",
    "necessary_iqvia.columns\n",
    "necessary_iqvia['ROW_KEY']='None'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_iqvia = pd.merge(necessary_iqvia, all_the_data, left_on='KEY',right_on='KEY_IQVIA').drop_duplicates('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_iqvia['ADDRESS_MATCHES']='None'\n",
    "necessary_iqvia['PHONE_MATCHES']='None'\n",
    "necessary_iqvia['ZIPCODE_FULL']='None'\n",
    "necessary_iqvia['ZIPCODE']='None'\n",
    "necessary_iqvia['PHONE_SOURCE']='None'\n",
    "necessary_iqvia['ADDRESS_SOURCE']='None'\n",
    "necessary_iqvia['ADDRESS_KEY']='None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_iqvia['ADDRESS_MATCHES']='None'\n",
    "necessary_iqvia['PHONE_MATCHES']='None'\n",
    "necessary_iqvia['PHONE_SOURCE']='IQVia'\n",
    "necessary_iqvia['ADDRESS_SOURCE']='IQVia'\n",
    "necessary_iqvia['DATA_KEY']= necessary_iqvia.KEY_IQVIA_x\n",
    "necessary_iqvia['ADDRESS_KEY']= necessary_iqvia.AddressNumber_IQVIA_y + necessary_iqvia.StreetName_IQVIA_y\n",
    "necessary_iqvia['ROW_KEY']= necessary_iqvia.ROW_KEY_x\n",
    "necessary_iqvia['ME_IQVIA']= necessary_iqvia.IQVIA_ME_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_iqvia.AddressNumber_IQVIA_y + necessary_iqvia.StreetName_IQVIA_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(older_polos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(iqvia.drop_duplicates('ME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_good_data.drop_duplicates('ME_IQVIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_iqvia['ZIPCODE_FULL'] = necessary_iqvia['ZIPCODE_IQVIA_x']\n",
    "necessary_iqvia['ZIPCODE'] = necessary_iqvia['ZIP_IQVIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_good_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_OF_IT = pd.concat([necessary_iqvia[more_good_data.columns], more_good_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iqvia[iqvia.KEY=='11213IQVIA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_good_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in necessary_iqvia.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necessary_iqvia[['KEY_IQVIA_x','KEY_IQVIA_y','IQVIA_ME_x','IQVIA_ME_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eek = ALL_OF_IT.drop_duplicates('ME_IQVIA', keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_present_employment():\n",
    "    present_employment_key = {\n",
    "        11: 'Self-Employed Solo Practice',\n",
    "        13: 'Two Physician Practice-Full Or Part Owner',\n",
    "        21: 'Other-Patient Care',\n",
    "        22: 'Locum Tenens',\n",
    "        30: 'Group Practice',\n",
    "        35: 'HMO',\n",
    "        40: 'Medical School',\n",
    "        50: 'Non-Government Hospital',\n",
    "        63: 'City/County/State Government-Hospital',\n",
    "        64: 'City/County/State Government-Other Than Hospital',\n",
    "        81: 'Federal Government-Hospital/Army',\n",
    "        82: 'Federal Government-Hospital/Navy',\n",
    "        83: 'Federal Government-Hospital/Air Force',\n",
    "        84: 'Federal Government-Hospital/Usphs',\n",
    "        85: 'Federal Government-Hospital/Vet Admin',\n",
    "        86: 'Federal Government-Hospital/Other Agency',\n",
    "        101: 'Other/Non-Patient Care',\n",
    "        110: 'No Classification'\n",
    "    }\n",
    "    return present_employment_key\n",
    "\n",
    "def humach_samplify(data):\n",
    "    present_employment_key = get_present_employment()\n",
    "    data['DESCRIPTION'] = [present_employment_key[x] for x in data.PE_CD]\n",
    "    new_columns = {\n",
    "        'ADDRESS_1':'POLO_MAILING_LINE_1',\n",
    "        'ADDRESS_2':'POLO_MAILING_LINE_2',\n",
    "        'CITY':'POLO_CITY',\n",
    "        'STATE':'POLO_STATE',\n",
    "        'ZIPCODE':'POLO_ZIP',\n",
    "        'PHONE':'TELEPHONE_NUMBER'}\n",
    "    humach_columns = [\n",
    "        'ME',\n",
    "        'FIRST_NAME',\n",
    "        'MIDDLE_NAME',\n",
    "        'LAST_NAME',\n",
    "        'SUFFIX',\n",
    "        'ADDRESS_1',\n",
    "        'ADDRESS_2',\n",
    "        'CITY',\n",
    "        'STATE',\n",
    "        'ZIPCODE',\n",
    "        'PHONE',\n",
    "        'PRIM_SPEC_CD',\n",
    "        'DESCRIPTION',\n",
    "        'PE_CD',\n",
    "        'FAX_NUMBER'\n",
    "    ]\n",
    "    humach_data = data[humach_columns].rename(columns = new_columns)\n",
    "    return humach_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_good_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD = older_polos[['ADDR_1_POLO','IQVIA_ME','ME',\n",
    "        'FIRST_NAME',\n",
    "        'MIDDLE_NAME',\n",
    "        'LAST_NAME',\n",
    "        'SUFFIX',\n",
    "        'PRIM_SPEC_CD',\n",
    "        'PE_CD',\n",
    "        'FAX_NUMBER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check zip phone area\n",
    "#check license\n",
    "#check 100 miles \n",
    "#check match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX = pd.merge(PPD, eek, left_on='IQVIA_ME', right_on='ME_IQVIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA = humach_samplify(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER = pd.read_csv('../../Data/POLO_Filter/Filtered_POLOs_Humach_Sample_2021-08-26.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX['FAX_NUMBER'] = [use.fix_phone(x) for x in XX.FAX_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER['ME'] = fix_me(OTHER.ME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER.to_excel('../../Data/POLO_Filter/Filtered_POLOs_Humach_Sample_2021-08-26.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BA.to_excel('../../Data/POLO_Filter/Older_POLOs_Humach_Sample_2021-08-26.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER.drop_duplicates('ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_good_data.drop_duplicates('ME_IQVIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#robust matching on disparate address elements + phone\n",
    "#data is included if there is corroboration between at least two sources\n",
    "#if addresses agreed and phones did not, phone was taken from IQVia, DataGov, or symphony in that preferred order\n",
    "#If phones agreed and addresses did not, address was taken from IQVia, DataGov, or symphony in that preferred order\n",
    "#if no agreement between sources, best IQVia affiliation was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
