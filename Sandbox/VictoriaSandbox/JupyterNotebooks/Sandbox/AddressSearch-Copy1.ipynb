{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from datetime import date\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.expected_conditions import presence_of_element_located\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import pandas as pd\n",
    "import json\n",
    "from bing import bing_search\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd = pd.read_csv('../../Data/PPD/ppd_data_20210410.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample = pd.read_excel('../../Data/PhoneAppend/validated_phones_and_polos_2021-03-23.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample = pd.read_excel('../../Data/Humach/top-ranked-address_agree-any.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample = pd.merge(humach_sample, ppd, right_on='ME', left_on='ME_NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = pd.read_csv('../../Data/PPD/speciality_id.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait(browser):\n",
    "    '''Define wait'''\n",
    "    return WebDriverWait(browser, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver, results = bing_search('MICHAEL J STANFORD MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"b_results\"]/li[11]/nav/ul/li[6]/a').click()\n",
    "driver.find_element_by_xpath('//*[@id=\"b_results\"]/li[15]/nav/ul/li[8]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_elements_by_tag_name(\"h2\")[1].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = driver.find_element_by_tag_name('body').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = test.replace(' ','').replace(')','').replace('(','').replace('-','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(new_test)):\n",
    "    if new_test[x:x+10].isnumeric():\n",
    "        print(new_test[x:x+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample = humach_sample.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = pd.merge(ppd, new_sample, on='ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE.columns = [c.replace(' ','_') for c in SAMPLE.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_find(row, driver):\n",
    "    driver.get('http://bing.com')\n",
    "    search_input = wait(driver).until(presence_of_element_located((By.ID, \"sb_form_q\")))\n",
    "#     if row.ADDR1 == 'None':\n",
    "#         addr_1 = ''\n",
    "#     else:\n",
    "#         addr_1 = row.ADDR1 + ' '\n",
    "    address_input = f'{row.MAILING_NAME} {row.ADDR_STATE} {row.DESC}'\n",
    "    search_input.send_keys(address_input)\n",
    "    search_input.send_keys(Keys.RETURN)\n",
    "    driver, dict_list = get_infos (driver, row)\n",
    "    return (driver, dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_find(row, driver):\n",
    "    driver.get('http://bing.com')\n",
    "    search_input = wait(driver).until(presence_of_element_located((By.ID, \"sb_form_q\")))\n",
    "    if row.OFFICE_ADDRESS_LINE_1 == 'None':\n",
    "        addr_1 = ''\n",
    "    else:\n",
    "        addr_1 = row.OFFICE_ADDRESS_LINE_1 + ' '\n",
    "    address_input = f'{row.MAILING_NAME} {addr_1}{row.OFFICE_ADDRESS_LINE_2} {row.OFFICE_ADDRESS_CITY} {row.OFFICE_ADDRESS_STATE} {row.OFFICE_ADDRESS_ZIP}'\n",
    "    search_input.send_keys(address_input)\n",
    "    search_input.send_keys(Keys.RETURN)\n",
    "    driver, dict_list = get_infos (driver, row)\n",
    "    return (driver, dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE =  SAMPLE.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_and_find(row, driver):\n",
    "    driver.get('http://bing.com')\n",
    "    search_input = wait(driver).until(presence_of_element_located((By.ID, \"sb_form_q\")))\n",
    "    if row.ADDR1 == 'None':\n",
    "        addr_1 = ''\n",
    "    else:\n",
    "        addr_1 = row.ADDR1 + ' '\n",
    "    address_input = f'{row.MAILING_NAME} {addr_1}{row.ADDR2} {row.ADDR_STATE} {row.ADDR_CITY} {row.ADDR_STATE} {row.ADDR_ZIP}'\n",
    "    search_input.send_keys(address_input)\n",
    "    search_input.send_keys(Keys.RETURN)\n",
    "    driver, dict_list = get_infos (driver, row)\n",
    "    return (driver, dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_list = []\n",
    "new_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_count = 0\n",
    "for row in fuck[new_count:].itertuples():\n",
    "    driver, new_list = search_and_find(row, driver)\n",
    "    address_list.append(new_list)\n",
    "    new_count+=1\n",
    "    print(f'{round((new_count/52*100),2)}% done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXTRA_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results.groupby(['NAME','NUMBERS']).count().sort_values('URL', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(address_results.drop_duplicates('NAME'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_class_name(\"sb_pagN\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(this).to_csv('../../Data/PhoneAppend/PhoneAppend_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results.to_csv('../../Data/PhoneAppend/PhoneAppend_NameAddressInput_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results = pd.DataFrame(this_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_results = pd.DataFrame(this_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_results.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this =[]\n",
    "for thing in all_list:\n",
    "    for thing_2 in thing:\n",
    "        this.append(thing_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_5 =[]\n",
    "for thing in address_list:\n",
    "    for thing_2 in thing:\n",
    "        this_5.append(thing_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_3 =[]\n",
    "for thing in EXTRA_list:\n",
    "    for thing_2 in thing:\n",
    "        this_3.append(thing_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_results = pd.DataFrame(this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuck = SAMPLE[SAMPLE.MAILING_NAME.isin(address_results.NAME)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuck = pd.read_csv('../../Data/PhoneAppend/unfinished_name_address_input.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuck.to_csv('../../Data/PhoneAppend/unfinished_name_address_input.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results.to_csv('../../Data/PhoneAppend/AddressInput_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.find_element_by_class_name(\"sb_pagN\").click()\n",
    "driver, dict_list_2 = get_infos(driver, address_input)\n",
    "driver.find_element_by_class_name(\"sb_pagN\").click()\n",
    "driver, dict_list_3 = get_infos(driver, address_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_input = wait(driver).until(presence_of_element_located((By.ID, \"sb_form_q\")))\n",
    "address_input = 'NADHIWAN S MAISIAK MD'\n",
    "search_input.send_keys(address_input)\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "driver, dict_list = three_pages (driver, address_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a class=\"sb_pagN sb_pagN_bp b_widePag sb_bp \" title=\"Next page\" href=\"/search?q=NADHIWAN+S+MAISIAK+MDNADHIWAN+S+MAISIAK+MD&amp;qs=n&amp;sp=-1&amp;pq=nadhiwan+s+maisiak+mdnadhi&amp;sc=0-26&amp;sk=&amp;cvid=76C40EA626CB4B4F8E2408A01ED1251F&amp;first=15&amp;FORM=PORE\" h=\"ID=SERP,5534.1\"><div class=\"sw_next\">Next</div></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD_SPEC.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_result(row, result):\n",
    "    check = False\n",
    "    if row.LAST_NAME in result.upper() & row.FIRST_NAME in result.upper():\n",
    "        check = True\n",
    "    return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(driver):\n",
    "    current_results = driver.find_element_by_id(\"b_results\").text\n",
    "    result_list = current_results.split('...')\n",
    "    return(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_address_infos(driver, row):\n",
    "    name = row.MAILING_NAME\n",
    "    og_url = driver.current_url\n",
    "    maxi = len(driver.find_elements_by_tag_name(\"h2\"))\n",
    "    dict_list = []\n",
    "    for link in range(0,maxi):\n",
    "        try:\n",
    "            wait(driver).until(presence_of_element_located((By.TAG_NAME, \"h2\")))\n",
    "            try:\n",
    "                print(driver.find_elements_by_tag_name(\"h2\")[link].text)\n",
    "                driver.find_elements_by_tag_name(\"h2\")[link].click()\n",
    "            except:\n",
    "                continue\n",
    "            if driver.current_url!=og_url:\n",
    "                test = driver.find_element_by_tag_name('body').text\n",
    "                new_test = test.replace(' ','').replace(')','').replace('(','').replace('-','')\n",
    "                url = driver.current_url\n",
    "                for x in range(len(new_test)):\n",
    "                    potential_number = new_test[x:x+10]\n",
    "                    if potential_number.isnumeric():\n",
    "                        if potential_number[0]=='1':\n",
    "                            potential_number = new_test[x:x+11]\n",
    "                        print(potential_number)\n",
    "                        new_dict = {\n",
    "                            'NAME': name,\n",
    "                            'URL':driver.current_url,\n",
    "                            'NUMBERS': potential_number\n",
    "                        }\n",
    "                        dict_list.append(new_dict)\n",
    "                if driver.current_url!=og_url:\n",
    "                    driver.back()\n",
    "        except:\n",
    "            break\n",
    "#         driver.find_element_by_class_name(\"sb_pagN\").click()\n",
    "    return (driver, dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_infos(driver, row):\n",
    "    name = row.MAILING_NAME\n",
    "    og_url = driver.current_url\n",
    "    maxi = len(driver.find_elements_by_tag_name(\"h2\"))\n",
    "    dict_list = []\n",
    "    for link in range(0,maxi):\n",
    "        try:\n",
    "            wait(driver).until(presence_of_element_located((By.TAG_NAME, \"h2\")))\n",
    "            try:\n",
    "                print(driver.find_elements_by_tag_name(\"h2\")[link].text)\n",
    "                driver.find_elements_by_tag_name(\"h2\")[link].click()\n",
    "            except:\n",
    "                continue\n",
    "#             driver.current_url!=og_url:\n",
    "            test = driver.find_element_by_tag_name('body').text\n",
    "            new_test = test.replace(' ','').replace(')','').replace('(','').replace('-','')\n",
    "            url = driver.current_url\n",
    "            for x in range(len(new_test)):\n",
    "                potential_number = new_test[x:x+10]\n",
    "                if potential_number.isnumeric():\n",
    "                    if potential_number[0]=='1':\n",
    "                        potential_number = new_test[x:x+11]\n",
    "                    print(potential_number)\n",
    "                    new_dict = {\n",
    "                            'NAME': name,\n",
    "                            'URL':driver.current_url,\n",
    "                            'NUMBERS': potential_number\n",
    "                        }\n",
    "                    dict_list.append(new_dict)\n",
    "            if driver.current_url!=og_url:\n",
    "                driver.back()\n",
    "        except:\n",
    "            break\n",
    "#         driver.find_element_by_class_name(\"sb_pagN\").click()\n",
    "    return (driver, dict_list)\n",
    "def three_pages(driver, row):\n",
    "    dict_list = []\n",
    "    for x in range(1,3):\n",
    "        driver, dict_list = get_infos(driver, row, dict_list)\n",
    "    return (driver, dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_results = driver.find_element_by_id(\"b_results\").text\n",
    "result_list = current_results.split('https')\n",
    "result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3138732225'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_urls(doctor_tweets):\n",
    "    '''Go to each url and get full link lolol'''\n",
    "    links = list(doctor_tweets.LINK)\n",
    "    driver_path = 'C:/Users/vigrose/Jupyter Notebooks/chromedriver.exe'\n",
    "    driver = webdriver.Chrome(executable_path=driver_path)\n",
    "    new_links = []\n",
    "    for link in links:\n",
    "        print(link)\n",
    "        try:\n",
    "            driver.get(link)\n",
    "        \n",
    "            print(driver.current_url)\n",
    "            new_links.append(driver.current_url)\n",
    "        except:\n",
    "            new_links.append(link)\n",
    "    driver.close()\n",
    "    doctor_tweets['LINK'] = new_links\n",
    "    return doctor_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# options = webdriver.ChromeOptions() \n",
    "# options.add_argument(\"start-maximized\")\n",
    "# options.add_argument(\"--headless\")\n",
    "# options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "# options.add_experimental_option('useAutomationExtension', False)\n",
    "# driver = webdriver.Chrome(options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd.head()[['MAILING_NAME','TELEPHONE_NUMBER']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd = ppd.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(int(x)) if x!='None' else x for x in ppd.head().TELEPHONE_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_spec = pd.merge(ppd, specs, left_on='PRIM_SPEC_CD', right_on='SPEC_CD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otherlist = []\n",
    "uniques = []\n",
    "count = 0\n",
    "for row in humach_sample[count:].itertuples():\n",
    "    unique = True\n",
    "    others = len(ppd[(ppd.LAST_NAME == row.LNAME)&(ppd.FIRST_NAME == row.FNAME)])\n",
    "    if others>1:\n",
    "        unique = False\n",
    "        print(f'{row.FNAME}{row.LNAME}:{others}')\n",
    "    otherlist.append(others)\n",
    "    uniques.append(unique)\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample = pd.merge(humach_sample, ppd_spec[['MAILING_NAME','ME']], on='ME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ppd_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(uniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "state_area = pd.read_excel(\"../../Data/PhoneAppend/state_area.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {\n",
    "        'Alabama': 'AL',\n",
    "        'Alaska': 'AK',\n",
    "        'American Samoa': 'AS',\n",
    "        'Arizona': 'AZ',\n",
    "        'Arkansas': 'AR',\n",
    "        'California': 'CA',\n",
    "        'Colorado': 'CO',\n",
    "        'Connecticut': 'CT',\n",
    "        'Delaware': 'DE',\n",
    "        'District of Columbia': 'DC',\n",
    "        'Florida': 'FL',\n",
    "        'Georgia': 'GA',\n",
    "        'Guam': 'GU',\n",
    "        'Hawaii': 'HI',\n",
    "        'Idaho': 'ID',\n",
    "        'Illinois': 'IL',\n",
    "        'Indiana': 'IN',\n",
    "        'Iowa': 'IA',\n",
    "        'Kansas': 'KS',\n",
    "        'Kentucky': 'KY',\n",
    "        'Louisiana': 'LA',\n",
    "        'Maine': 'ME',\n",
    "        'Maryland': 'MD',\n",
    "        'Massachusetts': 'MA',\n",
    "        'Michigan': 'MI',\n",
    "        'Minnesota': 'MN',\n",
    "        'Mississippi': 'MS',\n",
    "        'Missouri': 'MO',\n",
    "        'Montana': 'MT',\n",
    "        'Nebraska': 'NE',\n",
    "        'Nevada': 'NV',\n",
    "        'New Hampshire': 'NH',\n",
    "        'New Jersey': 'NJ',\n",
    "        'New Mexico': 'NM',\n",
    "        'New York': 'NY',\n",
    "        'North Carolina': 'NC',\n",
    "        'North Dakota': 'ND',\n",
    "        'Northern Mariana Islands':'MP',\n",
    "        'Ohio': 'OH',\n",
    "        'Oklahoma': 'OK',\n",
    "        'Oregon': 'OR',\n",
    "        'Pennsylvania': 'PA',\n",
    "        'Puerto Rico': 'PR',\n",
    "        'Rhode Island': 'RI',\n",
    "        'South Carolina': 'SC',\n",
    "        'South Dakota': 'SD',\n",
    "        'Tennessee': 'TN',\n",
    "        'Texas': 'TX',\n",
    "        'Utah': 'UT',\n",
    "        'Vermont': 'VT',\n",
    "        'Virgin Islands': 'VI',\n",
    "        'Virginia': 'VA',\n",
    "        'Washington': 'WA',\n",
    "        'West Virginia': 'WV',\n",
    "        'Wisconsin': 'WI',\n",
    "        'Wyoming': 'WY'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_area['STATE'] = [state_dict[x] if x!='Washington, DC' else 'DC' for x in state_area.State]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD_SPEC = pd.merge(ppd_spec, state_area, left_on='POLO_STATE', right_on='STATE', suffixes = ['_PPMA',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMACH_SAMPLE = pd.merge(humach_sample, state_area, left_on='ADDR_STATE', right_on='STATE', suffixes = ['_PPMA',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_area.to_csv('../../Data/PhoneAppend/state_area_codes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample['OTHER_COUNT']=otherlist\n",
    "humach_sample['UNIQUE']=uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_spec = ppd_spec.fillna('None')\n",
    "# sample_1 = ppd_spec[(ppd_spec.TELEPHONE_NUMBER!='None')&(ppd_spec.TELEPHONE_NUMBER!='None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPD_SPEC = PPD_SPEC.fillna('None')\n",
    "PPD_SPEC = PPD_SPEC[PPD_SPEC.TELEPHONE_NUMBER!='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleo = PPD_SPEC[PPD_SPEC.UNIQUE==True].sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(x)[0:3] for x in PPD_SPEC.TELEPHONE_NUMBER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(PPD_SPEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for row in HUMACH_SAMPLE.itertuples():\n",
    "    match = False\n",
    "    codes = str(row.Areacodes).split(',\\xa0')\n",
    "    if str(row.OFFICE_PHONE)[0:3] in codes:\n",
    "        match = True\n",
    "    matches.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMACH_SAMPLE['STATE_AREA_MATCH'] = matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD_SPEC['STATE_AREA_MATCH'] = matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPD_SPEC[(PPD_SPEC.STATE_AREA_MATCH==False)&(PPD_SPEC.TOP_CD==20)][['TELEPHONE_NUMBER', 'STATE_PPMA','STATE','Areacodes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUMACH_SAMPLE[HUMACH_SAMPLE.STATE_AREA_MATCH==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "94990/len(PPD_SPEC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "90627/len(PPD_SPEC[PPD_SPEC.TOP_CD==20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(x).split(',\\xa0') for x in state_area.Areacodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "if row.MAILING_LINE_1 != 'None':\n",
    "    new_dict['address'] = f'{row.MAILING_LINE_1} {row.MAILING_LINE_2}'\n",
    "else:\n",
    "    new_dict['address'] = row.MAILING_LINE_2\n",
    "new_dict['city'] = row.CITY\n",
    "new_dict['state'] = row.STATE\n",
    "new_dict['address_type'] = row.ADDRESS_TYPE\n",
    "new_dict['zipcode'] = str(int(row.ZIP))\n",
    "driver.get(\"http://bing.com\")\n",
    "search_input = wait(driver).until(presence_of_element_located((By.ID, \"sb_form_q\")))\n",
    "address_input = f\"{new_dict['address']} {new_dict['city']} {new_dict['state']} {new_dict['zipcode']}\"\n",
    "print(address_input)\n",
    "search_input.send_keys(address_input)\n",
    "search_input.send_keys(Keys.RETURN)\n",
    "current_results = driver.find_element_by_id(\"b_results\").text\n",
    "new_dict['results'] = current_results\n",
    "dict_list.append(new_dict)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = '10819 S Drake Ave'\n",
    "specialty = 'Chicago'\n",
    "degree = '60655'\n",
    "home_office = 0\n",
    "for result in result_list:\n",
    "    good = False\n",
    "    office_score = 0\n",
    "    home_score = 0\n",
    "    print(result)\n",
    "    if address in result:\n",
    "        if city in result:\n",
    "            good = True\n",
    "        elif zipcode in result:\n",
    "            good = True\n",
    "    if good == True:\n",
    "        for word in office_words:\n",
    "            if word in result.lower():\n",
    "                office_score += 1\n",
    "        for word in home_words:\n",
    "            if word in result.lower():\n",
    "                home_score += 1\n",
    "        print(office_score)\n",
    "        print(home_score)\n",
    "        if office_score > home_score:\n",
    "            home_office +=1\n",
    "        elif home_score > office_score:\n",
    "            home_office -= 1\n",
    "print(home_office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_sample = pd.read_csv('../../Data/ppd/address_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd_sample = ppd_sample.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_results(ppd_sample, driver):\n",
    "    dict_list = []\n",
    "    all_results = []\n",
    "    for row in ppd_sample.itertuples():\n",
    "        new_dict = {}\n",
    "        if row.MAILING_LINE_1 != 'None':\n",
    "            new_dict['address'] = f'{row.MAILING_LINE_1} {row.MAILING_LINE_2}'\n",
    "        else:\n",
    "            new_dict['address'] = row.MAILING_LINE_2\n",
    "        new_dict['city'] = row.CITY\n",
    "        new_dict['state'] = row.STATE\n",
    "        new_dict['address_type'] = row.ADDRESS_TYPE\n",
    "        new_dict['zipcode'] = str(int(row.ZIP))\n",
    "        driver.get(\"http://bing.com\")\n",
    "        search_input = wait(driver).until(presence_of_element_located((By.ID, \"sb_form_q\")))\n",
    "        address_input = f\"{new_dict['address']} {new_dict['city']} {new_dict['state']} {new_dict['zipcode']}\"\n",
    "        print(address_input)\n",
    "        search_input.send_keys(address_input)\n",
    "        search_input.send_keys(Keys.RETURN)\n",
    "        current_results = driver.find_element_by_id(\"b_results\").text\n",
    "        all_results.append(current_results)\n",
    "        new_dict['results'] = current_results\n",
    "        dict_list.append(new_dict)\n",
    "        time.sleep(1)\n",
    "    return(dict_list, all_results)\n",
    "\n",
    "def address_match(address, results):\n",
    "    match = 0\n",
    "    for word in address.split(' '):\n",
    "        if word in results:\n",
    "            match += 1\n",
    "    if match/len(address.split(' ')) > 0.8:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def get_address_type(result_dict):\n",
    "    home_office = 0\n",
    "    result_list = result_dict['results'].split('...')\n",
    "    for result in result_list:\n",
    "        good = False\n",
    "        office_score = 0\n",
    "        home_score = 0\n",
    "        print(result)\n",
    "        result = result.lower()\n",
    "        print(result_dict['address'])\n",
    "        result_dict_address = result_dict['address']\n",
    "        if 'APT' in result_dict_address:\n",
    "            result_dict_address = result_dict_address.split('APT')[0]\n",
    "        if address_match(result_dict_address.lower(),result):\n",
    "            if result_dict['city'].lower() in result:\n",
    "                good = True\n",
    "            elif str(int(result_dict['zipcode'])) in result:\n",
    "                good = True\n",
    "        if good == True:\n",
    "            for word in office_words:\n",
    "                if word in result:\n",
    "                    office_score += 1\n",
    "            for word in home_words:\n",
    "                if word in result:\n",
    "                    home_score += 1\n",
    "            print(office_score)\n",
    "            print(home_score)\n",
    "            if office_score > home_score:\n",
    "                home_office +=1\n",
    "            elif home_score > office_score:\n",
    "                home_office -= 1\n",
    "    return (home_office)\n",
    "\n",
    "def score_types(dict_list):\n",
    "    scores = []\n",
    "    for dicto in dict_list:\n",
    "        scores.append(get_address_type(dicto))\n",
    "    return(scores, dict_list)\n",
    "def append_correctness(dict_list, scores):\n",
    "    shit = pd.DataFrame(dict_list)\n",
    "    shit['SCORE'] = scores\n",
    "    corrects = []\n",
    "    for row in shit.itertuples():\n",
    "        correct = False\n",
    "        if row.address_type == 2.0 and row.SCORE < 0:\n",
    "            correct = True\n",
    "        elif row.address_type == 1.0 and row.SCORE > 0:\n",
    "            correct = True\n",
    "        corrects.append(correct)\n",
    "    shit['CORRECT']=corrects\n",
    "    return(shit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppd = pd.read_csv('../../Data/PPD/ppd_data_20210206.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ppd.sample(300)\n",
    "sample = sample.fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "dict_list, all_results = get_search_results(pp_sample, driver)\n",
    "driver.close()\n",
    "scores, dict_list = score_types(dict_list)\n",
    "# final_df = append_correctness(dict_list, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final_df[final_df['SCORE']!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('../../Data/PPD/ppd_shared_scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_words_x = {}\n",
    "home_words_x = {}\n",
    "for dicto in dict_list:\n",
    "    words = dicto['results'].split(' ')\n",
    "    if dicto['address_type'] == '2.0':\n",
    "        for word in words:\n",
    "            if word.lower() not in home_words_x.keys():\n",
    "                home_words_x[word.lower()] = 1\n",
    "            else:\n",
    "                print(home_words_x[word.lower()])\n",
    "                home_words_x[word.lower()]+=1\n",
    "    elif dicto['address_type'] == '1.0':\n",
    "        for word in words:\n",
    "            if word.lower() not in office_words_x:\n",
    "                office_words_x[word.lower()] = 1\n",
    "            else:\n",
    "                office_words_x[word.lower()] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_words_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in office_words_x.keys():\n",
    "    if word in home_words_x.keys():\n",
    "        office_words_x.remove(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "office_words_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_words_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shit = pd.DataFrame(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shit['SCORE'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_correctness(dict_list, scores)\n",
    "    shit = pd.DataFrame(dict_list)\n",
    "    shit['SCORE'] = scores\n",
    "    corrects = []\n",
    "    for row in shit.itertuples():\n",
    "        correct = False\n",
    "        if row.address_type == '2.0' and row.SCORE < 0:\n",
    "            correct = True\n",
    "        elif row.address_type == '1.0' and row.SCORE > 0:\n",
    "            correct = True\n",
    "        corrects.append(correct)\n",
    "    shit['CORRECT']=corrects\n",
    "    return(shit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shit['CORRECT']=corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shit[shit['CORRECT']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results = clean_phones(address_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(office_words_x, ['word','count']).transpose().sort_values('count',ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(home_words_x, ['word','count']).transpose().sort_values('count',ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shit.to_csv('../../Data/ppd/sample_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct(phone_results):\n",
    "    phone_results['WEBSITE'] = [x.split('/')[2] for x in phone_results.URL]\n",
    "    unique_phones = phone_results.drop_duplicates(['WEBSITE','NUMBERS'])\n",
    "# unique_phones.groupby(['NAME','NUMBERS']).count().to_csv('../../Data/PhoneAppend/Numbers_2.csv')\n",
    "    counts = unique_phones.groupby(['NAME','NUMBERS']).count()\n",
    "    correct = pd.merge(counts, humach_sample, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_PHONE'])\n",
    "    return (unique_phones, counts, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_unique_phones, add_counts, add_correct = get_correct(address_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(add_unique_phones, humach_sample, left_on='OFFICE_PHONE', right_on=['NUMBERS']).drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "135/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_results.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phones = phone_results.drop_duplicates(['WEBSITE','NUMBERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phones.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phones.groupby(['NAME','NUMBERS']).count().to_csv('../../Data/PhoneAppend/Numbers_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = unique_phones.groupby(['NAME','NUMBERS']).count()\n",
    "counts.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample['NUMBERS']=humach_sample.OFFICE_PHONE.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(final, humach_sample, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','NUMBERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = pd.merge(counts, humach_sample, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','NUMBERS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_numerics(seq):\n",
    "    seq_type= type(seq)\n",
    "    return seq_type().join(filter(seq_type.isdigit, seq))\n",
    "def is_repeating(number):\n",
    "    previous_digit = str(number)[0]\n",
    "    for digit in str(number):\n",
    "        if digit != previous_digit:\n",
    "            return(False)\n",
    "        else:\n",
    "            previous_digit = digit\n",
    "    return(True)\n",
    "def clean_phones(unique_phones):\n",
    "    num_list =[]\n",
    "    for number in unique_phones.NUMBERS:\n",
    "        new_number = number\n",
    "        if len(number)<10:\n",
    "            new_number = 'None'\n",
    "        elif len(number)>10:\n",
    "            if number[0]=='1':\n",
    "                new_number = number[1:]\n",
    "            new_number = only_numerics(new_number)\n",
    "        if len(new_number)!=10 or is_repeating(new_number):\n",
    "            new_number = 'None'\n",
    "        num_list.append(new_number)\n",
    "    unique_phones['OFFICE_PHONE'] = num_list\n",
    "    return(unique_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_repeating(number):\n",
    "    previous_digit = str(number)[0]\n",
    "    for digit in str(number):\n",
    "        if digit != previous_digit:\n",
    "            return(False)\n",
    "        else:\n",
    "            previous_digit = digit\n",
    "    return(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_phones(unique_phones):\n",
    "    num_list =[]\n",
    "    for number in unique_phones.NUMBERS:\n",
    "        new_number = number\n",
    "        if len(number)<10:\n",
    "            new_number = 'None'\n",
    "        elif len(number)>10:\n",
    "            if number[0]=='1':\n",
    "                new_number = number[1:]\n",
    "            new_number = only_numerics(new_number)\n",
    "        if len(new_number)!=10 or is_repeating(new_number):\n",
    "            new_number = 'None'\n",
    "        num_list.append(new_number)\n",
    "    unique_phones['OFFICE_PHONE'] = num_list\n",
    "    return(unique_phones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phones = unique_phones[unique_phones.OFFICE_PHONE!='None']\n",
    "counts = unique_phones.groupby(['NAME','OFFICE_PHONE']).count().sort_values('URL', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phones['OFFICE_PHONE'] = num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phones = unique_phones[unique_phones.OFFICE_PHONE!='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = unique_phones.groupby(['NAME','OFFICE_PHONE']).count().sort_values('URL', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.to_csv('../../Data/counts.csv')\n",
    "counts = pd.read_csv('../../Data/counts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranks(counts):\n",
    "    RANKS =[]\n",
    "    dicto ={}\n",
    "    for row in counts.itertuples():\n",
    "        if row.NAME in dicto.keys():\n",
    "            dicto[row.NAME]+=1\n",
    "        else:\n",
    "            dicto[row.NAME]=1\n",
    "        if row.URL == 1:\n",
    "            rank = 0\n",
    "        else:\n",
    "            rank = dicto[row.NAME]\n",
    "        RANKS.append(rank)\n",
    "    counts['RANK'] = RANKS\n",
    "    return(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_phones.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['WEBSITE_COUNT']=counts.URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts['OFFICE_PHONE']=counts.OFFICE_PHONE.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.merge(counts[['NAME', 'OFFICE_PHONE', 'RANK',\n",
    "       'WEBSITE_COUNT']], unique_phones, on=('NAME', 'OFFICE_PHONE'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[final.RANK==1].drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in final[final.RANK==1].groupby(['WEBSITE']).count().sort_values('NAME', ascending=False)[0:10].index:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZ[ZZ.OFFICE_PHONE.isin(correct.OFFICE_PHONE_x)].groupby(['WEBSITE']).count().sort_values('NAME', ascending=False).to_csv('../../Data/PhoneAppend/ACCURACY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.drop_duplicates(['WEBSITE', 'NAME']).groupby(['WEBSITE']).count().to_csv('../../Data/PhoneAppend/coverage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZZ = final.drop_duplicates(['WEBSITE', 'NAME','OFFICE_PHONE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = pd.read_csv('../../Data/PhoneAppend/coverage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = pd.read_csv('../../Data/PhoneAppend/ACCURACY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(coverage, accuracy, on='WEBSITE').to_csv(\"../../Data/PhoneAppend/website_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct.to_csv('../../Data/PhoneAppend/Humach_Sample_results_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct.groupby('RANK').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results = clean_phones(address_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(other_results, humach_sample, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','NUMBERS']).drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_results.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_2 = other_results.groupby(['NAME','NUMBERS']).count()\n",
    "counts_2\n",
    "get_ranks(counts_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_results.to_csv('../../Data/PhoneAppend/OnNameSpecState.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "humach_sample['OFFICE_PHONE']= [str(x) for x in humach_sample.OFFICE_PHONE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(humach_sample, address_results, on='OFFICE_PHONE').drop_duplicates('ME_NO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(humach_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results.NUMBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results = clean_phones(address_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results = address_results[address_results.OFFICE_PHONE!='None']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results['WEBSITE'] = [x.split('/')[2] for x in address_results.URL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLL = ['OFFICE_ADDRESS_LINE_1',\n",
    "'OFFICE_ADDRESS_LINE_2',\n",
    "'OFFICE_ADDRESS_CITY',\n",
    "'OFFICE_ADDRESS_STATE',\n",
    "'OFFICE_ADDRESS_ZIP',\n",
    "'OFFICE_ADDRESS_VERIFIED/UPDATED',\n",
    "'OFFICE_TELEPHONE',\n",
    "'OFFICE_PHONE_VERIFIED/UPDATED',\n",
    "'COMMENTS',\n",
    "'entity_id',\n",
    "'polo_comm_id',\n",
    "'polo_address_key',\n",
    "'polo_score',\n",
    "'top_comm_id',\n",
    "'address_key',\n",
    "'score',\n",
    "'dhc_match_top',\n",
    "'symphony_match_top',\n",
    "'top_matches_dhc_or_symphony',\n",
    "'iqvia_match_top',\n",
    "'updated_to_polo',\n",
    "'top_correct',\n",
    "'MAILING_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLL.append('MAILING_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(SAMPLE[COLL], address_results, left_on='MAILING_NAME', right_on='NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in SAMPLE.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_phones = address_results.drop_duplicates(['WEBSITE','NUMBERS'])\n",
    "# # unique_phones.groupby(['NAME','NUMBERS']).count().to_csv('../../Data/PhoneAppend/Numbers_2.csv')\n",
    "# counts = unique_phones.groupby(['NAME','OFFICE_PHONE']).count()\n",
    "correct = pd.merge(count, SAMPLE, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_TELEPHONE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD SYSTEM\n",
    "NEW SYSTEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.to_csv('../../Data/PhoneAppend/unique_phone_append.csv')\n",
    "count = pd.read_csv('../../Data/PhoneAppend/unique_phone_append.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE['OFFICE_TELEPHONE'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_sys = get_ranks(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_correct = pd.merge(old_sys, SAMPLE, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_TELEPHONE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_counts = address_results.groupby(['NAME','OFFICE_PHONE']).count()\n",
    "new_counts.to_csv('../../Data/PhoneAppend/all_phone_append.csv')\n",
    "new_count = pd.read_csv('../../Data/PhoneAppend/all_phone_append.csv')\n",
    "new_sys = get_ranks(new_count)\n",
    "new_correct = pd.merge(new_sys, SAMPLE, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_TELEPHONE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_correct.groupby('RANK').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_correct.groupby('RANK').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_correct.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_counts.sort_values('URL', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(new_sys, SAMPLE, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_TELEPHONE'], how='left').to_csv('../../Data/PhoneAppend/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_count.drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTY = new_count.sort_values('URL', ascending=False).drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTY_2 = count.sort_values('URL', ascending=False).drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy = pd.merge(TESTY, SAMPLE, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_TELEPHONE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample['OFFICE TELEPHONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE['OFFICE_TELEPHONE'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTY_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(TESTY_2, SAMPLE, left_on='NAME', right_on='MAILING_NAME')[['OFFICE_PHONE','OFFICE_TELEPHONE','WEBSITE']][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = pd.merge(TESTY_2, SAMPLE, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_TELEPHONE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy[yy.ME.isin(xx.ME)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "56\n",
    "80\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(xx, yy, on='ME', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([TESTY, TESTY_2]).drop_duplicates('OFFICE_PHONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_12 = pd.merge(state_area, SAMPLE[['OFFICE_ADDRESS_STATE', 'MAILING_NAME']], left_on='STATE', right_on='OFFICE_ADDRESS_STATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aah = pd.merge(address_results, check_12, left_on='NAME', right_on='MAILING_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = []\n",
    "for row in aah.itertuples():\n",
    "    match = False\n",
    "    codes = str(row.Areacodes).split(',\\xa0')\n",
    "    if str(row.OFFICE_PHONE)[0:3] in codes:\n",
    "        match = True\n",
    "    matches.append(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aah['AREA_CODE_MATCH'] = matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEEP = aah[aah.AREA_CODE_MATCH == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OTHER_counts = MEEP.groupby(['NAME','OFFICE_PHONE']).count()\n",
    "OTHER_counts.to_csv('../../Data/PhoneAppend/OTHER_phone_append.csv')\n",
    "OTHER_count = pd.read_csv('../../Data/PhoneAppend/OTHER_phone_append.csv')\n",
    "# new_sys = get_ranks(new_count)\n",
    "# new_correct = pd.merge(, SAMPLE, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_TELEPHONE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTY = OTHER_count.sort_values('URL', ascending=False).drop_duplicates('NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(TESTY, SAMPLE, left_on=['NAME','OFFICE_PHONE'], right_on=['MAILING_NAME','OFFICE_TELEPHONE']).groupby('polo_correct').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatchess = SAMPLE[SAMPLE.OFFICE_TELEPHONE.isin(TESTY.OFFICE_PHONE)==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(TESTY, mismatchess, left_on=['NAME'], right_on=['MAILING_NAME'])[['URL','OFFICE_PHONE','OFFICE_TELEPHONE']][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
